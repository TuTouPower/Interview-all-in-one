# 前言

## 作者介绍

大家好，我是小林，是这本图解网络电子书的作者，电子书的内容都是整理于我公众号「章。 **小林coding** 」里的图解文

还没关注的朋友，可以微信搜索「 **间发布** ，而且会有更多其他系列的图解文章，比如操作系统、计算机组成、数据库、算法等等。 **小林coding** 」，关注我的公众号， **后续最新版本的 PDF 会在我的公众号第一时**

简单介绍下这个图解网络图片都是小林一个点一条线画出来的，非常的不容易。 PDF，这本电子书共有 **15W 字 + 450 张图** ，文字都是小林一个字一个字敲出来的，

```
这本书图解网络适合什么群体呢？
```
这本书写的网络知识主要是工作或者面试的网络知识。 **面向程序员** 的，因为小林本身也是个程序员，所以涉及到的知识主要是关于程序员日常

非常适合有一点网络基础，但是又不怎么扎实，或者知识点串不起来的同学，说白 **水的同学而出来** 。 **这本图解网络就是为了拯救半桶**

因为小林写的图解网络就四个字， **通熟易懂** ！
相信你在看这本图解网络的时候，你心里的感受会是：
「卧槽，原来是这样，大学老师教知识原来是这么理解」
「卧槽，我的网络知识串起来了」
「卧槽，我感觉面试稳了」
「卧槽，相⻅恨晚」
当然，也适合面试突击网络知识时拿来看，不敢说容的深度应对大厂也是搓搓有余的，有非常多的读者跑来感激小林的图解网络，帮助他们拿到了国内很多一线大厂 100 % 涵盖了面试的网络问题，但是至少 90% 是有的，而且内
的 offer。

```
这本书图解网络要怎么阅读呢？
```
很诚恳的告诉你，这本书不是教科书，而是我写的图解网络文章的整合，所以肯定是没有教科书那么细致和全面，当然也不就不会有很多废话，而且有的知识点书上看不到。


#### 阅读的顺序可以不用从头读到尾，你可以根据你想要了解的知识点，去看哪个章节的文章就好，可以随意阅读任何章节的文章。

#### 下面这张思维导图是整个电子书的目录结构：


## 勘误事宜

#### 小林是个 如果你发现有任何错误或者疑惑的地方，欢迎你通过下方的邮箱反馈给小林手残党 ，虽然至今改了出第 3 个版本，但是我觉得还是会有很多错别字，所以在学习这份电子书的同学，，小林会逐个修正，然后发布新版本的

#### 图解网络 PDF，一起迭代出更好的图解网络！

勘误邮箱：xiaolincoding@163.com

# 一、基础篇

## 1.1 TCP/IP 网络模型

#### 对于同一台设备上的进程间通信，有很多种方式，比如有管道、消息队列、共享内存、信号等方式，而对于不同设备上的进程间通信，就需要网络通信，而设备是多样性的，所以要兼容多种多样的设备，就协商出了一套 通用的网

#### 络协议 。

#### 这个网络协议是分层的，每一层都有各自的作用和职责，接下来就分别对每一层进行介绍。


## 应用层^

最上层的，也是我们能直接接触到的就是用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。 **应用层** （ _Application Layer_ ），我们电脑或手机使用的应用软件都是在应

所以，应用层只需要专注于为用户提供应用功能，不用去关心数据是如何传输的，就类似于，我们寄快递的时候，只需要把包裹交给快递员，由他负责运输快递，我们不需要关心快速是如何被运输的。

而且应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态。

## 传输层^

应用层的数据包会传给传输层， **传输层** （ **Transport Layer** ）是为应用层提供网络支持的。

#### 在传输层会有两个传输协议，分别是 TCP 和 UDP。

TCP 如 HTTP 的全称叫传输层控制协议（应用层协议。TCP 相比 **Transmission Control Protocol** UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证），大部分应用使用的正是 TCP 传输层协议，比
数据包能可靠地传输给对方。
UDP 也高。当然，就相对很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP
传输协议，也不是一件简单的事情。
应用需要传输的数据可能会非常大，如果直接传输就不好控制，因此当传输层的数据包大小超过报文段⻓度） ，就要将数据包分块，这样即使中途有一个分块丢失或损坏了，只需要重新这一个分块，而不用重新 MSS（TCP 最大
发送整个数据包。在 TCP 协议中，我们把每个分块称为一个 **TCP 段** （ _TCP Segment_ ）。


#### 当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要用一个编号将应用区分开来，这个编号就是 端口 。

比如签栏都是一个独立的进程，操作系统会为这些进程分配临时的端口号。 80 端口通常是 Web 服务器用的， 22 端口通常是远程登录服务器用的。而对于浏览器（客户端）中的每个标

由于传输层的报文中会携带端口号，因此接收方可以识别出该报文是发送给哪个应用。

## 网络层^

#### 传输层可能大家刚接触的时候，会认为它负责将数据从一个设备传输到另一个设备，事实上它并不负责。

#### 实际场景中的网络环节是错综复杂的，中间有各种各样的线路和分叉路口，如果一个设备的数据要传输给另一个设备，就需要在各种各样的路径和节点进行选择，而传输层的设计理念是简单、高效、专注，如果传输层还负责这一

#### 块功能就有点违背设计原则了。

#### 也就是说，我们不希望传输层协议处理太多的事情，只需要服务好应用即可，让其作为应用间数据传输的媒介，帮

助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是 **网络层** （ _Internet Layer_ ）。


网络层最常使用的是成 IP 报文，如果 IP IP 报文大小超过协议（ _Internet Protocol_ MTU（以太网中一般为），IP 协议会将传输层的报文作为数据部分，再加上 1500 字节）就会 **再次进行分片** ，得到一个即将发送到网 IP 包头组装
络的 IP 报文。


#### 网络层负责将数据从一个设备传输到另一个设备，世界上那么多设备，又该如何找到对方呢？因此，网络层需要有区分设备的编号。

我们一般用的 IP 地址虽然做到了区分设备，但是寻址起来就特别麻烦，全世界那么多台设备，难道一个一个去匹配？这显然 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段，每段是 8 位。只有一个单纯
不科学。
因此，需要将 IP 地址分成两种意义：
一个是 **网络号** ，负责标识该 IP 地址是属于哪个子网的；
一个是 **主机号** ，负责标识同一子网下的不同主机；
怎么分的呢？这需要配合络号，才会去找对应的主机。 **子网掩码** 才能算出 IP 地址 的网络号和主机号。那么在寻址的过程中，先匹配到相同的网

除了寻址能力，而是通过很多网关、路由器、交换机等众多网络设备连接起来的，那么就会形成很多条网络的路径，因此当数据包 IP 协议还有另一个重要的能力就是 **路由** 。实际场景中，两台设备并不是用一条网线连接起来的，
到达一个网络节点，就需要通过算法决定下一步走哪条路径。
所以， **径。寻址更像在导航，路由更像在操作方向盘IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路** 。

## 数据链路层^


#### 实际场景中，网络并不是一个整体，比如你家和我家就不属于一个网络，所以数据不仅可以在同一个网络中设备间进行传输，也可以跨网络进行传输。

#### 一旦数据需要跨网络传输，就需要有一个设备同时在两个网络当中，这个设备一般是路由器，路由器可以通过路由表计算出下一个要去的 IP 地址。

#### 那问题来了，路由器怎么知道这个 IP 地址是哪个设备的呢？

于是，就需要有一个专⻔的层来标识网络中的设备，让数据在一个链路中传输，这就是 _Layer_ ），它主要为网络层提供链路级别传输的服务。 **数据链路层** （ _Data Link_

#### 每一台设备的网卡都会有一个通过 ARP 协议找到该目的地的 MAC MAC 地址，它就是用来唯一标识设备的。路由器计算出了下一个目的地地址，这样就知道这个 IP 地址是哪个设备的了。 IP 地址，再


## 物理层^

当数据准备要从设备发送到网络时，需要把数据包转换成电信号，让其可以在物理介质中传输，这一层就是（ _Physical Layer_ ），它主要是为数据链路层提供二进制传输的服务。 **物理层**


## 总结^


#### 综上所述，网络协议通常是由上到下，分成 5 层没，分别是应用层，传输层，网络层，数据链路层和物理层。

#### 哈喽，我是小林，就爱图解计算机基础，如果觉得文章对你有帮助，别忘记关注我哦！


# 二、HTTP 篇

## 2.1 HTTP 常⻅面试题

#### 在面试过程中，HTTP 被提问的概率还是比较高的。

#### 小林我搜集了 答 + 图解 的形式 5 大类 由浅入深 HTTP 的方式帮助大家进一步的学习和理解面试常问的题目，同时这 5 大类题跟 HTTP HTTP 。 的发展和演变 关联性是比较大的，通过 问

#### 1. HTTP 基本概念

2. Get 与 Post
3. HTTP 特性
4. HTTPS 与 HTTP
5. HTTP/1.1、HTTP/2、HTTP/3 演变


## HTTP 基本概念^

#### HTTP 是什么？描述一下

HTTP 是超文本传输协议，也就是 **H** yperText **T** ransfer **P** rotocol。

```
能否详细解释「超文本传输协议」？
```
HTTP的名字「超文本协议传输」，它可以拆成三个部分：
超文本
传输
协议


#### 1. 「协议」

#### 在生活中，我们也能随处可⻅「协议」，例如：

#### 刚毕业时会签一个「三方协议」；

#### 找房子时会签一个「租房协议」；

#### 生活中的协议，本质上与计算机中的协议是相同的，协议的特点:

#### 「个；租房协议里的参与者有两个：你和房东。 协 」字，代表的意思是必须有 两个以上的参与者 。例如三方协议里的参与者有三个：你、公司、学校三

#### 「房协议里规定租期期限、每月租金金额、违约如何处理等。 议 」字，代表的意思是对参与者的一种 行为约定和规范 。例如三方协议里规定试用期期限、毁约金等；租

#### 针对 HTTP 协议 ，我们可以这么理解。

#### HTTP 个以上的参与者 是一个用在计算机世界里的），以及相关的各种控制和错误处理方式（ 协议 。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（ 行为约定和规范 ）。 两

#### 2. 「传输」


#### 所谓的「传输」，很好理解，就是把一堆东⻄从 A 点搬到 B 点，或者从 B 点 搬到 A 点。

#### 别轻视了这个简单的动作，它至少包含两项重要的信息。

#### HTTP 协议是一个 双向协议 。

#### 我们在上网冲浪时，浏览器是请求方求数据发送给网站，网站再把一些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图片、视频了。 A ，百度网站就是应答方 B。双方约定用 HTTP 协议来通信，于是浏览器把请

#### 数据虽然是在 A 和 B 之间传输，但允许中间有 中转或接力 。

#### 就好像第一排的同学想传递纸条给最后一排的同学，那么传递的过程中就需要经过好多个同学（中间人），这样的传输方式就从「A < --- > B」，变成了「A <-> N <-> M <-> B」。

#### 而在 HTTP 里，需要中间人遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东⻄。

#### 针对 传输 ，我们可以进一步理解了 HTTP。

#### HTTP 是一个在计算机世界里专⻔用来在 两点之间传输数据 的约定和规范。

#### 3. 「超文本」

#### HTTP 传输的内容是「超文本」。

#### 我们先来理解「文本」，在互联网早期的时候只是简单的字符文字，但现在「文本」的涵义已经可以扩展为图片、视频、压缩包等，在 HTTP 眼里这些都算作「文本」。

#### 再来理解「超文本」，它就是一个超文本跳转到另外一个超文本。 超越了普通文本的文本 ，它是文字、图片、视频等的混合体，最关键有超链接，能从

#### HTML 览器的解释，呈现给我们的就是一个文字、有画面的网⻚了。就是最常⻅的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏


#### OK的答案：，经过了对 HTTP 里这三个名词的详细解释，就可以给出比「超文本传输协议」这七个字更准确更有技术含量

#### HTTP 规范」。是一个在计算机世界里专⻔在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和

#### 那「HTTP 是用于从互联网服务器传输超文本到本地浏览器的协议 ，这种说法正确吗？

#### 这种说法是 不正确 的。因为也可以是「服务器< -- >服务器」，所以采用 两点之间 的描述会更准确。

#### HTTP 常⻅的状态码，有哪些？

_1xx_
1xx 类状态码属于 **提示信息** ，是协议处理中的一种中间状态，实际用到的比较少。
_2xx_
2xx 类状态码表示服务器 **成功** 处理了客户端的请求，也是我们最愿意看到的状态。
「数据。 **200 OK** 」是最常⻅的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body

「 **204 No Content** 」也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。


「是其中的一部分，也是服务器处理成功的状态。 **206 Partial Content** 」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而

_3xx_
3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是 **重定
向** 。
「 **301 Moved Permanently** 」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
「 **302 Found** 」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。
301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

「存控制。 **304 Not Modified** 」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓

_4xx_
4xx 类状态码表示客户端发送的 **报文有误** ，服务器无法处理，也就是错误码的含义。
「 **400 Bad Request** 」表示客户端请求的报文有错误，但只是个笼统的错误。
「 **403 Forbidden** 」表示服务器禁止访问资源，并不是客户端的请求出错。
「 **404 Not Found** 」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。
_5xx_
5xx 类状态码表示客户端请求报文正确，但是 **服务器处理时内部发生了错误** ，属于服务器端的错误码。
「 **500 Internal Server Error** 」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
「 **501 Not Implemented** 」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。

「发生了错误。 **502 Bad Gateway** 」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器

「思。 **503 Service Unavailable** 」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意

```
http 常⻅字段有哪些？
```
_Host_ 字段


#### 客户端发送请求时，用来指定服务器的域名。

有了 Host 字段，就可以将请求发往「同一台」服务器上的不同网站。
_Content-Length_ 字段
服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据⻓度。

#### 如上面则是告诉浏览器，本次服务器回应的数据⻓度是 1000 个字节，后面的字节就属于下一个回应了。

_Connection_ 字段

```
Host: http://www.A.com
```
```
Content-Length: 1000
```

```
Connection 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。
```
HTTP/1.1 Keep-Alive版本的默认连接都是持久连接，但为了兼容老版本的。 HTTP，需要指定 Connection 首部字段的值为

#### 一个可以复用的 TCP 连接就建立了，直到客户端或服务器主动关闭连接。但是，这不是标准字段。

_Content-Type_ 字段
Content-Type 字段用于服务器回应时，告诉客户端，本次数据是什么格式。

#### 上面的类型表明，发送的是网⻚，而且编码是UTF-8。

```
Connection: keep-alive
```
```
Content-Type: text/html; charset=utf-
```

客户端请求的时候，可以使用 Accept 字段声明自己可以接受哪些数据格式。

上面代码中，客户端声明自己可以接受任何格式的数据。
_Content-Encoding_ 字段
Content-Encoding 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式

上面表示服务器返回的数据采用了 gzip 方式压缩，告知客户端需要用此方式解压。
客户端在请求时，用 Accept-Encoding 字段说明自己可以接受哪些压缩方法。

## GET 与 POST^

#### 说一下 GET 和 POST 的区别？

Get 方法的含义是请求 **从服务器获取资源** ，这个资源可以是静态的文本、⻚面、图片视频等。
比如，你打开我的文章，浏览器就会发送 GET 请求给服务器，服务器就会返回文章的所有文字及资源。

```
Accept: */*
```
```
Content-Encoding: gzip
```
```
Accept-Encoding: gzip, deflate
```

而POST 方法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报文的 body 里。
比如，你在我文章底部，敲入了留言后点击「提交」（留言文字放进了报文 body 里，然后拼接好 POST 请求头，通过 **暗示你们留言** TCP ），浏览器就会执行一次协议发送给服务器。 POST 请求，把你的

#### GET 和 POST 方法都是安全和幂等的吗？

#### 先说明下安全和幂等的概念：

#### 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。

#### 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

#### 那么很明显的，且每次的结果都是相同的。 GET 方法就是安全且幂等的 ，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全


#### POST 个资源，所以 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是 不是幂等 的。 不安全 的，且多次提交数据就会创建多

## HTTP 特性^

#### 你知道的 HTTP（1.1） 的优点有哪些，怎么体现的？

#### HTTP 最凸出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。

#### 1. 简单

HTTP 和使用的⻔槛。基本的报文格式就是 header + body，头部信息也是 key-value 简单文本的形式， **易于理解** ，降低了学习

_2._ 灵活和易于扩展
HTTP **义和扩充** 协议里的各类请求方法、。 URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员 **自定**

同时 HTTP 由于是工作在应用层（ OSI 第七层），则它 **下层可以随意变化** 。
HTTPS QUIC。也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚至把 TCP 层换成了基于 UDP 的

_3._ 应用广泛和跨平台
互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购
物、理财、吃鸡，HTTP 的应用 **片地开花** ，同时天然具有 **跨平台** 的优越性。

```
那它的缺点呢？
```
HTTP 协议里有优缺点一体的 **双刃剑** ，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。

_1._ 无状态双刃剑
无状态的负担，能够把更多的 **好处** ，因为服务器不会去记忆 CPU 和内存用来对外提供服务。 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的

无状态的 **坏处** ，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。
例如登录关联的，每次都要问一遍身份信息。->添加购物⻋->下单->结算->支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有


#### 这样每操作一次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是 酸爽 ！

对于无状态的问题，解法方案有很多种，其中比较简单的方式用 **Cookie** 技术。
Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。
相当于， **带上「小贴纸」，服务器就能认得了了在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，** ，

#### 2. 明文传输双刃剑

明文意味着在传输过程中的信息，是可方便阅读的，通过浏览器的看，为我们调试工作带了极大的便利性。 F12 控制台或 Wireshark 抓包都可以直接肉眼查


#### 但是这正是这样，容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那HTTP 的所有信息都暴露在了光天化日下，相当于 信息裸奔你号没了 。在传输的漫⻓的过程中，信息的内。

#### 3. 不安全

#### HTTP 比较严重的缺点就是不安全：

#### 通信使用明文（不加密），内容可能会被窃听。比如， 账号信息容易泄漏，那你号没了。

#### 不验证通信方的身份，因此有可能遭遇伪装。比如， 访问假的淘宝、拼多多，那你钱没了。

#### 无法证明报文的完整性，所以有可能已遭篡改。比如， 网⻚上植入垃圾广告，视觉污染，眼没了。

#### HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。

#### 那你再说下 HTTP/1.1 的性能如何？

#### HTTP 协议是基于 TCP/IP ，并且使用了「 请求 - 应答 」的通信模式，所以性能的关键就在这 两点 里。

#### 1. ⻓连接


#### 早期串行请求，做了无谓的 HTTP/1.0 性能上的一个很大的问题，那就是每发起一个请求，都要新建一次 TCP 连接建立和断开，增加了通信开销。 TCP 连接（三次握手），而且是

#### 为了解决上述TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。 TCP 连接问题，HTTP/1.1 提出了 ⻓连接 的通信方式，也叫持久连接。这种方式的好处在于减少了

#### 持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。

#### 2. 管道网络传输

HTTP/1.1 采用了⻓连接的方式，这使得管道（pipeline）网络传输成为了可能。
即可在同一个二个请求出去，可以 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第 **减少整体的响应时间。**

举例来说，客户端需要请求两个资源。以前的做法是，在同一个出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出TCP A 连接里面，先发送请求和 B 请求。 A 请求，然后等待服务器做


#### 但是服务器还是按照排队等着。这称为「队头堵塞」。 顺序 ，先回应 A 请求，完成后再回应 B 请求。要是前面的回应特别慢，后面就会有许多请求

#### 3. 队头阻塞

#### 「请求 - 应答」的模式加剧了 HTTP 的性能问题。

#### 因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致

#### 客户端一直请求不到数据，这也就是「 队头阻塞 」。 好比上班的路上塞⻋ 。


#### 总之 HTTP/1.1 的性能一般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。

## HTTP 与 HTTPS^

#### HTTP 与 HTTPS 有哪些区别？

#### 1. HTTP TCP 和是超文本传输协议，信息是明文传输，存在安全⻛险的问题。 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。HTTPS 则解决 HTTP 不安全的缺陷，在

#### 2. HTTP 后，还需进行连接建立相对简单， SSL/TLS 的握手过程，才可进入加密报文传输。 TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之

#### 3. HTTP 的端口号是 80 ，HTTPS 的端口号是 443 。

#### 4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

#### HTTPS 解决了 HTTP 的哪些问题？

#### HTTP 由于是明文传输，所以安全上存在以下三个⻛险：

#### 窃听⻛险 ，比如通信链路上可以获取通信内容，用户号容易没。

#### 篡改⻛险 ，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。


#### 冒充⻛险 ，比如冒充淘宝网站，用户钱容易没。

#### HTTP S 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的⻛险：

#### 信息加密 ：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。

#### 校验机制 ：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。

#### 身份证书 ：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。

#### 可⻅，只要自身不做「恶」，SSL/TLS 协议是能保证通信是安全的。

#### HTTPS 是如何解决上面的三个⻛险的？

#### 混合加密 的方式实现信息的 机密性 ，解决了窃听的⻛险。

#### 摘要算法 了篡改的⻛险。的方式来实现 完整性 ，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决

#### 将服务器公钥放入到 数字证书 中，解决了冒充的⻛险。

#### 1. 混合加密

#### 通过 混合加密 的方式可以保证信息的 机密性 ，解决了窃听的⻛险。


#### HTTPS 采用的是 对称加密 和 非对称加密 结合的「混合加密」方式：

#### 在通信建立前采用 非对称加密 的方式交换「会话秘钥」，后续就不再使用非对称加密。

#### 在通信过程中全部使用 对称加密 的「会话秘钥」的方式加密明文数据。

#### 采用「混合加密」的方式的原因：

#### 对称加密 只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。

#### 非对称加密 使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

#### 2. 摘要算法

#### 摘要算法 用来实现 完整性 ，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的⻛险。


#### 客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出 + 明文」一同加密成密文后，发

#### 的「指纹」做比较，若「指纹」相同，说明数据是完整的。

#### 3. 数字证书

#### 客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。

#### 这就存在些问题，如何保证公钥不被篡改和信任度？

#### 所以这里就需要借助第三方权威机构机构颁发）中，只要证书是可信的，公钥就是可信的。 CA （数字证书认证机构），将 服务器公钥放在数字证书 （由数字证书认证


#### 通过数字证书的方式保证服务器公钥的身份，解决冒充的⻛险。

#### HTTPS 是如何建立连接的？其间交互了什么？

#### SSL/TLS 协议基本流程：

#### 客户端向服务器索要并验证服务器的公钥。

#### 双方协商生产「会话秘钥」。

#### 双方采用「会话秘钥」进行加密通信。

#### 前两步也就是 SSL/TLS 的建立过程，也就是握手阶段。

#### SSL/TLS 的「握手阶段」涉及 四次 通信，可⻅下图：



#### SSL/TLS 协议建立的详细流程：

_1. ClientHello_
首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。
在这一步，客户端主要向服务器发送以下信息：
（ 1 ）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。
（ 2 ）客户端生产的随机数（Client Random），后面用于生产「会话秘钥」。
（ 3 ）客户端支持的密码套件列表，如 RSA 加密算法。
_2. SeverHello_
服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。服务器回应的内容有如下内容：
（ 1 ）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。
（ 2 ）服务器生产的随机数（Server Random），后面用于生产「会话秘钥」。
（ 3 ）确认的密码套件列表，如 RSA 加密算法。
（ 4 ）服务器的数字证书。
_3._ 客户端回应
客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。
如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：
（ 1 ）一个随机数（pre-master key）。该随机数会被服务器公钥加密。
（ 2 ）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
（要，用来供服务端校验。 3 ）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘


#### 上面第一项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协

#### 商的加密算法， 各自生成 本次通信的「会话秘钥」。

#### 4. 服务器的最后回应

服务器收到客户端的第三个随机数（钥」。然后，向客户端发生最后的信息：pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘

（ 1 ）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
（要，用来供客户端校验。 2 ）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘

至此，整个协议，只不过用「会话秘钥」加密内容。 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP

## HTTP/1.1、HTTP/2、HTTP/3 演变^

#### 说说 HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

#### HTTP/1.1 相比 HTTP/1.0 性能上的改进：

#### 使用 TCP ⻓连接的方式改善了 HTTP/1.0 短连接造成的性能开销。

```
支持管道（减少整体的响应时间。pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以
```
但 HTTP/1.1 还是有性能瓶颈：
请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分；
发送冗⻓的首部。每次互相发送相同的首部造成的浪费较多；
服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
没有请求优先级控制；
请求只能从客户端开始，服务器只能被动响应。
那上面的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。
那 HTTP/2 相比 HTTP/1.1 性能上的改进：

_1._ 头部压缩


HTTP/2 **复的部分** 会。 **压缩头** （Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你 **消除重**

这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索
引号，以后就不发送同样字段了，只发送索引号，这样就 **提高速度** 了。

_2._ 二进制格式
HTTP/2 且统称为帧（不再像frame HTTP/1.1 ）： **头信息帧和数据帧** 里的纯文本形式的报文，而是全面采用了。 **二进制格式** ，头信息和数据体都是二进制，并

#### 这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这 增加了数据传输的效率 。

#### 3. 数据流

#### HTTP/2 包做标记，指出它属于哪个回应。的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据

每个请求或回应的所有数据包，称为一个数据流（定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数Stream ）。每个数据流都标记着一个独一无二的编号，其中规

客户端还可以 **指定数据流的优先级** 。优先级高的请求，服务器就先响应该请求。


#### 4. 多路复用

#### HTTP/2 是可以在 一个连接中并发多个请求或回应，而不用按照顺序一一对应 。

#### 移除了 了连接的利用率 HTTP/1.1 。中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题， 降低了延迟，大幅度提高

#### 举例来说，在一个回应 A 请求已经处理好的部分，接着回应 TCP 连接里，服务器收到了客户端 B 请求，完成后，再回应 A 和 B 的两个请求，如果发现 A 请求剩下的部分。 A 处理过程非常耗时，于是就


#### 5. 服务器推送

#### HTTP/2 送消息。还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以 主动 向客户端发

举例来说，在浏览器刚请求 **少延时的等待** ，也就是服务器推送（ HTML 的时候，就提前把可能会用到的Server Push，也叫 Cache Push JS）。、CSS 文件等静态资源主动发给客户端， **减**

```
HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？
```
HTTP/2 的。所以一旦发生了丢包现象，就会触发主要的问题在于，多个 HTTP 请求在复用一个 TCP 的重传机制，这样在一个 TCP 连接，下层的 TCP TCP 连接中的协议是不知道有多少个 **所有的 HTTP 请求都必须等** HTTP 请求
**待这个丢了的包被重传回来** 。
HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了
HTTP/2 多个请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。
这都是基于 TCP 传输层的问题，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**


#### UDP 题。发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问

#### 大家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。

#### QUIC 影响 。有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流， 其他流不会受到

```
TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack。
```
HTTPS 把以往的要建立一个连接，要花费 TCP 和 TLS/1.3 的 6 6 次交互次交互，先是建立三次握手，然后是 **合并成了 3 次，减少了交互次数** (^) 。TLS/1.3 的三次握手。QUIC 直接


#### 所以， QUIC 是一个在 UDP 之上的 伪 TCP + TLS + HTTP/2 的多路复用的协议。

#### QUIC HTTP/3 是新协议，对于很多网络设备，根本不知道什么是现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 QUIC，只会当做 TCP UDP。 ，这样会出现新的问题。所以

#### 参考资料：

#### [1] 上野 宣.图解HTTP.人⺠邮电出版社.

#### [2] 罗剑锋.透视HTTP协议.极客时间.

[3] 陈皓.HTTP的前世今.酷壳CoolShell.https://coolshell.cn/articles/19840.html
[4] 阮一峰.HTTP 协议入⻔.阮一峰的网络日志.http://www.ruanyifeng.com/blog/2016/08/http.html

## 读者问答^

```
读者问：“https和http相比，就是传输的内容多了对称加密，可以这么理解吗？”
```

1. 建立连接时候：https 比 http多了 TLS 的握手过程；
2. 传输内容的时候：https 会把数据进行加密，通常是对称加密数据；
    读者问：“ 我看文中 TLS 和 SSL 没有做区分，这两个需要区分吗？”

这两实际上是一个东⻄。
SSL 设计的。是洋文 “ _Secure Sockets Layer_ 的缩写，中文叫做「安全套接层」。它是在上世纪 90 年代中期，由网景公司

到了称改为 (^1999) TLS年，（是SSL “ _Transport Layer Security_ 因为应用广泛，已经成为互联网上的事实标准。” 的缩写），中文叫做 「传输层安全协议」。IETF 就在那年把 SSL 标准化。标准化之后的名
很多相关的文章都把这两者并列称呼（SSL/TLS），因为这两者可以视作同一个东⻄的不同阶段。
读者问：“为啥 ssl 的握手是 4 次？”
SSL/TLS 1.2 送，就是 4 次握手：需要 4 握手，需要 2 个 RTT 的时延，我文中的图是把每个交互分开画了，实际上把他们合在一起发

#### 另外， SSL/TLS 1.3 优化了过程，只需要 1 个 RTT 往返时延，也就是只需要 3 次握手：


## 最后^

#### 本文的 30 张图片，都是从一条线两条线画出来，灰常的费劲，深切感受到画图也是个 体力活 啊！

#### 爱偷懒的我其实不爱画图，但为了让大家能更好的理解，在跟自己无数次斗争后，踏上了耗时耗体力的画图的不归路，希望对你们有帮助！

**小林是专为大家图解的工具人，Goodbye，我们下次⻅！**


## 2.2 HTTP/1.1如何优化？

#### 问你一句：「 你知道 HTTP/1.1 该如何优化吗？ 」

我想你第一时间想到的是，使用 KeepAlive 将 HTTP/1.1 从短连接改成⻓链接。
这个确实是一个优化的手段，它是从底层的传输层这一方向入手的，通过减少少了网络传输的延迟，从而提高 HTTP/1.1 协议的传输效率。 TCP 连接建立和断开的次数，来减

但其实还可以从其他方向来优化 HTTP/1.1 协议，比如有如下 3 种优化思路：
尽量避免发送 _HTTP_ 请求；
在需要发送 _HTTP_ 请求时，考虑如何减少请求次数；
减少服务器的 _HTTP_ 响应的数据大小；
下面，就针对这三种思路具体看看有哪些优化方法。

## 如何避免发送 HTTP 请求？^


#### 这个思路你看到是不是觉得很奇怪，不发送氓嘛？ HTTP 请求，那还客户端还怎么和服务器交互数据？小林你这不是耍流

#### 冷静冷静，你说的没错，客户端当然要向服务器发送请求的。

#### 但是，对于一些具有重复性的数据都 缓存在本地 ，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求 HTTP/1.1-响应」的

#### 的性能肯定肉眼可⻅的提升。

#### 所以，避免发送头部有不少是针对缓存的字段。 HTTP 请求的方法就是通过 缓存技术 ，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的

#### 那缓存是如何做到的呢？

客户端会把第一次请求以及响应的数据保存在本地磁盘上，其中将请求的形成映射关系。 URL 作为 key，而响应作为 value，两者

这样当后续发起相同的请求时，就可以先在本地磁盘上通过直接从本地读取该响应。毋庸置疑，读取本次磁盘的速度肯定比网络请求快得多，如下图： key 查到对应的 value，也就是响应，如果找到了，就


#### 聪明的你可能想到了，万一缓存的响应不是最新的，而客户端并不知情，那么该怎么办呢？

#### 放心，这个问题 HTTP 设计者早已考虑到。

#### 所以，服务器在发送应头部的信息时，一旦发现缓存的响应是过期的，则就会重新发送网络请求。 HTTP 响应时，会估算一个过期的时间，并把这个信息放到响应头部中，这样客户端在查看响HTTP 关于缓说明会的头部字段很

#### 多，这部分内容留在下次文章，这次暂时不具体说明。


#### 如果客户端从第一次请求得到的响应头部中发现该响应过期了，客户端重新发送请求，假设服务器上的资源并没有变更，还是老样子，那么你觉得还要在服务器的响应带上这个资源吗？

#### 很显然不带的话，可以提高 HTTP 协议的性能，那具体如何做到呢？

只需要客户端在重新发送请求时，在请求的识响应的资源，当服务器收到请求后，会将本地资源的摘要与请求中的摘要做个比较。 Etag 头部带上第一次请求的响应头部中的摘要，这个摘要是唯一标

如果不同，那么说明客户端的缓存已经没有价值，服务器在响应中带上最新的资源。
如果相同，说明客户端的缓存还是可以继续使用的，那么服务器告诉客户端仍然有效，这样就可以减少响应资源在网络中传输的延时，如下图： **仅返回不含有包体的 304 Not Modified 响应** ，


缓存真的是性能优化的一把万能钥匙，小到 CPU Cache、Page Cache、Redis Cache，大到 HTTP 协议的缓存。

## 如何减少 HTTP 请求次数？^

#### 减少 HTTP 请求次数自然也就提升了 HTTP 性能，可以从这 3 个方面入手：

#### 减少重定向请求次数；


#### 合并请求；

#### 延迟发送请求；

### 减少重定向请求次数

#### 我们先来看看什么是 重定向请求 ？

服务器上的一个资源可能由于迁移、维护等原因从时服务器不能粗暴地返回错误，而是通过 302 响应码和 url1 移至 Location url2 后，而客户端不知情，它还是继续请求 头部，告诉客户端该资源已经迁移至 url1 url2，这
了，于是客户端需要再发送 url2 请求以获得服务器的资源。
那么，如果重定向请求越多，那么客户端就要多次发起越降低网络性能。 HTTP 请求，每一次的 HTTP 请求都得经过网络，这无疑会

另外，服务端这一方往往不只有一台服务器，比如源服务器上一级是代理服务器，然后代理服务器才与客户端通信，这时客户端重定向就会导致客户端与代理服务器之间需要 2 次消息传递，如下图：

#### 如果 重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了 ，如下图：


#### 而且当代理服务器知晓了重定向规则后，可以进一步减少消息传递次数，如下图：


#### 除了 302 重定向响应码，还有其他一些重定向的响应码，你可以从下图看到：

其中，访问服务器的资源。 301 和 308 响应码是告诉客户端可以将重定向响应缓存到本地磁盘，之后客户端就自动用 url2 替代 url1


### 合并请求

#### 如果把多个访问小文件的请求合并成一个大的请求，虽然传输的总资源还是一样，但是减少请求，也就意味着 减少

#### 了重复发送的 HTTP 头部 。

#### 另外由于于是为了防止单个请求的阻塞，所以一般浏览器会同时发起 HTTP/1.1 是请求响应模型，如果第一个发送的请求，未收到对应的响应，那么后续的请求就不会发送， 5-6 个请求，每一个请求都是不同的 TCP 连接，那么

#### 如果合并了请求，也就会 减少 TCP 连接的数量，因而省去了 TCP 握手和慢启动过程耗费的时间 。

#### 接下来，具体看看合并请求的几种方式。

有的网⻚会含有很多小图片、小图标，有多少个小图片，客户端就要发起多少次请求。那么对于这些小图片，我们可以考虑使用 CSS Image Sprites 技术把它们合成一个大图片，这样浏览器就可以用一次请求获得一个大图片，
然后再根据 CSS 数据把大图片切割成多张小图片。

#### 这种方式就是 少网络的开销通过将多个小图片合并成一个大图片来减少 。 HTTP 请求的次数，以减少 HTTP 请求的次数，从而减

除了将小图片合并成大图片的方式，还有服务端使用件，也是能达到类似的效果。 webpack 等打包工具将 js、css 等资源合并打包成大文

另外，还可以将图片的二进制数据用发送. base64 编码后，以 URL 的形式潜入到 HTML 文件，跟随 HTML 文件一并

<imagesrc="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPoAAAFKCAIAAAC7M9WrAAAACXBIWXMAA ... (^)
/>


#### 这样客户端收到少了请求的次数。 HTML 后，就可以直接解码出数据，然后直接显示图片，就不用再发起图片相关的请求，这样便减

#### 可以看到， 合并请求的方式就是合并资源，以一个大资源的请求替换多个小资源的请求 。

#### 但是这样的合并请求会带来新的问题， 资源文件 ，这显然带来了额外的网络消耗。 当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大

### 延迟发送请求

#### 不要一口气吃成大胖子，一般于是可以通过「 按需获取 」的方式，来减少第一时间的 HTML 里会含有很多 HTTP HTTP 的 URL请求次数。，当前不需要的资源，我们没必要也获取过来，

#### 请求网⻚的时候，没必要把全部资源都获取到，而是只获取当前用户所看到的⻚面资源，当用户向下滑动⻚面的时候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果。

## 如何减少 HTTP 响应的数据大小？^

#### 对于 HTTP 的请求和响应，通常 HTTP 的响应的数据大小会比较大，也就是服务器返回的资源会比较大。

#### 于是，我们可以考虑对响应的资源进行 压缩 ，这样就可以减少响应的数据大小，从而提高网络传输的效率。

#### 压缩的方式一般分为 2 种，分别是：


#### 无损压缩；

#### 有损压缩；

### 无损压缩

#### 无损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合用在文本文件、程序可执行文件、程序源代码。

#### 首先，我们针对代码的语法规则进行压缩，因为通常代码文件都有很多换行符或者空格，这些是为了帮助程序员更好的阅读，但是机器执行时并不要这些符，把这些多余的符号给去除掉。

#### 接下来，就是无损压缩了，需要对原始资源建立统计模型，利用这个统计模型，将常出现的数据用较短的二进制比特序列表示，将不常出现的数据用较⻓的二进制比特序列表示，生成二进制比特序列一般是「霍夫曼编码」算法。

gzip 段告诉服务器：就是比较常⻅的无损压缩。客户端支持的压缩算法，会在 HTTP 请求中通过头部中的 Accept-Encoding 字

服务器收到后，会从中选择一个服务器支持的或者合适的压缩算法，然后使用此压缩算法对响应资源进行压缩，最后通过响应头部中的 content-encoding 字段告诉客户端该资源使用的压缩算法。

gzip 择压缩效率更高的的压缩效率相比 br Google 压缩算法。推出的 Brotli 算法还是差点意思，也就是上文中的 br，所以如果可以，服务器应该选

### 有损压缩

#### 与无损压缩相对的就是有损压缩，经过此方法压缩，解压的数据会与原始数据不同但是非常接近。

#### 有损压缩主要将次要的数据舍弃，牺牲一些质量来减少数据量、提高压缩比，这种方法经常用于压缩多媒体数据，比如音频、视频、图片。

可以通过 HTTP 请求头部中的 Accept 字段里的「 q 质量因子」，告诉服务器期望的资源质量。

关于图片的压缩，目前压缩比较高的是下图： Google 推出的 **WebP 格式** ，它与常⻅的 Png 格式图片的压缩比例对比如

```
Accept-Encoding: gzip, deflate, br
```
```
content-encoding: gzip
```
```
Accept: audio/*; q=0.2, audio/basic
```

可以发现，相同图片质量下，使用 WebP 格式的图片，这将大幅度提升网络传输的性能。WebP 格式的图片大小都比 Png 格式的图片小，所以对于大量图片的网站，可以考虑

关于音视频的压缩，音视频主要是动态的，每个帧都有时序的关系，通常时间连续的帧之间的变化是很小的。
比如，一个在看书的视频，画面通常只有人物的手和书桌上的书是会有变化的，而其他地方通常都是静态的，于是只需要在一个静态的关键帧，使用 **增量数据** 来表达后续的帧，这样便减少了很多数据，提高了网络传输的性能。对
于视频常⻅的编码格式有 H264、H265 等，音频常⻅的编码格式有 AAC、AC3。

## 总结^

#### 这次主要从 3 个方面介绍了优化 HTTP/1.1 协议的思路。

#### 第一个思路是，通过缓存技术来避免发送盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候 HTTP 请求。客户端收到第一个请求的响应后，可以将其缓存在本地磁

#### 带上响应数据的摘要，服务器比对后发现资源没有变化，就发出不带包体的有效。 304 响应，告诉客户端缓存的响应仍然

#### 第二个思路是，减少 HTTP 请求的次数，有以下的方法：

#### 1. 将原本由客户端处理的重定向请求，交给代理服务器处理，这样可以减少重定向请求的次数；

#### 2. 将多个小资源合并成一个大资源再传输，能够减少接数量，进而省去 TCP 握手和慢启动的网络消耗； HTTP 请求次数以及 头部的重复传输，再来减少 TCP 连

#### 3. 按需访问资源，只访问当前用户看得到迟请求，也就减少了同一时间的 HTTP /请求次数。用得到的资源，当客户往下滑动，再访问接下来的资源，以此达到延

#### 第三思路是，通过压缩响应资源，降低传输资源的大小，从而提高传输效率，所以应当选择更优秀的压缩算法。


#### 不管怎么优化和 HTTP/3 协议。 HTTP/1.1 协议都是有限的，不然也不会出现 HTTP/2 和 HTTP/3 协议，后续我们再来介绍 HTTP/2

#### 好了，此次分享到这就结束了，如果这篇文章对你有帮助，欢迎来个三连，你们的支持就是小林的最大动力，我们下次⻅！

#### 参考资料：

1. https://isparta.github.io/compare-webp/index.html
2. https://zh.wikipedia.org/wiki/https://en.wikipedia.org/wiki/Lossy_compression
3. https://en.wikipedia.org/wiki/Lossless_compression
4. https://time.geekbang.org/column/article/242667
5. https://www.tutorialrepublic.com/css-tutorial/css-sprites.php
6. https://blog.csdn.net/weixin_38055381/article/details/81504716
7. https://blog.csdn.net/weixin_44151887/article/details/106278559

## 最后^

#### 哈喽，我是小林，就爱图解计算机基础，如果文章对你有帮助，别忘记关注哦！


## 2.3 HTTPS RSA 握手解析

#### 我很早之前写过一篇关于以这次我们再来深入一下 HTTP HTTPS和，用 HTTPS 实战抓包 的文章，但对于的方式，带大家再来窥探一次 HTTPS 介绍还不够详细，只讲了比较基础的部分，所 HTTPS。

#### 对于还不知道对称加密和非对称加密的同学，你先复习我以前的这篇文章题」，本篇文章默认大家已经具备了这些知识。 「硬核！ 30 张图解 HTTP 常⻅的面试

## TLS 握手过程^

#### HTTP 都可以截获通信的内容。由于是明文传输，所谓的明文，就是说客户端与服务端通信的信息都是肉眼可⻅的，随意使用一个抓包工具

#### 所以安全上存在以下三个⻛险：

#### 窃听⻛险，比如通信链路上可以获取通信内容，用户号容易没。

#### 篡改⻛险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。

#### 冒充⻛险，比如冒充淘宝网站，用户钱容易没。

#### HTTP S 在 HTTP 与 TCP 层之间加入了 TLS 协议，来解决上述的⻛险。


#### TLS 协议是如何解决 HTTP 的⻛险的呢？

#### 信息加密： HTTP 交互信息是被加密的，第三方就无法被窃取；

#### 校验机制：校验信息传输过程中是否有被第三方篡改过，如果被篡改过，则会有警告提示；

#### 身份证书：证明淘宝是真的淘宝网；

#### 可⻅，有了握手过程，如下图： TLS 协议，能保证 HTTP 通信是安全的了，那么在进行 HTTP 通信前，需要先进行 TLS 握手。TLS 的


上图简要概述来位，类似于 TCP TLS 里的的握手过程，其中每一个「框」都是一个记录（ segment。多个记录可以组合成一个 TCP 包发送，所以 _record_ ），记录是 **通常经过「四个消息」就可以完成** TLS 收发数据的基本单
**TLS** 议。 **握手，也就是需要 2 个 RTT 的时延** ，然后就可以在安全的通信环境里发送 HTTP 报文，实现 HTTPS 协

所以可以发现，连接。 HTTPS 是应用层协议，需要先完成 TCP 连接建立，然后走 TLS 握手过程后，才能建立通信安全的


#### 事实上，不同的密钥交换算法，TLS 的握手过程可能会有一些区别。

#### 这里先简单介绍下密钥交换算法，因为考虑到性能的问题，所以双方在加密应用信息时使用的是对称加密密钥，而对称加密密钥是不能被泄漏的，为了保证对称加密密钥的安全性，所以使用非对称加密的方式来保护对称加密密钥

#### 的协商，这个工作就是密钥交换算法负责的。

#### 接下来，我们就以最简单的 RSA 密钥交换算法，来看看它的 TLS 握手过程。

## RSA 握手过程^

#### 传统的私钥，其中公钥会在 TLS 握手基本都是使用 TLS 握手阶段传递给客户端，私钥则一直留在服务端，一定要确保私钥不能被窃取。 RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书文件中包含一对公

#### 在法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双方就得到了相同的密钥，再用它加密应用消息。 RSA 密钥协商算法中，客户端会生成随机密钥，并使用服务端的公钥加密后再传给服务端。根据非对称加密算

我用 Wireshark 工具抓了用 RSA 密钥交换的 TLS 握手过程，你可以从下面看到，一共经历来四次握手：

对应 Wireshark 的抓包，我也画了一幅图，你可以从下图很清晰地看到该过程：


#### 那么，接下来针对每一个 TLS 握手做进一步的介绍。


### TLS 第一次握手

客户端首先会发一个「 **Client Hello** 」消息，字面意思我们也能理解到，这是跟服务器「打招呼」。

消息里面有客户端使用的数会被服务端保留，它是生成对称加密密钥的材料之一。 TLS 版本号、支持的密码套件列表，以及生成的 **随机数（** **_Client Random_** **）** ，这个随机

### TLS 第二次握手

当服务端收到客户端的「套件，以及生成 **随机数（** Client Hello **_Server Random_** 」消息后，会确认 **）** 。 TLS 版本号是否支持，和从密码套件列表中选择一个密码

接着，返回「然后从客户端的密码套件列表选择了一个合适的密码套件。 **Server Hello** 」消息，消息里面有服务器确认的 TLS 版本号，也给出了随机数（Server Random），


可以看到，服务端选择的密码套件是 “Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256”。
这个密码套件看起来真让人头晕，好一大串，但是其实它是有固定格式和规范的。基本的形式是「 **签名算法 + 对称加密算法 + 摘要算法** 」， 一般 WITH 单词前面有两个单词，第一个单词是约定密钥交换的算法， **密钥交换算法 +**
第二个单词是约定证书的验证算法。比如刚才的密码套件的意思就是：
由于 WITH 单词只有一个 RSA，则说明握手时密钥交换算法和签名算法都是使用 RSA；
握手后的通信使用 AES 对称算法，密钥⻓度 128 位，分组模式是 GCM；
摘要算法 SHA384 用于消息认证和产生随机数；
就前面这两个客户端和服务端相互「打招呼」的过程，客户端和服务端就已确认了而且你可能发现客户端和服务端都会各自生成一个随机数，并且还会把随机数传递给对方。 TLS 版本和使用的密码套件，

那这个随机数有啥用呢？其实这两个随机数是后续作为生成「会话密钥」的条件，所谓的会话密钥就是数据传输时，所使用的对称加密密钥。

然后，服务端为了证明自己的身份，会发送「 **Server Certificate** 」给客户端，这个消息里含有数字证书。

随后，服务端发了「呼完毕。 **Server Hello Done** 」消息，目的是告诉客户端，我已经把该给你的东⻄都给你了，本次打招


### 客户端验证证书

#### 在这里刹个⻋，客户端拿到了服务端的数字证书后，要怎么校验该数字证书是真实有效的呢？

#### 数字证书和 CA 机构

#### 在说校验数字证书是否可信的过程前，我们先来看看数字证书是什么，一个数字证书通常包含了：

#### 公钥；

#### 持有者信息；

#### 证书认证机构（CA）的信息；

#### CA 对这份文件的数字签名及使用的算法；

#### 证书有效期；

#### 还有一些其他额外信息；

#### 那数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充。说简单些，证书就是用来告诉客户端，该服务端是否是合法的，因为只有证书合法，才代表服务端身份是可信的。

#### 我们用证书来认证公钥持有者的身份（服务端的身份），那证书又是怎么来的？又该怎么认证证书呢？

为了让服务端的公钥被大家信任，服务端的证书都是由就是网络世界里的公安局、公证中心，具有极高的可信度，所以由它来给各个公钥签名，信任的一方签发的证书， CA （ _Certificate Authority_ ，证书认证机构）签名的，CA
那必然证书也是被信任的。
之所以要签名，是因为签名的作用可以避免中间人在获取证书时对证书内容的篡改。
**数字证书签发和验证流程**
如下图图所示，为数字证书签发和验证流程：


#### CA 签发证书的过程，如上图左边部分：

首先得到一个 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 值； Hash 计算，
然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；
最后将 Certificate Signature 添加在文件证书上，形成数字证书；
客户端校验服务端的数字证书的过程，如上图右边部分：
首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
通常浏览器和操作系统中集成了Signature 内容，得到一个 Hash CA 值 H2 的公钥信息，浏览器收到证书后可以使用； CA 的公钥解密 Certificate
最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。
**证书链**
但事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级： CA 申请的证书一般不是根证书签发的，


#### 对于这种三级层级关系的证书的验证过程如下：

客户端收到钥去验证 baidu.com baidu.com 证书是否可信。于是，客户端根据的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公 baidu.com 证书中的签发者，找到该证书的颁发机构
是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。
请求到证书后发现签发的，由于 “GlobalSign Root CA” “GlobalSign Organization Validation CA - SHA256 - G2” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会证书是由 “GlobalSign Root CA”
检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。 “GlobalSign
“GlobalSign Organization Validation CA - SHA256 - G2” Validation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书被信任后，可以使用证书的可信性，如果验证通过，就可以信任 “GlobalSign Organization
baidu.com 证书。
在这四个步骤中，最开始客户端只信任根证书“GlobalSign Organization Validation CA - SHA256 - G2” GlobalSign Root CA 证书，而 “GlobalSign Organization Validation CA -证书的，然后 “GlobalSign Root CA” 证书信任
SHA256 - G2” 证书又信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。
总括来说，由于用户信任作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign，所以由 GlobalSign GlobalSign 所担保的 baidu.com 都可被信任。可以被信任，另外由于用户信任操


#### 操作系统里一般都会内置一些根证书，比如我的 MAC 电脑里内置的根证书有这么多：


#### 这样的一层层地验证就构成了一条信任链路，整个证书信任链验证流程如下图所示：

最后一个问题，为什么需要证书链这么麻烦的流程？呢？ Root CA 为什么不直接颁发证书，而是要搞那么多中间层级

这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。

### TLS 第三次握手

客户端验证完证书后，认为可信则继续往下走。接着，客户端就会生成一个新的 **随机数 (** **_pre-master_** **)** ，用服务器
的 RSA 公钥加密该随机数，通过「 **Change Cipher Key Exchange** 」消息传给服务端。


服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。
至此， **客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master** 。
于是，双方根据已经得到的三个随机数，生成请求/响应的数据加解密。 **会话密钥（Master Secret）** ，它是对称密钥，用于对后续的 HTTP

生成完会话密钥后，然后客户端发一个「 **Change Cipher Spec** 」，告诉服务端开始使用加密方式发送消息。

然后，客户端再发一个「要，再用会话密钥（master secret **Encrypted Handshake Message** ）加密一下，让服务器做个验证，验证加密通信是否可用和之前握手信息是否有 **（Finishd）** 」消息，把之前所有发送的数据做个摘
被中途篡改过。

可以发现，「Change Cipher Spec」之前传输的 TLS 握手数据都是明文，之后都是对称密钥加密的密文。

### TLS 第四次握手

服务器也是同样的操作，发「验证加密和解密没问题，那么握手正式完成。 **Change Cipher Spec** 」和「 **Encrypted Handshake Message** 」消息，如果双方都

最后，就用「会话密钥」加解密 HTTP 请求和响应了。

## RSA 算法的缺陷^


#### 使用 一）给服务端时使用的是公钥加密的，服务端收到到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏 RSA 密钥协商算法的最大问题是不支持前向保密 。因为客户端传递随机数（用于生成对称加密密钥的条件之

#### 了，过去被第三方截获的所有 TLS 通讯密文都会被破解。

#### 为了解决这一问题，于是就有了 DH 密钥协商算法，这里简单介绍它的工作流程。

#### 客户端和服务端各自会生成随机数，并以此作为私钥，然后根据公开的握手双方交换各自的公钥，这样双方都有自己的私钥和对方的公钥，然后双方根据各自持有的材料算出一个随机 DH 计算公示算出各自的公钥，通过 TLS

#### 数，这个随机数的值双方都是一样的，这就可以作为后续对称加密时使用的密钥。

#### DH 密钥的，而且每一次对称加密密钥都是实时生成的，实现前向保密 密钥交换过程中， 即使第三方截获了 TLS 握手阶段传递的公钥，在不知道的私钥的情况下，也是无法计算出 。

#### 但因为钥协商算法，关于 DH 算法的计算效率问题，后面出现了 ECDHE 握手的过程，将在下一篇揭晓，尽情期待哦。 ECDHE 密钥协商算法，我们现在大多数网站使用的正是 ECDHE 密

## 最后^


#### 哈喽，我是小林，就爱图解计算机基础，如果文章对你有帮助，别忘记关注哦！

## 2.4 HTTPS ECDHE 握手解析

#### HTTPS 常用的密钥交换算法有两种，分别是 RSA 和 ECDHE 算法。

#### 其中，具有前向安全，所以被广泛使用。RSA 是比较传统的密钥交换算法，它不具备前向安全的性质，因此现在很少服务器使用的。而 ECDHE 算法

#### 我在上一篇已经介绍了 RSA 握手的过程，今天这一篇就「从理论再到实战抓包」介绍 ECDHE 算法 。


## 离散对数^

#### ECDHE 密钥协商算法是 DH 算法演进过来的，所以我们先从 DH 算法说起。

#### DH 算法是非对称加密算法， 因此它可以用于密钥交换，该算法的核心数学思想是 离散对数 。


#### 是不是听到这个数学概念就怂了？不怕，这次不会说离散对数推到的过程，只简单提一下它的数学公式。

#### 离散对数是「离散 + 对数」的两个数学概念的组合，所以我们先来复习一遍对数。

#### 要说起对数，必然要说指数，因为它们是互为反函数，指数就是幂运算，对数是指数的逆运算。

#### 举个栗子，如果以 2 作为底数，那么指数和对数运算公式，如下图所示：

#### 那么对于底数为 2 的时候， 32 的对数是 5 ， 64 的对数是 6 ，计算过程如下：

#### 对数运算的取值是可以连续的，而离散对数的取值是不能连续的，因此也以「离散」得名，

离散对数是在对数运算的基础上加了「模运算」，也就说取余数，对应编程语言的操作符是「表示。离散对数的概念如下图： %」，也可以用 mod


上图的，底数上面的公式计算出真数。但反过来，知道真数却很难推算出对数。 a 和模数 p 是离散对数的公共参数，也就说是公开的，b 是真数，i 是对数。知道了对数，就可以用

**特别是当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算水平是几乎无法算出离散
对数的，这就是 DH 算法的数学基础。**

## DH 算法^

#### 认识了离散对数，我们来看看 DH 算法是如何密钥交换的。

#### 现假设小红和小明约定使用的参数，这两个参数是公开的，用 DH 算法来交换密钥，那么基于离散对数，小红和小明需要先确定模数和底数作为算法 P 和 G 来代称。

然后小红和小明各自生成一个随机整数作为小明的私钥用 b 代称。 **私钥** ，双方的私钥要各自严格保管，不能泄漏，小红的私钥用 a 代称，

现在小红和小明双方都有了 P 和 G 以及各自的私钥，于是就可以计算出 **公钥** ：
小红的公钥记作 A，A = G ^ a ( mod P )；
小明的公钥记作 B，B = G ^ b ( mod P )；
A 计算机的计算能力是无法破解的，如果量子计算机出来了，那就有可能被破解，当然如果量子计算机真的出来了，和 B 也是公开的，因为根据离散对数的原理，从真数（A 和 B）反向计算对数 a 和 b 是非常困难的，至少在现有
那么密钥协商算法就要做大的升级了。
双方交换各自A。 DH 公钥后，小红手上共有 5 个数：P、G、a、A、B，小明手上也同样共有 5 个数：P、G、b、B、

然后小红执行运算：mod P )，得到的结果也是 B ^ a ( mod P ) K。 ，其结果为 K，因为离散对数的幂运算有交换律，所以小明执行运算： A ^ b (


#### 这个 K 就是小红和小明之间用的 对称加密密钥 ，可以作为会话密钥使用。

可以看到，整个密钥协商过程中，小红和小明公开了是公钥，而 a、b 是双方各自保管的私钥，黑客无法获取这 4 个信息： 2 个私钥，因此黑客只能从公开的P、G、A、B，其中 P、G 是算法的参数， P、G、A、B A 入手，和 B
计算出离散对数（私钥）。
前面也多次强调，的，破解不出私钥，也就无法计算出会话密钥，因此 根据离散对数的原理，如果 P 是一个大数，在现有的计算机的计算能力是很难破解出 DH 密钥交换是安全的。 私钥 a、b

## DHE 算法^

#### 根据私钥生成的方式，DH 算法分为两种实现：

static DH 算法，这个是已经被废弃了；
DHE 算法，现在常用的；
static DH 固定，即 a 算法里有一方的私钥是静态的，也就说每次密钥协商的时候有一方的私钥都是一样的，一般是服务器方不变，客户端的私钥则是随机生成的。

于是，量的密钥协商过程的数据，因为密钥协商的过程有些数据是公开的，黑客就可以依据这些数据暴力破解出服务器的DH 交换密钥时就只有客户端的公钥是变化，而服务端公钥是不变的，那么随着时间延⻓，黑客就会截获海
私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解，所以 **性** 。 **static DH 算法不具备前向安全**

既然固定一方的私钥有被破解的⻛险，那么干脆就让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。


#### 所以，即使有个牛逼的黑客破解了某一次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为 的私钥都是没有任何关系的，都是独立的，这样就保证了「前向安全」 。 每个通信过程

## ECDHE 算法^

#### DHE 钥交换算法算法由于计算性能不佳，因为需要做大量的乘法，为了提升 —— ECDHE 算法 。 DHE 算法的性能，所以就出现了现在广泛用于密

#### ECDHE 话密钥。算法是在 DHE 算法的基础上利用了 ECC 椭圆曲线特性，可以用更少的计算量计算出公钥，以及最终的会

#### 小红和小明使用 ECDHE 密钥交换算法的过程：

#### 双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；

双方各自随机生成一个随机数作为和 d1，小明的公私钥为 Q2 和 d2； **私钥d** ，并与基点 G相乘得到 **公钥Q** （Q = dG），此时小红的公私钥为 Q1
双方交换各自的公钥，最后小红计算点（上是可以满足乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 x1，y1） = d1Q2，小明计算点（，因此x2，y2 **双方的** ） = d2Q1 **x 坐标是一样的，所** ，由于椭圆曲线
**以它是共享密钥，也就是会话密钥** 。
这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点G）也是很难计算出椭圆曲线上的离散对数（私钥）。

## ECDHE 握手过程^

#### 知道了 ECDHE 算法基本原理后，我们就结合实际的情况来看看。

我用 Wireshark 工具抓了用 ECDHE 密钥协商算法的 TSL 握手过程，可以看到是四次握手：


#### 细心的小伙伴应该发现了，对于 RSA 握手过程，必须要完成 使用了 TLS ECDHE 四次握手，才能传输应用数据。 ，在 TLS 第四次握手前，客户端就已经发送了加密的 HTTP 数据 ，而

所以， _False Start_ **ECDHE** 」，跟「 **相比 RSA** _TCP Fast Open_ **握手过程省去了一个消息往返的时间** 」有点像，都是在还没连接完全建立前，就发送了应用数据，这样便提高了传，这个有点「抢跑」的意思，它被称为是「 _TLS_
输的效率。
接下来，分析每一个 ECDHE 握手过程。

### TLS 第一次握手

客户端首先会发一个「成的 **随机数（** **_Client Random_** **Client Hello）** 。」消息，消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生

### TLS 第二次握手

服务端收到客户端的「打招呼」，同样也要回礼，会返回「号，也给出了一个 **随机数（** **_Server Random_** **）** ，然后从客户端的密码套件列表选择了一个合适的密码套件。 **Server Hello** 」消息，消息面有服务器确认的 TLS 版本


#### 不过，这次选择的密码套件就和 RSA 不一样了，我们来分析一下这次的密码套件的意思。

#### 「 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384」

#### 密钥协商算法使用 ECDHE；

#### 签名算法使用 RSA；

#### 握手后的通信使用 AES 对称算法，密钥⻓度 256 位，分组模式是 GCM；

#### 摘要算法使用 SHA384；

接着，服务端为了证明自己的身份，发送「 **Certificate** 」消息，会把证书也发给客户端。

#### 这一步就和 RSA 握手过程有很大到区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，

发送「 **Server Key Exchange** 」消息。


#### 这个过程服务器做了三件事：

选择了客户端； **名为 named_curve 的椭圆曲线** ，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给
生成随机数作为服务端椭圆曲线的私钥，保留到本地；
根据基点 G 和私钥计算出 **服务端的椭圆曲线公钥** ，这个会公开给客户端。
为了保证这个椭圆曲线的公钥不被第三方篡改，服务端会用 RSA 签名算法给服务端的椭圆曲线公钥做个签名。
随后，就是「 **Server Hello Done** 」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。

至此， **Random** TLS **、使用的椭圆曲线、椭圆曲线基点** 两次握手就已经完成了，目前客户端和服务端通过明文共享了这几个信息： **G、服务端椭圆曲线的公钥** ，这几个信息很重要，是后续生成会话密 **Client Random、Server**
钥的材料。

### TLS 第三次握手

#### 客户端收到了服务端的证书后，自然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。校验证书到过程，会走证书链逐级验证，确认证书的真实性，再用证书的公钥验证签名，这样就能确认服务端的身份

#### 了，确认无误后，就可以继续往下走。

客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，生成 **钥** ，然后用「 **Client Key Exchange** 」消息发给服务端。 **客户端的椭圆曲线公**


至此，双方都有对方的椭圆曲线公钥、自己的椭圆曲线私钥、椭圆曲线基点y），其中 x 坐标值双方都是一样的，前面说 ECDHE 算法时候，说 x 是会话密钥， G。于是，双方都就计算出点（ **但实际应用中，x 还不是最终** x，
**的会话密钥** 。
还记得 TLS 握手阶段，客户端和服务端都会生成了一个随机数传递给对方吗？
**最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成
的** 。
之所以这么麻烦，是因为把三个不可靠的随机数混合起来，那么「随机」的程度就非常高了，足够让黑客计算出最终的会话密钥，安全性更 TLS 设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，
高。
算好会话密钥后，客户端会发一个「 **Change Cipher Spec** 」消息，告诉服务端后续改用对称算法加密通信。

接着，客户端会发「一下，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用。 **Encrypted Handshake Message** 」消息，把之前发送的数据做一个摘要，再用对称密钥加密

### TLS 第四次握手

最后，服务端也会有一个同样的操作，发「息，如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 **Change Cipher Spec** 」和「 **Encrypted Handshake Message** HTTP 请求和响应了。」消


## 总结^

#### RSA 和 ECDHE 握手过程的区别：

#### RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；

#### 使用了以不用等服务端的最后一次 RSA 密钥协商算法， TLS TLS 握手，就可以提前发出加密的完成四次握手后，才能进行应用数据传输，而对于 HTTP 数据，节省了一个消息的往返时间； ECDHE 算法，客户端可

```
使用过程没有该消息； ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手
```
参考资料：

1. https://zh.wikipedia.org/wiki/橢圓曲線迪菲-赫爾曼金鑰交換
2. https://zh.wikipedia.org/wiki/椭圆曲线
3. https://zh.wikipedia.org/wiki/迪菲-赫爾曼密鑰交換
4. https://time.geekbang.org/column/article/148188
5. https://zhuanlan.zhihu.com/p/106967180

## 最后^

#### 哈喽，我是小林，就爱图解计算机基础，如果文章对你有帮助，别忘记关注哦！


## 2.5 HTTPS 如何优化？

#### 由裸数据传输的也带来了性能消耗。 HTTP 协议转成加密数据传输的 HTTPS 协议，给应用数据套了个「保护伞」，提高安全性的同时

#### 因为 密钥 HTTPS ，这个过程最⻓可以花费掉相比 HTTP 协议多一个 2 RTT TLS ，接着后续传输的应用数据都得使用对称加密密钥来加密协议握手过程， 目的是为了通过非对称加密握手协商或者交换出对称加密 /解密。

#### 为了数据的安全性，我们不得不使用HTTPS 的优化是非常重要的。 HTTPS 协议，至今大部分网址都已从 HTTP 迁移至 HTTPS 协议，因此针对

#### 这次，就从多个⻆度来优化 HTTPS。


## 分析性能损耗^

#### 既然要对 HTTPS 优化，那得清楚哪些步骤会产生性能消耗，再对症下药。


#### 产生性能消耗的两个环节：

#### 第一个环节， TLS 协议握手过程；

#### 第二个环节，握手后的对称加密报文传输。

对于第二环节，现在主流的对称加密算法硬件级别的优化，因此这个环节的性能消耗可以说非常地小。 AES、ChaCha20 性能都是不错的，而且一些 CPU 厂商还针对它们做了

而第一个环节，会产生性能损耗，比如：TLS 协议握手过程不仅增加了网络延时（最⻓可以花费掉 2 RTT），而且握手过程中的一些步骤也

对于 ECDHE 密钥协商算法，握手过程中会客户端和服务端都需要临时生成椭圆曲线公私钥；
客户端验证证书时，会访问 CA 获取 CRL 或者 OCSP，目的是验证服务器的证书是否有被吊销；
双方计算 Pre-Master，也就是对称加密密钥；
为了大家更清楚这些步骤在 TLS 协议握手的哪一个阶段，我画出了这幅图：


## 硬件优化^

#### 玩游戏时，如果我们怎么都战胜不了对方，那么有一个最有效、最快的方式来变强，那就是「充钱」，如果还是不行，那说明你充的钱还不够多。


#### 对于计算机里也是一样，软件都是跑在物理硬件上，硬件越牛逼，软件跑的也越快，所以如果要优化化，最直接的方式就是花钱买性能参数更牛逼的硬件。 HTTPS 优

#### 但是花钱也要花对方向，应该花在 CPU 上。 HTTPS 协议是计算密集型，而不是 I/O 密集型 ，所以不能把钱花在网卡、硬盘等地方，

#### 一个好的TLS 握手过程。 CPU，可以提高计算性能，因为 HTTPS 连接过程中就有大量需要计算密钥的过程，所以这样可以加速

#### 另外，如果可以，应该选择可以法，这样便加速了数据的加解密传输过程。 支持 AES-NI 特性的 CPU ，因为这种款式的 CPU 能在指令级别优化了 AES 算

如果你的服务器是 Linux 系统，那么你可以使用下面这行命令查看 CPU 是否支持 AES-NI 指令集：


如果我们的加密算法，因为 CPU ChaCha20 支持 AES-NI 算法的运算指令相比特性，那么对于对称加密的算法应该选择 AES 算法会对 CPU 更友好一点。 AES 算法。否则可以选择 ChaCha20 对称

## 软件优化^

#### 如果公司预算充足对于新的服务器是可以考虑购买更好的可能就不太适合了，于是就要从软件的方向来优化了。 CPU，但是对于已经在使用的服务器，硬件优化的方式

#### 软件的优化方向可以分层两种，一个是 软件升级 ，一个是 协议优化 。

#### 先说第一个软件升级，软件升级就是将正在使用的软件升级到最新版本，因为最新版本不仅提供了最新的特性，也优化了以前软件的问题或性能。比如：

将 Linux 内核从 2.x 升级到 4.x；
将 OpenSSL 从 1.0.1 升级到 1.1.1；
...
看似简单的软件升级，对于有成百上千服务器的公司来说，软件升级也跟硬件升级同样是一个棘手的问题，因为要实行软件升级，会花费时间和人力，同时也存在一定的⻛险，也可能会影响正常的线上服务。

既然如此，我们把目光放到协议优化，也就是在现有的环节下，通过较小的改动，来进行优化。

## 协议优化^

#### 协议的优化就是对「密钥交换过程」进行优化。


### 密钥交换算法优化

#### TLS 1.2 传输，而且版本如果使用的是 RSA 密钥交换算法不具备前向安全性。 RSA 密钥交换算法，那么需要 4 次握手，也就是要花费 2 RTT，才可以进行应用数据的

#### 总之使用 RSA 密钥交换算法的 TLS 握手过程，不仅慢，而且安全性也不高 。

因此如果可以，尽量的意思，客户端可以在 **选用** TLS **ECDHE** 协议的第 **密钥交换** 3 次握手后，第算法替换 RSA 4 次握手前，发送加密的应用数据，以此将算法，因为该算法由于支持「False Start **TLS** 」，它是 **握手的消息** “抢跑”
**往返由 2 RTT 减少到 1 RTT，而且安全性也高，具备前向安全性** 。
ECDHE 快的椭圆曲线。算法是基于椭圆曲线实现的，不同的椭圆曲线性能也不同，应该尽量 **选择 x25519 曲线** ，该曲线是目前最

比如在 Nginx 上，可以使用 ssl_ecdh_curve 指令配置想使用的椭圆曲线，把优先使用的放在前面：

#### 对于对称加密算法方面，如果对安全性不是特别高的要求，可以些，因为密钥的⻓度短一些。 选用 AES_128_GCM ，它比 AES_256_GCM 快一

比如在且把性能最快最安全的算法放在最前面： Nginx 上，可以使用 ssl_ciphers 指令配置想使用的非对称加密算法和对称加密算法，也就是密钥套件，而


### TLS 升级

#### 当然，如果可以，直接把 RTT ，而且安全性更高。 TLS 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤， 完成 TLS 握手只要 1

在手） TLS 1.2 消息协商出后续使用的加密算法，再互相交换公钥（第的握手中，一般是需要 4 次握手，先要通过 Client Hello 3 和 第 4 （第次握手），然后计算出最终的会话密钥，下 1 次握手）和 Server Hello（第 2 次握
图的左边部分就是 TLS 1.2 的握手过程：

上图的右边部分就是 **于是这样就减少到只需** TLS 1.3 **1 RTT** 的握手过程，可以发现 **就能完成 TLS 握手** 。 **TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，**

怎么合并的呢？具体的做法是，客户端在钥。 Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公

服务端收到后，选定一个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这已经有生成会话密钥的材料了，于是客户端计算出会话密钥，就可以进行应用数据的加密传输了。 1 个 RTT，双方手上

而且， **对于密钥交换算法，废除了不支持前向安全性的** TLS1.3 对密码套件进行“减肥”了， **RSA 和 DH 算法，只支持 ECDHE 算法** 。

对于对称加密和签名算法，只支持目前最安全的几个密码套件，比如 openssl 中仅支持下面 5 种密码套件：


#### TLS_AES_256_GCM_SHA384

#### TLS_CHACHA20_POLY1305_SHA256

#### TLS_AES_128_GCM_SHA256

#### TLS_AES_128_CCM_8_SHA256

#### TLS_AES_128_CCM_SHA256

之所以用降级攻击，伪造客户端的 TLS1.3 仅支持这么少的密码套件，是因为 Client Hello 消息，替换客户端支持的密码套件为一些不安全的密码套件，使得服务器 TLS1.2 由于支持各种古老且不安全的密码套件，中间人可以利
被迫使用这个密码套件进行 HTTPS 连接，从而破解密文。

## 证书优化^

#### 为了验证的服务器的身份，服务器会在的。 TSL 握手过程中，把自己的证书发给客户端，以此证明自己身份是可信

#### 对于证书的优化，可以有两个方向：

#### 一个是 证书传输 ，

#### 一个是 证书验证 ；

### 证书传输优化

#### 要让证书更便于传输，那必然是减少证书的大小，这样可以节约带宽，也能减少客户端的运算量。所以， 器的证书应该选择椭圆曲线（ECDSA）证书，而不是 RSA 证书，因为在相同安全强度下， ECC 密钥⻓度比对于服务 RSA

#### 短的多 。

### 证书验证优化

#### 客户端在验证证书时，是个复杂的过程，会走证书链逐级验证，验证的过程不仅需要「用「用签名算法验证证书的完整性」，而且为了知道证书是否被 CA 吊销，客户端有时还会再去访问 CA 公钥解密证书」以及 CA， 下载 CRL

#### 或者 OCSP 数据，以此确认证书的有效性。

#### 这个访问过程是 HTTP 访问，因此又会产生一系列网络通信的开销，如 DNS 查询、建立连接、收发数据等。

#### CRL

CRL 证书序号，如果服务器的证书在此列表，就认为证书已经失效，不在的话，则认为证书是有效的。称为证书吊销列表（ _Certificate Revocation List_ ），这个列表是由 CA 定期更新，列表内容都是被撤销信任的


#### 但是 CRL 存在两个问题：

#### 第一个问题，由于 CRL 列表是由 CA 维护的，定期更新，如果一个证书刚被吊销后，客户端在更新 CRL 之

#### 前还是会信任这个证书， 实时性较差 ；

#### 第二个问题，的列表，那么就会导致客户端在校验证书这一环节的延时很大，进而拖慢了 随着吊销证书的增多，列表会越来越大，下载的速度就会越慢 ，下载完客户端还得遍历这么大 HTTPS 连接。

#### OCSP

因此，现在基本都是使用性，它的工作方式是 **向 CA** OCSP **发送查询请求，让** ，名为在线证书状态协议（ **CA 返回证书的有效状态** _Online Certificate Status Protocol_ 。 ）来查询证书的有效


#### 不必像决了 CRL CRL 的实时性问题。方式客户端需要下载大大的列表，还要从列表查询，同时因为可以实时查询每一张证书的有效性，解

#### OCSP CA 服务器繁忙，也会导致客户端在校验证书这一环节的延时变大。需要向 CA 查询，因此也是要发生网络请求，而且还得看 CA 服务器的“脸色”，如果网络状态不好，或者

**OCSP Stapling**
于是为了解决这一个网络开销，就出现了一个带有时间戳和签名的响应结果并缓存它。 OCSP Stapling，其原理是：服务器向 CA 周期性地查询证书状态，获得


#### 当有客户端发起连接请求时，服务器会把这个「响应结果」在服务器无法篡改，因此客户端就能得知证书是否已被吊销了，这样客户端就不需要再去查询。 TLS 握手过程中发给客户端。由于有签名的存在，

## 会话复用^

#### TLS 密密钥缓存起来，待下次需要建立握手的目的就是为了协商出会话密钥，也就是对称加密密钥，那我们如果我们把首次 HTTPS 连接时，直接「复用」这个密钥，不就减少 TLS TLS 握手的性能损耗了吗？握手协商的对称加

这种方式就是 **会话复用** （ _TLS session resumption_ ），会话复用分两种：
第一种叫 Session ID；
第二种叫 Session Ticket；

### Session ID

Session ID **Session ID** 的工作原理是， **来标识** ，Session ID **客户端和服务器首次** 和会话密钥相当于 **TLS** key-value **握手连接后，双方会在内存缓存会话密钥，并用唯一的** 的关系。

当客户端再次连接时，钥恢复会话状态，跳过其余的过程，只用一个消息往返就可以建立安全通信。当然为了安全性，内存中的会话密钥hello 消息里会带上 Session ID，服务器收到后就会从内存找，如果找到就直接用该会话密
会定期失效。


#### 但是它有两个缺点：

#### 服务器必须保持每一个客户端的会话密钥，随着客户端的增多， 服务器的内存压力也会越大 。

#### 现在网站服务一般是由多台服务器通过负载均衡提供服务的， 务器 ，于是还要走完整的 TLS 握手过程； 客户端再次连接不一定会命中上次访问过的服

### Session Ticket

为了解决 **作交给了客户端** Session ID ，类似于的问题，就出现了 HTTP 的 Cookie Session Ticket。 ， **服务器不再缓存每个客户端的会话密钥，而是把缓存的工**

客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。
客户端再次连接服务器时，客户端会发送如果没问题，就可以恢复会话了，开始加密通信。 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，


对于集群服务器的话，台服务器时，都能恢复会话。 **要确保每台服务器加密 「会话密钥」的密钥是一致的** ，这样客户端携带 Ticket 访问任意一

Session ID 话密钥」，前面劫持的通信密文都会被破解。和 Session Ticket **都不具备前向安全性** ，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会

同时应对 **重放攻击** 也很困难，这里简单介绍下重放攻击工作的原理。

假设如哈希函数的转换之后）。与此同时， Alice 想向 Bob 证明自己的身份。Eve Bob 窃听了对话并保留了密码（或哈希）。要求 Alice 的密码作为身份证明，爱丽丝应尽全力提供（可能是在经过

交换结束后，读取的 Alice 的密码（或哈希），从而授予Eve（冒充 Alice ）连接到 Bob Eve 。当被要求提供身份证明时，访问权限。 Eve 发送从 Bob 接受的最后一个会话中

重放攻击的危险之处在于，如果中间人截获了某个客户端的般 POST 请求会改变数据库的数据，中间人就可以利用此截获的报文，不断向服务器发送该报文，这样就会导致数 Session ID 或 Session Ticket 以及 POST 报文，而一
据库的数据被中间人改变了，而客户是不知情的。
避免重放攻击的方式就是需要 **对会话密钥设定一个合理的过期时间** 。


### Pre-shared Key

前面的 Session ID 和 Session Ticket 方式都需要在 1 RTT 才能恢复会话。
而和 TLS1.3 HTTP 请求一同发送给服务端，这种方式叫更为牛逼，对于重连 TLS1.3 只需要 **Pre-shared Key 0 RTT** ，原理和。 Ticket 类似，只不过在重连时，客户端会把 Ticket

同样的，Pre-shared Key 也有重放攻击的危险。


#### 如上图，假设中间人通过某种方式，截获了客户端使用会话重用技术的据库的数据，然后中间人就可以把截获的这个报文发送给服务器，服务器收到后，也认为是合法的，于是就恢复会 POST 请求，通常 POST 请求是会改变数

#### 话，致使数据库的数据又被更改，但是此时用户是不知情的。

#### 所以，应对重放攻击可以给会话密钥设定一个合理的过期时间，以及只针对安全的会话重用。 HTTP 请求如 GET/HEAD 使用

## 总结^

#### 对于硬件优化的方向，因为 特性的 CPU ，这个特性可以在硬件级别优化 HTTPS 是属于计算密集型，应该选择计算力更强的 AES 对称加密算法，加快应用数据的加解密。 CPU，而且最好选择 支持 AES-NI

对于软件优化的方向，如果可以，把软件升级成较新的版本，比如将升级到 1.1.1，因为新版本的软件不仅会提供新的特性，而且还会修复老版本的问题。 Linux 内核 2.X 升级成 4.X，将 openssl 1.0.1

对于协议优化的方向：
密钥交换算法应该选择以在第三次握手之后，就发送加密应用数据，节省了 **ECDHE 算法** ，而不用 RSA 算法，因为 1 RTT。 ECDHE 算法具备前向安全性，而且客户端可
将 TSL1.2 升级 **TSL1.3** ，因为 TSL1.3 的握手过程只需要 1 RTT，而且安全性更强。
对于证书优化的方向：
服务器应该选用这样可以提高证书传输的效率； **ECDSA 证书** ，而非 RSA 证书，因为在相同安全级别下，ECC 的密钥⻓度比 RSA 短很多，
服务器应该开启TLS 握手的时候就不用再访问 **OCSP Stapling** CA 功能，由服务器预先获得服务器，减少了网络通信的开销，提高了证书验证的效率； OCSP 的响应，并把响应结果缓存起来，这样


#### 对于重连复会话，而不用再重新走完整的 HTTPS 时，我们可以使用一些技术让客户端和服务端使用上一次 TLS 握手过程。 HTTPS 连接使用的会话密钥，直接恢

常⻅的就可以恢复会话。对于 **会话重用** 技术有 Session ID TLS1.3 使用和 Pre-shared Key Session Ticket，用了会话重用技术，当再次重连会话重用技术，只需要 0 RTT 就可以恢复会话。 HTTPS 时，只需要 1 RTT

这些会话重用技术虽然好用，但是存在一定的安全⻛险，它们不仅不具备前向安全，而且有重放攻击的⻛险，所以应当对会话密钥设定一个合理的过期时间。

#### 参考资料：

1. [http://www.doc88.com/p-8621583210895.html](http://www.doc88.com/p-8621583210895.html)
2. https://zhuanlan.zhihu.com/p/33685085
3. https://en.wikipedia.org/wiki/Replay_attack
4. https://en.wikipedia.org/wiki/Downgrade_attack
5. https://www.cnblogs.com/racent-Z/p/14011056.html
6. [http://www.guoyanbin.com/a-detailed-look-at-rfc-8446-a-k-a-tls-1-3/](http://www.guoyanbin.com/a-detailed-look-at-rfc-8446-a-k-a-tls-1-3/)
7. https://www.thesslstore.com/blog/crl-explained-what-is-a-certificate-revocation-list/

## 最后^

#### 哈喽，我是小林，就爱图解计算机基础，如果文章对你有帮助，别忘记关注哦！


## 2.6 HTTP/2 牛逼在哪？

#### 不多 BB 了，直接发⻋！

#### 一起来看看 HTTP/2 牛逼在哪？


## HTTP/1.1 协议的性能问题^

#### 我们得先要了解下 HTTP/1.1 协议存在的性能问题，因为 HTTP/2 协议就是把这些性能问题逐个攻破了。

#### 现在的站点相比以前变化太多了，比如：

#### 消息的大小变大了，从几 KB 大小的消息，到几 MB 大小的消息；

#### ⻚面资源变多了，从每个⻚面不到 10 个的资源，到每⻚超 100 多个资源；

#### 内容形式变多样了，从单纯到文本内容，到图片、视频、音频等内容；

#### 实时性要求变高了，对⻚面的实时性要求的应用越来越多；

#### 这些变化带来的最大性能问题就是 HTTP/1.1 的高延迟 ，延迟高必然影响的就是用户体验。主要原因如下几个：

#### 延迟难以下降白了就是到达了延迟的下限；，虽然现在网络的「带宽」相比以前变多了，但是延迟降到一定幅度后，就很难再下降了，说

#### 并发连接有限TCP 慢启动过程给流量带来的影响；，谷歌浏览器最大并发连接数是 6 个，而且每一个连接都要经过 TCP 和 TLS 握手耗时，以及

#### 队头阻塞问题，同一连接只能在完成一个 HTTP 事务（请求和响应）后，才能处理下一个事务；

```
HTTP cookie 头部巨大且重复的头部，而 cookie ，由于的大小通常很大； HTTP 协议是无状态的，每一个请求都得携带 HTTP 头部，特别是对于有携带
不支持服务器推送消息了带宽和服务器资源。，因此当客户端需要获取通知时，只能通过定时器不断地拉取消息，这无疑浪费大量
```
为了解决 HTTP/1.1 性能问题，具体的优化手段你可以看这篇文章「」，这里我举例几个常⻅的优化手段：
将多张小图合并成一张大图供浏览器来了新的问题，当某张小图片更新了，那么需要重新请求大图片，浪费了大量的网络带宽； JavaScript 来切割使用，这样可以将多个请求合并成一个请求，但是带
将图片的二进制数据通过次数； base64 编码后，把编码数据嵌入到 HTML 或 CSS 文件中，以此来减少网络请求
将多个体积较小的求替代了很多个请求，但是带来的问题，当某个 JavaScript 文件使用 webpack js 等工具打包成一个体积更大的文件变化了，需要重新请求同一个包里的所有 JavaScript 文件，以一个请 js 文件；
将同一个⻚面的资源分散到不同域名，提升并发连接上限，因为浏览器通常对同一域名的能是 6 个； HTTP 连接最大只

尽管对 HTTP/1.1 协议的优化手段如此之多，但是效果还是不尽人意，因为这些手段都是对 HTTP/1.1 协议的“外
部 **能主动推送等，要改变这些必须重新设计** ”做优化， **而一些关键的地方是没办法优化的，比如请求 HTTP 协议，于是-响应模型、头部巨大且重复、并发连接耗时、服务器不 HTTP/2 就出来了！**

## 兼容 HTTP/1.1^

#### HTTP/2 协议推广起来就相当困难，所幸出来的目的是为了改善 HTTP HTTP/2 的性能。协议升级有一个很重要的地方，就是要做到了兼容 HTTP/1.1 。 兼容 老版本的协议，否则新


#### 那么，HTTP/2 是怎么做的呢？

第一点，于是只需要浏览器和服务器在背后自动升级协议，这样可以让用户意识不到协议的升级，很好的实现了协议的平滑HTTP/2 没有在 URI 里引入新的协议名，仍然用「http://」表示明文协议，用「https://」表示加密协议，
升级。

第二点，只在应用层做了改变，还是基于解成了「语义」和「语法」两个部分，「语义」层不做改动，与 TCP 协议传输，应用层方面为了保持功能上的兼容， HTTP/1.1 完全一致，比如请求方法、状态码、头HTTP/2 把 HTTP 分
字段等规则保留不变。
但是，HTTP/2 在「语法」层面做了很多改造，基本改变了 HTTP 报文的传输格式。

## 头部压缩^

HTTP Encoding协议的报文是由「」指定 Body 的压缩方式，比如用Header + Body」构成的，对于 gzip 压缩，这样可以节约带宽，但报文中的另外一部分 Body 部分，HTTP/1.1 协议可以使用头字段 Header 「Content-，是没
有针对它的优化手段。
HTTP/1.1 报文中 Header 部分存在的问题：
含很多固定的字段，比如所以有必要 **压缩** ； Cookie、User Agent、Accept 等，这些字段加起来也高达几百字节甚至上千字节，
大量的请求和响应的报文里有很多字段值都是重复的，这样会使得大量带宽被这些冗余的数据占用了，所以
有必须要 **避免重复性** ；
字段是 ASCII 编码的，虽然易于人类观察，但效率低，所以有必要改成 **二进制编码** ；
HTTP/2 对 Header 部分做了大改造，把以上的问题都解决了。
HTTP/2 分： 没使用常⻅的 gzip 压缩方式来压缩头部，而是开发了 **HPACK** 算法，HPACK 算法主要包含三个组成部

静态字典；
动态字典；
Huffman 编码（压缩算法）；
客户端和服务器两端都会建立和维护「数据， **可达到 50%~90% 的高压缩率** 。 **字典** 」，用⻓度较小的索引号表示重复的字符串，再用 Huffman 编码压缩


### 静态表编码

#### HTTP/2 表里共有为高频出现在头部的字符串和字段建立了一张 61 组，如下图： 静态表 ，它是写入到 HTTP/2 框架里的，不会变化的，静态


表中的如 Index Index为 2 代表 表示索引（ GET，Index Key），为 8 Header Value代表状态码 200 表示索引对应的。 Value，Header Name 表示字段的名字，比


你可能注意到，表中有的Value 都会经过 Huffman Index 编码后，才会发送出去。没有对应的 Header Value，这是因为这些 Value 并不是固定的而是变化的，这些

这么说有点抽象，我们来看个具体的例子，下面这个 server 头部字段，在 HTTP/1.1 的形式如下：

算上冒号空格和末尾的 **率大概 47 %** 。 \r\n，共占用了 17 字节， **而使用了静态表和 Huffman 编码，可以将它压缩成 8 字节，压缩**

我抓了个server HTTP/2 头部数据。协议的网络包，你可以从下图看到，高亮部分就是 server 头部字段，只用了 8 个字节来表示

根据 01 RFC7541 ，所以整个头部格式如下图：规范，如果头部字段属于静态表范围，并且 Value 是变化，那么它的 HTTP/2 头部前 2 位固定为

HTTP/2 Length）来分割头部由于基于 Index **二进制编码** 和 Value。，就不需要冒号空格和末尾的\r\n作为分隔符，于是改用表示字符串⻓度（Value

接下来，根据这个头部格式来分析上面抓包的 server 头部的二进制数据。

```
server: nghttpx\r\n
```

首先，从静态表中能查到字节就是 01110110 ，这正是上面抓包标注的红色部分的二进制数据。 server 头部字段的 Index 为 54 ，二进制为 110110 ，再加上固定 01 ，头部格式第 1 个

然后，第二个字节的首个比特位表示子的第二个字节为 10000110 ，首位比特位为 Value 是否经过 1 就代表 Huffman Value 编码，剩余的字符串是经过 (^7) Huffman 位表示 Value 编码的，经过的⻓度，比如这次例 Huffman 编
码的 Value ⻓度为 6 。
最后，字符串「较短」的编码表示，从而缩减字符串⻓度。 nghttpx 经过 Huffman 编码后压缩成了 6 个字节，Huffman 编码的原理是将高频出现的信息用
于是，在统计大量的RFC7541 文档找到这张 HTTP **静态** 头部后， **Huffman** HTTP/2 **表** ，我就不把表的全部内容列出来了，我只列出字符串根据出现频率将 ASCII 码编码为了 Huffman 编码表，可以在 nghttpx 中每个字
符对应的 Huffman 编码，如下图：
通过查表后，字符串同的颜色将他们对应起来了，最后的 nghttpx 的 Huffman 7 位是补位的。编码在下图看到，共 6 个字节，每一个字符的 Huffman 编码，我用相
最终，server 头部的二进制数据对应的静态头部格式如下：


### 动态表编码

静态表只包含了Index 从 62 起步，会在编码解码的时候随时更新。 61 种高频出现在头部的字符串，不在静态表范围内的头部字符串就要自行构建 **动态表** ，它的

比如，第一次发送时头部中的「和服务器双方都会更新自己的动态表，添加一个新的user-agent 」字段数据有上百个字节，经过 Index 号 62 。 **那么在下一次发送的时候，就不用重复发这个** Huffman 编码发送出去后，客户端
**字段的数据了，只用发 1 个字节的 Index 号就好了，因为双方都可以根据自己的动态表获取到字段的数据** 。
所以，使得动态表生效有一个前提：接上只发送了 1 次，或者重复传输时，字段总是略有变化，动态表就无法被充分利用了。 **必须同一个连接上，重复传输完全相同的 HTTP 头部** 。如果消息字段在 1 个连

因此，随着在同一最终每个头部字段都会变成 HTTP/2 连接上发送的报文越来越多，客户端和服务器双方的「字典」积累的越来越多，理论上 1 个字节的 Index，这样便避免了大量的冗余数据的传输，大大节约了带宽。


理想很美好，现实很⻣感。动态表越大，占用的内存也就越大，如果占用了太多内存，是会影响服务器性能的，因此 Web 服务器都会提供类似 http2_max_requests 的配置，用于限制一个连接上能够传输的请求数量，避免动态
表无限增大，请求数量到达上限后，就会关闭 HTTP/2 连接来释放内存。
综上，HTTP/2 头部的编码通过「静态表、动态表、Huffman 编码」共同完成的。

## 二进制帧^

#### HTTP/2 制数据使用位运算能高效解析。厉害的地方在于将 HTTP/1 的文本格式改成二进制格式传输数据，极大提高了 HTTP 传输效率，而且二进

#### 你可以从下图看到，HTTP/1.1 的响应 和 HTTP/2 的区别：

HTTP/2 也就是说一条把响应报文划分成了两个 HTTP 响应，划分成了两个帧来传输，并且采用二进制来编码。 **帧（** **_Frame_** **）** ，图中的 HEADERS（首部）和 DATA（消息负载） 是帧的类型，


#### HTTP/2 二进制帧 的结构如下图：

帧头（Fream Header）很小，只有 9 个字节，帧开头的前 3 个字节表示帧数据（Fream Playload）的 **⻓度** 。
帧⻓度后面的一个字节是表示下表格： **帧的类型** ，HTTP/2 总共定义了 10 种类型的帧，一般分为 **数据帧** 和 **控制帧** 两类，如

#### 帧类型后面的一个字节是 标志位 ，可以保存 8 个标志位，用于携带简单的控制信息，比如：


**END_HEADERS** 表示头数据结束标志，相当于 HTTP/1 里头后的空行（“\r\n”）；
**END_STREAM** 表示单方向数据发送结束，后续不会再有数据帧。
**PRIORITY** 表示流的优先级；
帧头的最后值是 2^31，大约是 4 个字节是 21 **流标识符** 亿，它的作用是用来标识该（Stream ID），但最高位被保留不用，只有 Fream 属于哪个 Stream，接收方可以根据这个信息从乱序的帧 31 位可以使用，因此流标识符的最大
里找到相同 Stream ID 的帧，从而有序组装信息。
最后面就是 **帧数据** 了，它存放的是通过 **HPACK 算法** 压缩过的 HTTP 头部和包体。

## 并发传输^

#### 知道了 HTTP/2 的帧结构后，我们再来看看它是如何实现 并发传输 的。

#### 我们都知道处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能

#### 的请求是无法发送的，也造成了 队头阻塞 的问题。

而HTTP/1.1 HTTP/2 队头阻塞的问题，提高了就很牛逼了，通过 Stream HTTP 这个设计，传输的吞吐量。 **多个 Stream 复用一条 TCP 连接，达到并发的效果** ，解决了

为了理解 HTTP/2 的并发是怎样实现的，我们先来理解 HTTP/2 中的 Stream、Message、Frame 这 3 个概念。


#### 你可以从上图中看到：

```
1 个 TCP 连接包含一个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术；
Stream 成； 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构
Message 容（头部和包体）；里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内
```
因此，我们可以得出 2 个结论：HTTP 消息可以由多个 Frame 构成，以及 1 个 Frame 可以由多个 TCP 报文构成。
在 HTTP/2 连接上， **不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）** ，因为每个帧的头部会
携带 **格有序的** Stream ID 。 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而 **同一 Stream 内部的帧必须是严**


客户端和服务器务器建立的 Stream **双方都可以建立** 必须是偶数号。 **Stream** ， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服

同一个连接中的GOAWAY ，用来关闭 Stream ID TCP 是不能复用的，只能顺序递增，所以当连接。 Stream ID 耗尽时，需要发一个控制帧

在 Nginx 中，可以通过 http2_max_concurrent_streams 配置来设置 Stream 的上限，默认是 128 个。
HTTP/2 通过 Stream 实现的并发，比 HTTP/1.1 通过 TCP 连接实现并发要牛逼的多， **因为当 HTTP/2 实现 100 个
并发TCP Stream 握手、慢启动以及时，只需要建立一次 TLS 握手过程，这些都是很耗时的。 TCP 连接，而 HTTP/1.1 需要建立 100 个 TCP 连接，每个 TCP 连接都要经过**

HTTP/2 HTML/CSS 还可以对每个和图片资源时，希望服务器先传递 Stream 设置不同 **优先级** ，帧头中的「标志位」可以设置优先级，比如客户端访问 HTML/CSS，再传图片，那么就可以通过设置 Stream 的优先级来
实现，以此提高用户体验。

## 服务器主动推送资源^


#### HTTP/1.1 源。 不支持服务器主动推送资源给客户端，都是由客户端向服务器发起请求后，才能获取到服务器响应的资

#### 比如，客户端通过这时客户端还要再发起获取 HTTP/1.1 CSS 请求从服务器那获取到了文件的请求，需要两次消息往返，如下图左边部分： HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染⻚面，

#### 如上图右边部分，在的次数。 HTTP/2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件，减少了消息传递

在 Nginx 中，如果你希望客户端访问 /test.html 时，服务器直接推送 /test.css，那么可以这么配置：

#### 那 HTTP/2 的推送是怎么实现的？

客户端发起的请求，必须使用的是奇数号源时，会通过 PUSH_PROMISE 帧传输 Stream HTTP 头部，并通过帧中的，服务器主动的推送，使用的是偶数号 Promised Stream ID Stream 字段告知客户端，接。服务器在推送资
下来会在哪个偶数号 Stream 中发送包体。

location /test.html { http2_push /test.css; (^)
}


如上图，在是可以 **并发** Stream 1 的。 中通知客户端 CSS 资源即将到来，然后在 Stream 2 中发送 CSS 资源，注意 Stream 1 和 2

## 总结^


#### HTTP/2 协议其实还有很多内容，比如流控制、流状态、依赖关系等等。

#### 这次主要介绍了关于 HTTP/2 是如何提示性能的几个方向，它相比 HTTP/1 大大提高了传输效率、吞吐能力。

第一点，对于常⻅的 HTTP 头部通过 **静态表和 Huffman 编码** 的方式，将体积压缩了近一半，而且针对后续的请求
头部，还可以建立 **动态表** ，将体积压缩近 90%，大大提高了编码效率，同时节约了带宽资源。
不过，动态表并非可以无限增大，并发能力，因此服务器需要限制 HTTP/2 因为动态表是会占用内存的，动态表越大，内存也越大，容易影响服务器总体的连接时⻓或者请求次数。

第二点，及减少了 **HTTP/2** TCP 慢启动阶段对流量的影响。不同的 **实现了 Stream 并发** ，多个 Stream Stream ID 只需复用才可以并发，即时乱序发送帧也没问题，但是同一个 1 个 TCP 连接，节约了 TCP 和 TLS 握手时间，以
Stream 里的帧必须严格有序。
另外，可以根据资源的渲染顺序来设置 Stream 的 **优先级** ，从而提高用户体验。

第三点，帧，告诉客户端接下来在哪个 **服务器支持主动推送资源** Stream ，大大提升了消息的传输性能，服务器推送资源时，会先发送发送资源，然后用偶数号 Stream 发送资源给客户端。 PUSH_PROMISE

HTTP/2 阻塞”的问题，只不过问题不是在通过 Stream 的并发能力，解决了 HTTP 这一层面，而是在 HTTP/1 队头阻塞的问题，看似很完美了，但是 TCP 这一层。 HTTP/2 还是存在“队头

**HTTP/2 这样内核才会将缓冲区里的数据返回给是基于 TCP 协议来传输数据的， HTTP TCP 应用，那么当「前是字节流协议，TCP 1 个字节数据」没有到达时，后收到的字节数据只层必须保证收到的字节数据是完整且连续的，
能存放在内核缓冲区里，只有等到这HTTP/2 队头阻塞问题。 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是**

有没有什么解决方案呢？既然是议，这个大胆的决定， HTTP/3 TCP 协议做了！协议自身的问题，那干脆放弃 TCP 协议，转而使用 UDP 协议作为传输层协


#### 参考资料：

1. https://developers.google.com/web/fundamentals/performance/http2
2. https://http2.akamai.com/demo
3. https://tools.ietf.org/html/rfc7541

## 最后^

#### 哈喽，我是小林，就爱图解计算机基础，如果文章对你有帮助，别忘记关注哦！

## 2.7 HTTP/3 强势来袭

#### HTTP/3 对于包格式可能后续会有变化。现在还没正式推出，不过自 2017 年起， HTTP/3 已经更新到 34 个草案了，基本的特性已经确定下来了，

#### 所以，这次 HTTP/3 介绍不会涉及到包格式，只说它的特性。


## 美中不足的 HTTP/2^

#### HTTP/2 足的是 HTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了协议是基于 TCP 实现的，于是存在的缺陷有三个。 HTTP/1.1 的性能，而美中不

#### 队头阻塞；

#### TCP 与 TLS 的握手时延迟；

#### 网络迁移需要重新连接；

### 队头阻塞

#### HTTP/2 TCP 连接中的所有请求。多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该

#### 因为中丢失了，即使序列号较高的 TCP 是字节流协议，TCP TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的段已经被接收了，应用层也无法从内核中读取到这部分数据，从 TCP HTTP 段在网络传输视⻆

#### 看，就是请求被阻塞了。

#### 举个例子，如下图：


图中发送方发送了很多个网络中丢失了，即使 packet 4-6 packet，每个被接收方收到后，由于内核中的 packet 都有自己的序号，你可以认为是 TCP 数据不是连续的，于是接收方的应用层就无 TCP 的序列号，其中 packet 3 在
法从内核中读取到，只有等到队头阻塞问题，是在 TCP 层面发生的。 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的

### TCP 与 TLS 的握手时延迟

#### 发起能发出请求数据。 HTTP 请求时，需要经过 TCP 三次握手和 TLS 四次握手（TLS 1.2）的过程，因此共需要 3 个 RTT 的时延才


#### 另外，产生"减速 TCP "效果。由于具有「拥塞控制」的特性，所以刚建立连接的 TCP 会有个「慢启动」的过程，它会对 TCP 连接

### 网络迁移需要重新连接

#### 一个口变动了，就会导致需要 TCP 连接是由四元组（源 TCP 与 IP TLS 地址，源端口，目标重新握手，这不利于移动设备切换网络的场景，比如 IP 地址，目标端口）确定的，这意味着如果 4G 网络环境切换成 IP 地址或者端

#### WIFI。

#### 这些问题都是 传输层协议替换成 TCP UDP 协议固有的问题，无论应用层的，这个大胆的决定，HTTP/3 HTTP/2 做了！在怎么设计都无法逃脱。要解决这个问题，就必须把


## QUIC 协议的特点^

#### 我们深知，UDP 是一个简单、不可靠的传输协议，而且是 UDP 包之间是无序的，也没有依赖关系。

#### 而且，UDP 是不需要连接的，也就不需要握手和挥手的过程，所以天然的就比 TCP 快。

#### 当然，具有类似HTTP/3 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应用层」实现了 UDP 协议变成 QUIC “可靠 协议 ”的了，，它

#### 所以不用担心数据包丢失的问题。

#### QUIC 协议的优点有很多，这里举例几个，比如：

#### 无队头阻塞；

#### 更快的连接建立；

#### 连接迁移；

### 无队头阻塞

QUIC 可以认为就是一条协议也有类似 HTTP HTTP/2 Stream 请求。 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream

由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。
不过使该流的其他数据包到达了，数据也无法被 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。


#### 而其他流的数据报文只要被完整接收，数据包丢失了，其他流也会因此受影响。HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的

所以，受影响。QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不

### 更快的连接建立

对于此它们难以合并在一起，需要分批次来握手，先 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、 TCP 握手，再 TLS 握手。 openssl 库实现的表示层，因

HTTP/3 ID」，连接迁移就是基于连接在传输数据前虽然需要 ID QUIC 实现的。协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接

但是 **录”，再加上** HTTP/3 **QUIC** 的 QUIC **使用的是** 协议并不是与 **TLS1.3** TLS **，因此仅需** 分层，而是 **1 个 RTT QUIC 就可以「同时」完成建立连接与密钥协商，甚至在第二内部包含了 TLS，它在自己的帧会携带 TLS 里的“记
次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果** 。
如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT：


### 连接迁移

#### 在前面我们提到，基于定一条 TCP 连接，那么当移动设备的网络从 TCP 传输协议的 HTTP 4G 协议，由于是通过四元组（源切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连 IP、源端口、目的 IP、目的端口）确

#### 接，然后重新建立连接，而建立连接的过程包含过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速

#### 而自选择一组 QUIC 协议没有用四元组的方式来 ID 来标记自己，因此即使移动设备的网络变化后，导致“绑定”连接，而是通过 连接 ID 来标记通信的两个端点，客户端和服务器可以各 IP 地址变化了，只要仍保有上下文信息（比如

#### 连接能。 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了 连接迁移 的功

## HTTP/3 协议^

#### 了解完 QUIC 协议的特点后，我们再来看看 HTTP/3 协议在 HTTP 这一层做了什么变化。

HTTP/3 HTTP/3 自身不需要再定义同 HTTP/2 一样采用二进制帧的结构，不同的地方在于 Stream，直接使用 QUIC 里的 Stream HTTP/2 ，于是 HTTP/3 的二进制帧里需要定义的帧的结构也变简单了。 Stream，而


#### 从上图可以看到，HTTP/3 帧头只有两个字段：类型和⻓度。

#### 根据帧类型的不同，大体上分为数据帧和控制帧两大类，属于数据帧。 HEADERS 帧（HTTP 头部）和 DATA 帧（HTTP 包体）

HTTP/3 HTTP/3 在头部压缩算法这一方便也做了升级，升级成了中的 QPACK 也采用了静态表、动态表及 Huffman **QPACK** 编码。。与 HTTP/2 中的 HPACK 编码方式相似，

对于静态表的变化，HTTP/2 中的 HPACK 的静态表只有 61 项，而 HTTP/3 中的 QPACK 的静态表扩大到 91 项。
HTTP/2 和 HTTP/3 的 Huffman 编码并没有多大不同，但是动态表编解码方式不同。
所谓的动态表，在首次请求仅用 1 个数字表示，然后对方可以根据这-响应后，双方会将未包含在静态表中的 1 个数字从动态表查到对应的数据，就不必每次都传输⻓⻓的数据，大大 Header 项更新各自的动态表，接着后续传输时
提升了编码效率。

可以看到， **HPACK 头部，因为对方还没建立好动态表，因此后续的请求解码会阻塞到首次请求中丢失的数据包重传过来动态表是具有时序性的，如果首次出现的请求发生了丢包，后续的收到请求，对方就无法解码出** (^) 。
HTTP/3 的 QPACK 解决了这一问题，那它是如何解决的呢？
QUIC 消息时用的是双向流，这两个单向流的用法：会有两个特殊的单向流，所谓的单项流只有一端可以发送消息，双向则指两端都可以发送消息，传输 HTTP
一个叫HTTP 请求头部，客户端可以通过这个 QPACK Encoder Stream， 用于将一个字典（ Stream 发送字典；key-value）传递给对方，比如面对不属于静态表的
一个叫就可以使用这个字典来编码了。 QPACK Decoder Stream，用于响应对方，告诉它刚发的字典已经更新到自己的本地动态表了，后续
这两个特殊的单向流是用来部。 **同步双方的动态表** ，编码方收到解码方更新确认的通知后，才使用动态表编码 HTTP 头

## 总结^


#### HTTP/2 虽然具有多个流并发传输的能力，但是传输层是 TCP 协议，于是存在以下缺陷：

#### 队头阻塞 列号较高的，HTTP/2 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从多个请求跑在一个 TCP 连接中，如果序列号较低的 TCP 段在网络传输中丢失了，即使序 HTTP 视⻆看，就是多个请

#### 求被阻塞了；

#### TCP 和 TLS 握手时延 ，TCL 三次握手和 TLS 四次握手，共有 3-RTT 的时延；

#### 连接迁移需要重新连接 连接的，那么网络环境变化后，就会导致，移动设备从 4G 网络环境切换到 IP 地址或端口变化，于是 WIFI 时，由于 TCP TCP 只能断开连接，然后再重新建立连是基于四元组来确认一条 TCP

#### 接，切换网络环境的成本高；

#### HTTP/3 就将传输层从 TCP 替换成了 UDP，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输。

#### QUIC 协议的特点：

**无队头阻塞** 生丢包了，只会影响该流，其他流不受影响；，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，也不会有底层协议限制，某个流发
**建立连接速度快** 钥协商，甚至在第二次连接的时候，应用数据包可以和，因为 QUIC 内部包含 TLS1.3，因此仅需 QUIC 1 个握手信息（连接信息 RTT 就可以「同时」完成建立连接与 + TLS 信息）一起发送， TLS 密
达到 0-RTT 的效果。
**连接迁移** 户端和服务器可以各自选择一组，QUIC 协议没有用四元组的方式来 ID 来标记自己，因此即使移动设备的网络变化后，导致“绑定”连接，而是通过「连接 ID 」来标记通信的两个端点，客 IP 地址变化了，只
要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本；
另外 HTTP/3 的 QPACK 通过两个特殊的单向流来同步双方的动态表，解决了 HTTP/2 的 HPACK 队头阻塞问题。
**期待，HTTP/3 正式推出的那一天！**

参考资料：

1. https://medium.com/faun/http-2-spdy-and-http-3-quic-bae7d9a3d484
2. https://developers.google.com/web/fundamentals/performance/http2?hl=zh-cn
3. https://blog.cloudflare.com/http3-the-past-present-and-future/
4. https://tools.ietf.org/html/draft-ietf-quic-http-34
5. https://tools.ietf.org/html/draft-ietf-quic-transport-34#section-17
6. https://ably.com/topic/http3?amp%3Butm_campaign=evergreen&%3Butm_source=reddit&utm_medium=referral
7. https://www.nginx.org.cn/article/detail/422
8. https://www.bilibili.com/read/cv793000/
9. https://www.chinaz.com/2020/1009/1192436.shtml

## 最后^


#### 哈喽，我是小林，就爱图解计算机基础，如果文章对你有帮助，别忘记关注哦！

# 三、TCP 篇

## 3.1 TCP 三次握手与四次挥手

不管面试 Java 、C/C++、Python 等开发岗位， TCP 的知识点可以说是必问的了。
**任 TCP 虐我千百遍，我仍待 TCP 如初恋。**
遥想小林当年校招时常因 TCP 面试题被刷，真是又爱又恨....
过去不会没关系，今天就让我们来消除这份恐惧，微笑着勇敢的面对它吧！
所以小林整理了关于 **TCP 三次握手和四次挥手的面试题型** ，跟大家一起探讨探讨。

1. TCP 基本认识


#### 2. TCP 连接建立

#### 3. TCP 连接断开


4. Socket 编程

#### PS：本次文章不涉及 TCP 流量控制、拥塞控制、可靠性传输等方面知识，这些留在下篇哈！

## TCP 基本认识^

#### 瞧瞧 TCP 头格式

#### 我们先来看看 TCP 头的格式，标注颜色的表示与本文关联比较大的字段，其他字段不做详细阐述。


#### 序列号 ：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就

#### 「累加」一次该「数据字节数」的大小。 用来解决网络包乱序问题。

#### 确认应答号 据都已经被正常接收。：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数 用来解决不丢包的问题。

#### 控制位：

#### ACK 须设置为：该位为 1 。 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必

#### RST ：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。

#### SYN ：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。

#### FIN 主机之间就可以相互交换：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的 FIN 位为 1 的 TCP 段。

#### 为什么需要 TCP 协议？ TCP 工作在哪一层？

#### IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。


#### 如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。

#### 因为 和按序的。 TCP 是一个工作在 传输层 的 可靠 数据传输的服务，它能确保接收端接收的网络包是 无损坏、无间隔、非冗余

#### 什么是 TCP ？

#### TCP 是 面向连接的、可靠的、基于字节流 的传输层通信协议。

#### 面向连接 对多是无法做到的；：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一


#### 可靠的 ：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；

#### 字节流 「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当

#### 复」的报文会自动丢弃。

#### 什么是 TCP 连接？

#### 我们来看看 RFC 793 是如何定义「连接」的：

_Connections:The reliability and flow control mechanisms described above require
that TCPs initialize and maintain certain status information foreach data stream. The combination of this information, including
sockets, sequence numbers, and window sizes, is called a connection._
简单来说就是， **用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口
大小称为连接。**

#### 所以我们可以知道，建立一个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识。

```
Socket ：由 IP 地址和端口号组成
序列号 ：用来解决乱序问题等
窗口大小 ：用来做流量控制
如何唯一确定一个 TCP 连接呢？
```
TCP 四元组可以唯一的确定一个连接，四元组包括如下：
源地址


#### 源端口

#### 目的地址

#### 目的端口

#### 源地址和目的地址的字段（ 32 位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。

#### 源端口和目的端口的字段（ 16 位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。

#### 有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？

#### 服务器通常固定在某个本地端口上监听，等待客户端的连接请求。

#### 因此，客户端 IP 和 端口是可变的，其理论值计算公式如下:

对大 IPv4 TCP ，客户端的连接数，约为 IP 数最多为 2 的 48 2 次方。 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最

当然，服务端最大并发 TCP 连接数远不能达到理论上限。

```
首先主要是 文件描述符限制 ，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目；
另一个是 内存限制 ，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的。
UDP 和 TCP 有什么区别呢？分别的应用场景是？
```
UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。
UDP 协议真的非常简，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：


#### 目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。

#### 包⻓度：该字段保存了 UDP 首部的⻓度跟数据的⻓度之和。

#### 校验和：校验和是为了提供可靠的 UDP 首部和数据而设计。

#### TCP 和 UDP 区别：

#### 1. 连接

#### TCP 是面向连接的传输层协议，传输数据前先要建立连接。

#### UDP 是不需要连接，即刻传输数据。

#### 2. 服务对象

#### TCP 是一对一的两点服务，即一条连接只有两个端点。

#### UDP 支持一对一、一对多、多对多的交互通信

#### 3. 可靠性

#### TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。

#### UDP 是尽最大努力交付，不保证可靠交付数据。

#### 4. 拥塞控制、流量控制

#### TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。


#### UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

#### 5. 首部开销

#### TCP 字段则会变⻓的。首部⻓度较⻓，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」

#### UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

#### 6. 传输方式

#### TCP 是流式传输，没有边界，但保证顺序和可靠。

#### UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

#### 7. 分片不同

#### TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP

#### UDP 再传给传输层，但是如果中途丢了一个分片，在实现可靠传输的的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 UDP 时则就需要重传所有的数据包，这样 IP 层组装完数据，接着

#### 传输效率非常差，所以通常 UDP 的报文应该小于 MTU。

#### TCP 和 UDP 应用场景：

#### 由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

#### FTP 文件传输

#### HTTP / HTTPS

#### 由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

#### 包总量较少的通信，如 DNS 、 SNMP 等

#### 视频、音频等多媒体通信

#### 广播通信

#### 为什么 UDP 头部没有「首部⻓度」字段，而 TCP 头部有「首部⻓度」字段呢？

#### 原因是度。 TCP 有 可变⻓ 的「选项」字段，而 UDP 头部⻓度则是 不会变化 的，无需多一个字段去记录 UDP 的首部⻓

#### 为什么 UDP 头部有「包⻓度」字段，而 TCP 头部则没有「包⻓度」字段呢？

#### 先说说 TCP 是如何计算负载数据⻓度：


其中可以求得 IP 总⻓度 TCP (^) 数据的⻓度。和 IP 首部⻓度，在 IP 首部格式是已知的。TCP 首部⻓度，则是在 TCP 首部格式已知的，所以就
大家这时就奇怪了问：「包⻓度」呢？” “ UDP 也是基于 IP 层的呀，那 UDP 的数据⻓度也可以通过这个公式计算呀？ 为何还要有
这么一问，确实感觉 UDP 「包⻓度」是冗余的。
**因为为了网络设备硬件设计和处理方便，首部⻓度需要是 4 字节的整数倍。**
如果去掉UDP 首部⻓度是 UDP 「包⻓度」字段，那 4 字节的整数倍，才补充了「包⻓度」字段。 UDP 首部⻓度就不是 4 字节的整数倍了，所以小林觉得这可能是为了补全

## TCP 连接建立^

#### TCP 三次握手过程和状态变迁

#### TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而 建立连接是通过三次握手来进行的。


#### 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态


客户端会随机初始化序号（位置为 1 ，表示 SYN 报文。接着把第一个client_isn），将此序号置于 SYN 报文发送给服务端，表示向服务端发起连接，该报文不 TCP 首部的「序号」字段中，同时把 SYN 标志
包含应用层数据，之后客户端处于 SYN-SENT 状态。

服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入


```
TCP 和 ACK首部的「序号」字段中，其次把 标志位置为 1 。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN SYN-
RCVD 状态。
```
```
客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客 TCP 首部 ACK 标志位
户到服务器的数据，之后客户端处于 ESTABLISHED 状态。
服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。
```
从上面的过程可以发现 **第三次握手是可以携带数据的，前两次握手是不可以携带数据的** ，这也是面试常问的题。
一旦完成三次握手，双方都处于数据了。 ESTABLISHED 状态，此时连接就已建立完成，客户端和服务端就可以相互发送

```
如何在 Linux 系统中查看 TCP 状态？
```
TCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。


#### 为什么是三次握手？不是两次、四次？

#### 相信大家比较常回答的是：“因为三次握手才能保证双方具有接收和发送的能力。”

#### 这回答是没问题，但这回答是片面的，并没有说出主要的原因。

#### 在前面我们知道了什么是 TCP 连接 ：

```
用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括接。 Socket、序列号和窗口大小 称为连
```
所以，重要的是 **为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接。**
接下来以三个方面分析三次握手的原因：
三次握手才可以阻止重复历史连接的初始化（主要原因）
三次握手才可以同步双方的初始序列号
三次握手才可以避免资源浪费
原因一：避免历史连接
我们来看看 RFC 793 指出的 TCP 连接使用三次握手的 **首要原因** ：
_The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causingconfusion._

简单来说，三次握手的 **首要原因是为了防止旧的重复连接初始化造成混乱。**
网络环境是错综复杂的，往往并不是如我们期望的一样，先发送的数据包，就先到达目标主机，反而它很骚，可能会由于网络拥堵等乱七八糟的原因，会使得旧的数据包，先到达目标主机，那么这种情况下 TCP 三次握手是如何
避免的呢？


#### 客户端连续发送多次 SYN 建立连接的报文，在 网络拥堵 情况下：

#### 一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端；

#### 那么此时服务端就会回一个 SYN + ACK 报文给客户端；

#### 客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送RST 报文给服务端，表示中止这一次连接。

#### 如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接：

#### 如果是历史连接（序列号过期或超时），则第三次握手发送的报文是 RST 报文，以此中止历史连接；


#### 如果不是历史连接，则第三次发送的报文是 ACK 报文，通信双方就会成功建立连接；

#### 所以，TCP 使用三次握手建立连接的最主要原因是 防止历史连接初始化了连接。

#### 原因二：同步双方初始序列号

#### TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

#### 接收方可以去除重复的数据；

#### 接收方可以根据数据包的序列号按序接收；

#### 可以标识发送出去的数据包中， 哪些是已经被对方收到的；

#### 可⻅，序列号在候，需要服务端回一个 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序 SYN 报文的时

#### 列号」给客户端的时候，依然也要得到客户端的应答回应， 同步。 这样一来一回，才能确保双方的初始序列号能被可靠的

#### 四次握手其实也能够可靠的同步双方的初始化序号，但由于手」。 第二步和第三步可以优化成一步 ，所以就成了「三次握

#### 而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

#### 原因三：避免资源浪费


#### 如果只有「两次握手」，当客户端的送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK ACK 报文，就会重新发 确认信号，所以

#### 每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？

#### 如果客户端的 接，造成不必要的资源浪费。 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会 建立多个冗余的无效链


#### 即两次握手会造成消息滞留情况下，服务器重复接受无用的连接请求 SYN 报文，而造成重复分配资源。

#### 小结

#### TCP 列号 。序列号能够保证数据包不重复、不丢弃和按序传输。建立连接时，通过三次握手 能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序

#### 不使用「两次握手」和「四次握手」的原因：

#### 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；

#### 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

#### 为什么客户端和服务端的初始序列号 ISN 是不相同的？

#### 如果一个已经失效的连接被重用了，但是该旧连接的历史报文还残留在网络中，如果序列号相同，那么就无法分辨出该报文是不是历史报文，如果历史报文被新的连接接收了，则会产生数据错乱。

#### 所以，每次建立连接前重新初始化一个序列号主要是为了通信双方能够根据序号将不属于本连接的报文段丢弃。

#### 另一方面是为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收。

#### 初始序列号 ISN 是如何随机产生的？

#### 起始 ISN 是基于时钟的，每 4 毫秒 + 1，转一圈要 4.55 个小时。

#### RFC1948 中提出了一个较好的初始化序列号 ISN 随机生成算法。

_ISN = M + F (localhost, localport, remotehost, remoteport)_


#### M 是一个计时器，这个计时器每隔 4 毫秒加 1 。

```
被外部轻易推算得出，用F^ 是一个 Hash 算法，根据源 MD5 IP算法是一个比较好的选择。、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能
既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？
```
我们先来认识下 MTU 和 MSS

#### MTU：一个网络包的最大⻓度，以太网中一般为 1500 字节；

#### MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大⻓度；

#### 如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？

#### 当若干片，保证每一个分片都小于 IP 层有一个超过 MTU 大小的数据（ MTU。把一份TCP 头部 IP 数据报进行分片以后，由目标主机的 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成 IP 层来进行重新组装后，

#### 再交给上一层 TCP 传输层。

#### 这看起来井然有序，但这存在隐患的， 那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传 。

#### 因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

#### 当接收方发现后，就会重发「整个 TCP 报文（头部 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 + 数据）」。 ACK 给对方，那么发送方的 TCP 在超时

#### 因此，可以得知由 IP 层进行分片传输，是非常没有效率的。

#### 所以，为了达到最佳的传输效能MSS 时，则就先会进行分片，当然由它形成的 TCP 协议在 建立连接的时候通常要协商双方的 IP 包的⻓度也就不会大于 MTU MSS ，自然也就不用 值 ，当 TCP IP 层发现数据超过分片了。


#### 经过增加了重传的效率。 TCP 层分片后，如果一个 TCP 分片丢失后， 进行重发时也是以 MSS 为单位 ，而不用重传所有的分片，大大

#### 什么是 SYN 攻击？如何避免 SYN 攻击？

#### SYN 攻击

我们都知道一个 SYN TCP 报文，就进入连接建立是需要三次握手，假设攻击者短时间伪造不同SYN_RCVD 状态，但服务端发送出去的 ACK + SYN IP 地址的 (^) 报文，无法得到未知SYN 报文，服务端每接收到 IP 主机的
ACK 应答，久而久之就会 **占满服务端的 SYN 接收队列（未连接队列）** ，使得服务器不能为正常用户服务。

#### 避免 SYN 攻击方式一

其中一种解决方式是通过修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。
当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数：

```
SYN_RCVD 状态连接的最大个数：
```
```
net.core.netdev_max_backlog
```
```
net.ipv4.tcp_max_syn_backlog
```

#### 超出处理能时，对新的 SYN 直接回报 RST，丢弃连接：

#### 避免 SYN 攻击方式二

我们先来看下 Linux 内核的 SYN （未完成连接建立）队列与 Accpet （已完成连接建立）队列是如何工作的？

#### 正常流程：

#### 当服务端接收到客户端的 SYN 报文时，会将其加入到内核的「 SYN 队列」；

#### 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；

```
服务端接收到 ACK 报文后，从「 SYN 队列」移除放入到「 Accept 队列」；
应用通过调用 accpet() socket 接口，从「 Accept 队列」取出连接。
```
```
net.ipv4.tcp_abort_on_overflow
```

#### 应用程序过慢：

```
如果应用程序过慢时，就会导致「 Accept 队列」被占满。
```

#### 受到 SYN 攻击：

#### 如果不断受到 SYN 攻击，就会导致「 SYN 队列」被占满。

```
tcp_syncookies 的方式可以应对 SYN 攻击的方法：
net.ipv4.tcp_syncookies = 1
```

#### 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」；

```
计算出一个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，
服务端接收到客户端的应答报文时，服务器会检查这个队列」。 ACK 包的合法性。如果合法，直接放入到「 Accept
最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。
```
## TCP 连接断开^

#### TCP 四次挥手过程和状态变迁

#### 天下没有不散的宴席，对于 TCP 连接也是这样， TCP 断开连接是通过 四次挥手 方式。

#### 双方都可以主动断开连接，断开连接后主机中的「资源」将被释放。


#### 客户端打算关闭连接，此时会发送一个户端进入 FIN_WAIT_1 状态。 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客

#### 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。

#### 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。

#### 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。

#### 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态

#### 服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，至此服务端已经完成连接的关闭。

#### 客户端在经过 2MSL 一段时间后，自动进入 CLOSED 状态，至此客户端也完成连接的关闭。

#### 你可以看到，每个方向都需要 一个 FIN 和一个 ACK ，因此通常被称为 四次挥手 。


#### 这里一点需要注意是： 主动关闭连接的，才有 TIME_WAIT 状态。

#### 为什么挥手需要四次？

#### 再来回顾下四次挥手双方发 FIN 包的过程，就能理解为什么需要四次了。

#### 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。

#### 服务器收到客户端的服务端不再发送数据时，才发送 FIN 报文时，先回一个 FIN 报文给客户端来表示同意现在关闭连接。 ACK 应答报文，而服务端可能还有数据需要处理和发送，等

#### 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的送，从而比三次握手导致多了一次。 ACK 和 FIN 一般都会分开发

#### 为什么 TIME_WAIT 等待的时间是 2MSL？

间报文将被丢弃。因为MSL^ 是 Maximum Segment Lifetime TCP 报文基于是， IP **报文最大生存时间** 协议的，而 IP 头中有一个，它是任何报文在网络上存在的最⻓时间，超过这个时 TTL 字段，是 IP 数据报可以经过的最大路
由数，每经过一个处理他的路由器此值就减 1 ，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。
MSL **时间** ，以确保报文已被自然消亡。与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的**

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包
被接收方处理后又会向对方发送响应，所以 **一来一回需要等待 2 倍的时间** 。
比如如果被动关闭方没有收到断开连接的最后的会重发 ACK 给被动关闭方， 一来一去正好 2 个 ACK MSL。报文，就会触发超时重发 Fin 报文，另一方接收到 FIN 后，

没有传输到服务端，客户端又接收到了服务端重发的2MSL^ 的时间是从 **客户端接收到 FIN 后发送 ACK 开始计时的** FIN 报文，那么。如果在 **2MSL** TIME-WAIT **时间将重新计时** 时间内，因为客户端的。 ACK^

在 **间为固定的** Linux 系统里 **60 秒** (^) 。2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。 **Linux 系统停留在 TIME_WAIT 的时**
其定义在 Linux 内核代码里的名称为 TCP_TIMEWAIT_LEN：
如果要修改内核。 TIME_WAIT 的时间⻓度，只能修改 Linux 内核代码里 TCP_TIMEWAIT_LEN 的值，并重新编译 Linux
为什么需要 TIME_WAIT 状态？

### TIMEWAIT

#### 主动发起关闭连接的一方，才会有 TIME-WAIT 状态。

#### 需要 TIME-WAIT 状态，主要是两个原因：

#### 防止具有相同「四元组」的「旧」数据包被收到；

#### 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的闭； ACK 能让被动关闭方接收，从而帮助其正常关

#### 原因一：防止旧连接的数据包

#### 假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？


#### 如上图⻩色框框服务端在关闭连接之前发送的 SEQ = 301 报文，被网络延迟了。

#### 这时有相同端口的这个过期的报文，这就会产生数据错乱等严重的问题。 TCP 连接被复用后，被延迟的 SEQ = 301 抵达了客户端，那么客户端是有可能正常接收

#### 所以，TCP 就设计出了这么一个机制，经过 2MSL 这个时间， 足以让两个方向上的数据包都被丢弃，使得原来

#### 连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。

#### 原因二：保证连接正确关闭

#### 在 RFC 793 指出 TIME-WAIT 另一个重要的作用是：

_TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received theacknowledgment of its connection termination request._

也就是说，TIME-WAIT 作用是 **等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**
假设 TIME-WAIT 没有等待时间或时间过短，断开连接会造成什么问题呢？

#### 如上图红色框框客户端四次挥手的最后一个 ACK 报文如果在网络中被丢失了，此时如果客户端 TIME-


#### WAIT 过短或没有，则就直接进入了 CLOSED 状态了，那么服务端则会一直处在 LASE_ACK 状态。

#### 当客户端发起建立连接的终止。 SYN 请求报文后，服务端会发送 RST 报文给客户端，连接建立的过程就会被

#### 如果 TIME-WAIT 等待足够⻓的情况就会遇到两种情况：

#### 服务端正常收到四次挥手的最后一个 ACK 报文，则服务端正常关闭连接。

#### 服务端没有收到四次挥手的最后一个文。 ACK 报文时，则会重发 FIN 关闭连接报文并等待新的 ACK 报

#### 所以客户端在 TIME-WAIT 状态等待 2MSL 时间后，就可以 保证双方的连接都可以正常的关闭。

#### TIME_WAIT 过多有什么危害？

#### 如果服务器有处于 TIME-WAIT 状态的 TCP，则说明是由服务器方主动发起的断开请求。

#### 过多的 TIME-WAIT 状态主要的危害有两种：

#### 第一是内存资源占用；

#### 第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口；

#### 第二个危害是会造成严重的后果的，要知道，端口资源也是有限的，一般可以开启的端口为可以通过如下参数设置指定 32768 ～ 61000 ，也

#### 如果发起连接一方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。

#### 客户端受端口资源限制：

#### 客户端接。 TIME_WAIT过多，就会导致端口资源被占用，因为端口就 65536 个，被占满就会导致无法创建新的连

#### 服务端受系统资源限制：

#### 由于一个四元组表示扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多一直不断的连接了。所以 TCP 连接，理论上服务端可以建立很多连接，服务端确实只监听一个端口 但是会把连接

#### 当服务端出现大量 TIME_WAIT 时，系统资源被占满时，会导致处理不过来新的连接。

#### 如何优化 TIME_WAIT？

#### 这里给出优化 TIME-WAIT 的几个方式，都是有利有弊：

```
打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；
```
```
net.ipv4.ip_local_port_range
```

net.ipv4.tcp_max_tw_buckets
程序中使用 SO_LINGER ，应用强制使用 RST 关闭。
方式一： _net.ipv4.tcp_tw_reuse_ 和 _tcp_timestamps_
如下的 Linux 内核参数开启后，则可以 **复用处于 TIME_WAIT 的 socket 为新的连接所用** 。
有一点需要注意的是， **函数时，内核会随机找一个tcp_tw_reuse time_wait 功能只能用客户端（连接发起方），因为开启了该功能，在调用状态超过 1 秒的连接给新的连接复用。 connect()**

#### 使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即

#### 这个时间戳的字段是在戳。 TCP 头部的「选项」里，用于记录 TCP 发送方的当前时间戳和从对端接收到的最新时间

#### 由于引入了时间戳，我们在前面提到的弃。 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢

方式二： _net.ipv4.tcp_max_tw_buckets_
这个值默认为 **状态重置。** 18000 ，当系统中处于 TIME_WAIT 的连接 **一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接**

这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，不推荐使用。
方式三：程序中使用 _SO_LINGER_
我们可以通过设置 socket 选项，来设置调用 close 关闭连接行为。

如果将跳过四次挥手，也就跳过了l_onoff为非 0 ， 且l_lingerTIME_WAIT值为 0 ，那么调用状态，直接关闭。close后，会立该发送一个RST标志给对端，该 TCP 连接

但这为跨越TIME_WAIT状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。

```
如果已经建立了连接，但是客户端突然出现故障了怎么办？
```
TCP 有一个机制是 **保活机制** 。这个机制的原理是这样的：

```
net.ipv4.tcp_tw_reuse = 1
```
```
net.ipv4.tcp_timestamps=1（默认即为 1 ）
```
```
structso_linger linger.l_onoff so_linger = 1 ;;
so_lingersetsockopt.l_linger(s, SOL_SOCKET = 0 ;, SO_LINGER, &so_linger,sizeof(so_linger));
```

#### 定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的TCP 保活机制会开始作用，每隔一个时间间

#### TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：

tcp_keepalive_time=7200动，则会启动保活机制 ：表示保活时间是 7200 秒（ 2 小时），也就 2 小时内如果没有任何连接相关的活
tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；
tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。
也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。

#### 这个时间是有点⻓的，我们也可以根据实际的需求，对以上的保活相关的参数进行设置。

#### 如果开启了 TCP 保活，需要考虑以下几种情况：

#### 第一种，对端程序是正常工作的。当 重置 ，等待下一个 TCP 保活时间的到来。 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被

#### 第二种，对端程序崩溃并重启。当有效信息， 会产生一个 RST 报文 ，这样很快就会发现 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的 TCP 连接已经被重置。

#### 第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当海，没有响应，连续几次，达到保活探测次数后， TCP 会报告该 TCP TCP 连接已经死亡 保活的探测报文发送给对端后，石沉大。

## Socket 编程^

```
net.ipv4.tcp_keepalive_time=7200net.ipv4.tcp_keepalive_intvl=75
net.ipv4.tcp_keepalive_probes=9
```

```
针对 TCP 应该如何 Socket 编程？
```
```
服务端和客户端初始化 socket，得到文件描述符；
服务端调用 bind，将绑定在 IP 地址和端口;
服务端调用 listen，进行监听；
服务端调用 accept，等待客户端连接；
客户端调用 connect，向服务器端的地址和端口发起连接请求；
服务端 accept 返回用于传输的 socket 的文件描述符；
客户端调用 write 写入数据；服务端调用 read 读取数据；
```
客户端断开连接时，会调用数据后，服务端调用 close (^) ，表示连接关闭。close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完
这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。


所以，监听的 **成连接 socket** socket 。 和真正用来传送数据的 socket，是「两个」 socket，一个叫作 **监听 socket** ，一个叫作 **已完**

成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东⻄一样。

```
listen 时候参数 backlog 的意义？
```
Linux内核中会维护两个队列：
未完成连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；
已完成连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；

```
int listen (int socketfd, int backlog)
```

参数一 socketfd 为 socketfd 文件描述符
参数二 backlog，这参数在历史版本有一定的变化
在早期 Linux 内核 backlog 是 SYN 队列大小，也就是未完成的队列大小。
在 Linux 内核 2.2 之后，backlog 变成 accept 队列，也就是已完成连接建立的队列⻓度， **所以现在通常认为
backlog 是 accept 队列。
但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列⻓度 = min(backlog, somaxconn)。**

```
accept 发生在三次握手的哪一步？
```
我们先看看客户端连接服务端时，发送了什么？

```
客户端的协议栈向服务器端发送了SYN_SENT 状态； SYN 包，并告诉服务器端当前发送序列号 client_isn，客户端进入
服务器端的协议栈收到这个包之后，和客户端进行client_isn 的确认，同时服务器也发送一个 SYN 包，告诉客户端当前我的发送序列号为 ACK 应答，应答的值为 client_isn+1 server_isn，表示对 SYN ，服务器端包
进入 SYN_RCVD 状态；
```

```
客户端协议栈收到成功，客户端的状态为 ACK ESTABLISHED之后，使得应用程序从，同时客户端协议栈也会对服务器端的 connect 调用返回，表示客户端到服务器端的单向连接建立 SYN 包进行应答，应答数据为
server_isn+1；
应答包到达服务器端后，服务器端协议栈使得接也建立成功，服务器端也进入 ESTABLISHED accept状态。 阻塞调用返回，这个时候服务器端到客户端的单向连
```
从上面的描述过程，我们可以得知 **客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握
手成功之后。**

```
客户端调用 close 了，连接是断开的流程是什么？
```
我们看看客户端主动调用了 close，会发生什么？


客户端调用状态； close，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1
服务端接收到了可以通过 read FIN 调用来感知这个报文，TCP 协议栈会为 FIN 包。这个 FIN EOF包插入一个文件结束符 会被 **放在已排队等候的其他已接收的数据之后** EOF 到接收缓冲区中，应用程序，这就
意味着服务端需要处理这种异常情况，因为CLOSE_WAIT 状态； EOF 表示在该连接上再无额外数据到达。此时，服务端进入

接着，当处理完数据后，自然就会读到出一个 FIN 包，之后处于 LAST_ACK 状态； EOF，于是也调用 close 关闭它的套接字，这会使得客户端会发

客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；
服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；


#### 客户端经过 2MSL 时间之后，也进入 CLOSE 状态；

#### 参考资料：

#### [1] 趣谈网络协议专栏.刘超.极客时间.

#### [2] 网络编程实战专栏.盛延敏.极客时间.

#### [3] 计算机网络-自顶向下方法.陈鸣 译.机械工业出版社

#### [4] TCP/IP详解 卷 1 ：协议.范建华 译.机械工业出版社

#### [5] 图解TCP/IP.竹下隆史.人⺠邮电出版社

[6] https://www.rfc-editor.org/rfc/rfc793.html
[7] https://draveness.me/whys-the-design-tcp-three-way-handshake
[8] https://draveness.me/whys-the-design-tcp-time-wait/

## 读者问答^

```
读者问： 1 ，以及一些其他网络书籍和“关于文中三次握手最主要的原因，有一个疑问：为什么新包和旧包的 RFC793 部分，都没有明确说明关于第一个 SYN 如果发生重传会改变 seq 会不一样？查阅了 seqtcp/ip。” 详解 卷
```
文章的例子不是超时重发的 SYN 报文，而是新产生的一个 SYN 报文，所以 seq 是不一样的。
我文章的例子是 RFC 793 ：https://www.rfc-editor.org/rfc/rfc793.html , 33 ⻚的 Figure 9。

```
读者问：重启后，可以立刻使用。这里设置“请教个问题，为了方便调试服务器程序，一般会在服务端设置SO_REUSEADDR 是不是就等价于对这个 SO_REUSEADDR socket 设置了内核中的选项，这样服务器程序在
net.ipv4.tcp_tw_reuse=1 这个选项？”
```
这两个东⻄没有关系的哦。

1. tcp_tw_reuse 后，新的连接才可以被复用，注意，这里是「连接的发起方」；是内核选项，主要用在连接的发起方（客户端）。TIME_WAIT 状态的连接创建时间超过 1 秒
2. SO_REUSEADDR 但是 TCP 连接状态位于是用户态的选项，用于「连接的服务方」，用来告诉操作系统内核，如果端口已被占用， TIME_WAIT ，可以重用端口。如果端口忙，而 TCP 处于其他状态，重用会有
    “Address already in use” 的错误信息。


tcp_tw_reuse 后的问题。 是为了缩短 time_wait 的时间，避免出现大量的 time_wait 连接而占用系统资源，解决的是 accept

SO_REUSEADDR bind 时的问题。 是为了解决 time_wait 状态带来的端口占用问题，以及支持同一个 port 对应多个 ip，解决的是

```
读者问：2msl，这个时候会发生什么？认为连接已经关闭吗？“请教一下，如果客户端第四次挥手ack丢失，服务端超时重发的” fin报文也丢失，客户端timewait时间超过了
```
当客户端 timewait 时间超过了 2MSL，则客户端就直接进入关闭状态。
服务端超时重发 fin 报文的次数如果超过 tcp_orphan_retries 大小后，服务端也会关闭 TCP 连接。

```
读者问：片，如果某一片丢失则需要所有分片都重传；（“求教两个小问题：文章在解释IP分片和 2 TCP MSS）IP没有重传机制，所以需要等分片时说，如果用IP分片会有两个问题：（TCP发送方超时才能重传；问题一： 1 ）IP按MTU分
MSS为什么协商后的跟IP的MTUMSS分片相比，只是多了一步协商可以做到丢失后只发丢失的这一片来提高效率，而默认协商好MSS值的过程，而IP的MTU可以看作是默认协商好就是 1500 字节的IP分片就需要所有片都 1500 字节，所以
重传呢？问题二：能在超时前就直到丢了分片从而提高效率的呢？谢谢老师。TCP MSS分片如果丢失了一片，是不是也需要发送方等待超时再重传？如果不是，” MSS的协商如何
```
问题一：
如果一个大的TCP 头部，接收方 TCP IP 报文是被层只有重组了这些分片，才会认为是一个 MTU 分片，那么只有「第一个分片」才具有 TCP 报文，那么丢失了其中一个分片，接收 TCP 头部，后面的分片则没有
方 IP 层就不会把 TCP 报文丢给 TCP 层，那么就会等待对方超时重传这一整个 TCP 报文。
如果一个大的TCP 头部的TCP TCP 报文，那么其中一个报文被 MSS 分片，那么所有「分片都具有 MSS 分片丢失，就只需要重传这一个分片就可以。 TCP 头部」，因为每个 MSS 分片的是具有

问题二：
TCP MSS数据的可靠交付。分片如果丢失了一片，发送方没收到对方ACK应答，也是会触发超时重传的，因为TCP层是会保证

```
读者问：time_wait “大佬，请教个问题，如果是服务提供方发起的会影响服务端的端口吗？谢谢。” close ，然后引起过多的 time_wait 状态的 tcp 链接，
```
不会。
如果发起连接一方（客户端）的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。
客户端受端口资源限制：
客户端接。 TIME_WAIT过多，就会导致端口资源被占用，因为端口就 65536 个，被占满就会导致无法创建新连


#### 服务端受系统资源限制：

#### 由于一个连接扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多一直不断的连接了。 TCP 四元组表示 TCP 连接，理论上服务端可以建立很多连接，服务端只监听一个端口，但是会把

#### 所以当服务端出现大量 TIMEWAIT 时，系统资源容易被耗尽。

## 最后^

#### 小林为写此文重学了一篇以小林花费了一个星期多才写完此文章。 TCP，深感 TCP 真的是一个非常复杂的协议，要想轻易拿下，也不是一天两天的事，所

#### 正所谓知道的越多，不知道的也越多。

#### 下篇给大家带来 TCP 滑动窗口、流量控制、拥塞控制的图解文章！

**小林是专为大家图解的工具人，Goodbye，我们下次⻅！**


## 3.2 TCP 重传、滑动窗口、流量控制、拥塞控制

#### 前一篇「在此特别感谢你们的认可，大家都暖暖的。硬不硬你说了算！近 40 张图解被问千百遍的 TCP 三次握手和四次挥手面试题」得到了很多读者的认可，

#### 来了，今天又来图解 TCP 了， 小林可能会迟到，但不会缺席。

#### 迟到的原因，主要是着发现这水太深了。。。 TCP 巨复杂 ，它为了保证可靠性，用了巨多的机制来保证，真是个「伟大」的协议，写着写


本文的全部图片都是小林绘画的，非常的辛苦且累，不废话了，直接进入正文，Go！
相信大家都知道 TCP 是一个可靠传输的协议，那它是如何保证可靠的呢？
为了实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等问题。如不能解决这些问题，也就无从谈起可靠传输。

那么，TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。
今天，将重点介绍 TCP 的 **重传机制、滑动窗口、流量控制、拥塞控制。**

## 重传机制^

#### TCP 实现可靠传输的方式之一，是通过序列号与确认应答。

#### 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。


#### 但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？

#### 所以 TCP 针对数据包丢失的情况，会用 重传机制 解决。

#### 接下来说说常⻅的重传机制：

#### 超时重传

#### 快速重传

#### SACK

#### D-SACK


### 超时重传

#### 重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的确认应答报文，就会重发该数据，也就是我们常说的 超时重传 。 ACK

#### TCP 会在以下两种情况发生超时重传：

#### 数据包丢失

#### 确认应答丢失

#### 超时时间应该设置为多少呢？

我们先来了解一下什么是 RTT（Round-Trip Time 往返时延），从下图我们就可以知道：


#### RTT 就是 数据从网络一端传送到另一端所需的时间 ，也就是包的往返时间。

超时重传时间是以 RTO （Retransmission Timeout 超时重传时间）表示。
假设在重传的情况下，超时时间 RTO 「较⻓或较短」时，会发生什么事情呢？


#### 上图中有两种超时时间不同的情况：

#### 当超时时间 RTO 较大 时，重发就慢，丢了老半天才重发，没有效率，性能差；

#### 当超时时间时，更多的超时导致更多的重发。 RTO 较小 时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超

#### 精确的测量超时时间 RTO 的值是非常重要的，这可让我们的重传机制更高效。

#### 根据上述的两种情况，我们可以得知， 超时重传时间 RTO 的值应该略大于报文往返 RTT 的值 。


#### 至此，可能大家觉得超时重传时间 RTO 的值计算，也不是很复杂嘛。

好像就是在发送端发包时记下那么简单， **这只是一个采样，不能代表普遍情况** t0 ，然后接收端再把这个。 ack 回来时再记一个 t1，于是 RTT = t1 – t0。没

实际上「报文往返 RTT 的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」
是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个 **动态变化的值** 。
我们来看看 Linux 是如何计算 RTO 的呢？
估计往返时间，通常需要采样以下两个：
需要的，因为网络状况不断地变化。 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化
除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。
RFC6289 建议使用以下的公式计算 RTO：


其中 SRTT 是计算平滑的RTT ，DevRTR 是计算平滑的RTT 与 最新 RTT 的差距。
在 Linux 下， **α = 0.125，β = 0.25， μ = 1，∂ = 4** 。别问怎么来的，问就是大量实验中调出来的。
如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是 **超时间隔加倍。**
也就是 **差，不宜频繁反复发送。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境**

超时触发重传存在的问题是，超时周期可能相对较⻓。那是不是可以有更快的方式呢？
于是就可以用「快速重传」机制来解决超时重发的时间等待。

### 快速重传

TCP 还有另外一种 **快速重传（Fast Retransmit）机制** ，它 **不以时间为驱动，而是以数据驱动重传** 。
快速重传机制，是如何工作的呢？其实很简单，一图胜千言。


#### 在上图，发送方发出了 1 ， 2 ， 3 ， 4 ， 5 份数据：

第一份 Seq1 先送到了，于是就 Ack 回 2 ；
结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2 ；
后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2 ，因为 Seq2 还是没有收到；
**发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。**
最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。
所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是 **重传的时候，是重
传之前的一个，还是重传所有的问题。**


比如对于上面的例子，是重传三个 Ack 2 是谁传回来的。 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的

根据 TCP 不同的实现，以上两种情况都是有可能的。可⻅，这是一把双刃剑。
为了解决不知道该重传哪些 TCP 报文，于是就有 SACK 方法。

### SACK 方法

还有一种实现重传机制的方式叫：SACK（ Selective Acknowledgment 选择性确认）。
这种方式需要在方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以 TCP 头部「选项」字段里加一个 SACK 的东⻄，它 **可以将缓存的地图发送给发送方只重传丢失的数据** 。 ，这样发送

如下图，发送方收到了三次同样的200~299 这段数据丢失，则重发时，就只选择了这个 ACK 确认报文，于是就会触发快速重发机制，通过 TCP 段进行重复。 SACK 信息发现只有

如果要支持2.4 后默认打开）。 SACK，必须双方都要支持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux

### Duplicate SACK

Duplicate SACK 又称 D-SACK，其主要 **使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**
下面举例两个栗子，来说明 D-SACK 的作用。


#### 栗子一号： ACK 丢包

#### 「接收方」发给「发送方」的两个 3499 ） ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~

#### 于是「接收方」发现数据是重复收到的，于是回了一个 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 SACK = 3000~3500 4000 之前的所有数据都已收到，所以这个，告诉「发送方」 3000~3500

#### SACK 就代表着 D-SACK 。

#### 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。

#### 栗子二号：网络延时


数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。
而后面报文到达的三个相同的（1000~1499）又到了「接收方」； ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包

**所以「接收方」回了一个示收到了重复的包。 SACK=1000~1500，因为 ACK 已经到了 3000 ，所以这个 SACK 是 D-SACK，表**

这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的延迟了。 ACK 包丢了，而是因为网络


#### 可⻅，D-SACK 有这么几个好处：

#### 1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;

#### 2. 可以知道是不是「发送方」的数据包被网络延迟了;

#### 3. 可以知道网络中是不是把「发送方」的数据包给复制了;

在 Linux 下可以通过 net.ipv4.tcp_dsack 参数开启/关闭这个功能（Linux 2.4 后默认打开）。

## 滑动窗口^

#### 引入窗口概念的原因

#### 我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。

#### 这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是效率比较低的。

#### 如果你说完一句话，我在处理其他事情，没有及时回复你，那你不是要干等着我做完其他事情后，我回复你，你才能说下一句话，很显然这不现实。


#### 所以，这样的传输方式有一个缺点：数据包的 往返时间越⻓，通信的效率就越低 。

#### 为解决这个问题，TCP 引入了 窗口 这个概念。即使在往返时间较⻓的情况下，它也不会降低网络通信的效率。

#### 那么有了窗口，就可以指定窗口大小，窗口大小就是指 无需等待确认应答，而可以继续发送数据的最大值 。

#### 窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

#### 假设窗口大小为通过「下一个确认应答进行确认」。如下图： 3 个 TCP 段，那么发送方就可以「连续发送」 3 个 TCP 段，并且中途若有 ACK 丢失，可以


#### 图中的 700 确认应答，就意味着 ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 700 之前的所有数据「接收方」都收到了。这个模式就叫 累计确认 或者 累计应答 。 ACK

#### 窗口大小由哪一方决定？

TCP 头里有一个字段叫 Window，也就是窗口大小。
**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

所以，通常窗口的大小是由接收方的窗口大小来决定的。
发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

```
发送方的滑动窗口
```
我们先来看看发送方的窗口，下图就是发送方缓存的数据，根据处理的情况分成四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口：


#### #1 是已发送并收到 ACK确认的数据：1~31 字节

#### #2 是已发送但未收到 ACK确认的数据：32~45 字节

#### #3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节

#### #4 是未发送但总大小超过接收方处理范围（接收方没有空间）： 52 字节以后

#### 在下图，当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为ACK 确认之前是无法继续发送数据了。 0 了，表明可用窗口耗尽，在没收到

#### 在下图，当收到之前发送的数据 32~36 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则 滑动窗口往

**右边移动** 可以发送 (^5) 52~56 **个字节，因为有** 这 5 个字节的数据了。 **5 个字节的数据被应答确认** ，接下来 52~56 字节又变成了可用窗口，那么后续也就

#### 程序是如何表示发送方的四个部分的呢？


#### TCP 定的序列号），一个是相对指针（需要做偏移）。滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特

#### SND.WND：表示发送窗口的大小（大小是由接收方指定的）；

#### 个字节。SND.UNA：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一

#### 字节。SND.NXT：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个

#### 指向#4 的第一个字节了。 #4 的第一个字节是个相对指针，它需要 SND.UNA 指针加上 SND.WND 大小的偏移量，就可以指向

#### 那么可用窗口大小的计算就可以是：

#### 可用窗口大 = SND.WND -（SND.NXT - SND.UNA）

#### 接收方的滑动窗口

#### 接下来我们看看接收方的窗口，接收窗口相对简单一些，根据处理的情况划分成三个部分：

#### #1 + #2 是已成功接收并确认的数据（等待应用进程读取）；

#### #3 是未收到数据但可以接收的数据；

#### #4 未收到数据并不可以接收的数据；


#### 其中三个接收部分，使用两个指针进行划分:

#### RCV.WND：表示接收窗口的大小，它会通告给发送方。

#### 节。RCV.NXT：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字

#### 指向#4 的第一个字节了。 #4 的第一个字节是个相对指针，它需要 RCV.NXT 指针加上 RCV.WND 大小的偏移量，就可以指向

#### 接收窗口和发送窗口的大小是相等的吗？

#### 并不是完全相等，接收窗口的大小是 约等于 发送窗口的大小的。

因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过
程是存在时延的，所以接收窗口和发送窗口是约等于的关系。

## 流量控制^

#### 发送方不能无脑的发数据给接收方，要考虑接收方处理能力。

#### 如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。

#### 为了解决这种现象发生， 这就是所谓的流量控制。TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，

#### 下面举个栗子，为了简单起⻅，假设以下场景：

#### 客户端是接收方，服务端是发送方

#### 假设接收窗口和发送窗口相同，都为 200


#### 假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响


#### 根据上图的流量控制，说明下每个过程：

#### 1. 客户端向服务端发送请求数据报文。这里要说明下，本次例子是把服务端作为发送方，所以没有画出服务端的接收窗口。

2. 服务端收到请求报文后，发送确认报文和SND.NXT 指针也向右偏移 80 字节后，指向 80 字节的数据，于是可用窗口 321 ， **这意味着下次发送数据的时候，序列号是** Usable 减少为 (^120) **321** 字节，同时 **。**

3. 客户端收到 **望的下一个报文的序列号是** 80 字节数据后，于是接收窗口往右移动 **321** ，接着发送确认报文给服务端。 80 字节，RCV.NXT 也就指向 321 ， **这意味着客户端期**
4. 服务端再次发送了 120 字节数据，于是可用窗口耗尽为 0 ，服务端无法再继续发送数据。
5. 客户端收到报文给服务端。 120 字节的数据后，于是接收窗口往右移动 120 字节，RCV.NXT 也就指向 441 ，接着发送确认
6. 服务端收到对增大到 80 。 80 字节数据的确认报文后，SND.UNA 指针往右偏移后指向 321 ，于是可用窗口 Usable
7. 服务端收到对增大到 200 。 120 字节数据的确认报文后，SND.UNA 指针往右偏移后指向 441 ，于是可用窗口 Usable
8. 服务端可以继续发送了，于是发送了少到 40 。 160 字节的数据后，SND.NXT 指向 601 ，于是可用窗口 Usable 减
9. 客户端收到给服务端。 160 字节后，接收窗口往右移动了 160 字节，RCV.NXT 也就是指向了 601 ，接着发送确认报文
10. 服务端收到对 160 后指向 601 160 ，可用窗口字节数据的确认报文后，发送窗口往右移动了 Usable 也就增大至了 200 。 160 字节，于是 SND.UNA 指针偏移了

### 操作系统缓冲区与滑动窗口的关系

#### 前面的流量控制例子，我们假定了发送窗口和接收窗口是不变的，但是实际上，发送窗口和接收窗口中所存放的字

#### 节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会 被操作系统调整 。

#### 当应用进程没办法及时读取缓冲区的内容时，也会对我们的缓冲区造成影响。

#### 那操心系统的缓冲区，是如何影响发送窗口和接收窗口的呢？

#### 我们先来看看第一个例子。

#### 当应用程序没有及时读取缓存时，发送窗口和接收窗口的变化。


#### 考虑以下场景：

#### 客户端作为发送方，服务端作为接收方，发送窗口和接收窗口初始大小为 360 ；

#### 服务端非常的繁忙，当收到客户端的数据时，应用层不能及时读取数据。


#### 根据上图的流量控制，说明下每个过程：

#### 1. 客户端发送 140 字节数据后，可用窗口变为 220 （360 - 140）。

#### 2. 服务端收到 区，于是接收窗口收缩到了 140 字节数据， 260 但是服务端非常繁忙，应用进程只读取了（360 - 100） ，最后发送确认信息时，将窗口大小通告给客户端。 40 个字节，还有 100 字节占用着缓冲

#### 3. 客户端收到确认和窗口通告报文后，发送窗口减少为 260 。

#### 4. 客户端发送 180 字节数据，此时可用窗口减少到 80 。

5. 服务端收到 **口收缩到了** (^180) **80 （** 字节数据， **260 - 180）但是应用程序没有读取任何数据，这** ，并在发送确认信息时，通过窗口大小给客户端。 **180 字节直接就留在了缓冲区，于是接收窗**

6. 客户端收到确认和窗口通告报文后，发送窗口减少为 80 。
7. 客户端发送 80 字节数据后，可用窗口耗尽。
8. 服务端收到 **缩到了 0** ，并在发送确认信息时，通过窗口大小给客户端。 80 字节数据， **但是应用程序依然没有读取任何数据，这 80 字节留在了缓冲区，于是接收窗口收**
9. 客户端收到确认和窗口通告报文后，发送窗口减少为 0 。
可⻅最后窗口都收缩为探测报文，以便知道接收方的窗口是否发生了改变，这个内容后面会说，这里先简单提一下。 0 了，也就是发生了窗口关闭。当发送方可用窗口变为 0 时，发送方实际上会定时发送窗口

我们先来看看第二个例子。
当服务端系统资源非常紧张的时候，操心系统可能会直接减少了接收缓冲区大小，这时应用程序又无法及时读取缓存数据，那么这时候就有严重的事情发生了，会出现数据包丢失的现象。


#### 说明下每个过程：

#### 1. 客户端发送 140 字节的数据，于是可用窗口减少到了 220 。

#### 2. 服务端因为现在非常的繁忙，操作系统于是就把接收缓存减少了应用程序没有读取任何数据，所以 140 字节留在了缓冲区中，于是接收窗口大小从 120 字节，当收到 140 360 字节数据后，又因为收缩成了 100 ，最后

#### 发送确认信息时，通告窗口大小给对方。

#### 3. 此时客户端因为还没有收到服务端的通告窗口报文，所以不知道此时接收窗口收缩成了自己的可用窗口还有 220 ，所以客户端就发送了 180 字节数据，于是可用窗口减少到 40 100 。，客户端只会看

#### 4. 服务端收到了 180 字节数据时， 发现数据大小超过了接收窗口的大小，于是就把数据包丢失了。

#### 5. 客户端收到第左收缩了 80 ，此时可用窗口的大小就会出现诡异的负值。 2 步时，服务端发送的确认报文和通告窗口报文，尝试减少发送窗口到 100 ，把窗口的右端向


#### 所以，如果发生了先减少缓存，再收缩窗口，就会出现丢包的现象。

#### 为了防止这种情况发生，存，这样就可以避免了丢包情况。TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓

### 窗口关闭

#### 在前面我们都看到了，TCP 通过让接收方指明希望从发送方接收的数据大小（窗口大小）来进行流量控制。

#### 如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。

#### 窗口关闭潜在的危险

#### 接收方向发送方通告窗口大小时，是通过 ACK 报文来通告的。

#### 那么，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非的 ACK 报文在网络中丢失了，那麻烦就大了。 0 的 ACK 报文，如果这个通告窗口


#### 这会导致发送方一直等待接收方的非的过程，会造成了死锁的现象。 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待

#### TCP 是如何解决窗口关闭时，潜在的死锁现象呢？

#### 为了解决这个问题， 续计时器。 TCP 为每个连接设有一个持续定时器， 只要 TCP 连接一方收到对方的零窗口通知，就启动持

如果持续计时器超时，就会发送 **probe ) 报文** ，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。 **窗口探测 ( Window**

#### 如果接收窗口仍然为 0 ，那么收到这个报文的一方就会重新启动持续计时器；

#### 如果接收窗口不是 0 ，那么死锁的局面就可以被打破了。

#### 窗口探测的次数一般为话，有的 TCP 实现就会发 3 次，每次大约 RST 报文来中断连接。 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的


### 糊涂窗口综合症

#### 如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。

#### 到最后， 这就是糊涂窗口综合症如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节， 。

#### 要知道，我们的了。 TCP + IP 头有 40 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济

#### 就好像一个可以承载不然迟早破产。要解决这个问题也不难，大巴司机等乘客数量超过了 50 人的大巴⻋，每次来了一两个人，就直接发⻋。除非家里有矿的大巴司机，才敢这样玩， 25 个，才认定可以发⻋。

#### 现举个糊涂窗口综合症的栗子，考虑以下场景：

#### 接收方的窗口大小是 360 字节，但接收方由于某些原因陷入困境，假设接收方的应用层读取的能力如下：

#### 接收方每接收 3 个字节，应用程序就只能从缓冲区中读取 1 个字节的数据；

#### 在下一个发送方的 TCP 段到达之前，应用程序还从缓冲区中读取了 40 个额外的字节；


#### 每个过程的窗口大小的变化，在图中都描述的很清楚了，可以发现窗口不断减少了，并且发送的数据都是比较小的了。

#### 所以，糊涂窗口综合症的现象是可以发生在发送方和接收方：

#### 接收方可以通告一个小的窗口

#### 而发送方可以发送小数据

#### 于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了

#### 让接收方不通告小窗口给发送方

#### 让发送方避免发送小数据


#### 怎么让接收方不通告小窗口呢？

#### 接收方通常的策略如下:

当「窗口大小」小于告窗口为 0 ，也就阻止了发送方再发数据过来。 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通

等到接收方处理了一些数据后，窗口大小送方发送数据过来。 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发

```
怎么让发送方避免发送小数据呢？
```
发送方通常的策略:
使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：
要等到窗口大小 >= MSS 或是 数据大小 >= MSS
收到之前发送数据的 ack 回包
只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。
另外，性比较强的程序，则需要关闭Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如， Nagle 算法。 telnet 或 ssh 这样的交互

可以在自己的特点来关闭） Socket 设置 TCP_NODELAY 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用

## 拥塞控制^

#### 为什么要有拥塞控制呀，不是有流量控制了吗？

#### 前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。

#### 一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。

#### 在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放 TCP 就会重传数据，但是

#### 大....

```
setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&value, sizeof(int));
```

#### 所以，发送的数据量。TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低

#### 于是，就有了 拥塞控制 ，控制的目的就是 避免「发送方」的数据填满整个网络。

#### 为了在「发送方」调节所要发送数据的量，定义了一个叫做「 拥塞窗口 」的概念。

#### 什么是拥塞窗口？和发送窗口有什么关系呢？

**拥塞窗口 cwnd** 是发送方维护的一个的状态变量，它会根据 **网络的拥塞程度动态变化的** 。
我们在前面提到过发送窗口时发送窗口的值是swnd = min(cwnd, rwnd) swnd 和接收窗口，也就是拥塞窗口和接收窗口中的最小值。 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此

拥塞窗口 cwnd 变化的规则：
只要网络中没有出现拥塞，cwnd 就会增大；
但网络中出现了拥塞，cwnd 就减少；
那么怎么知道当前网络是否出现了拥塞呢？

其实只要「发送方」没有在规定时间内接收到 **塞。** ACK 应答报文，也就是 **发生了超时重传，就会认为网络出现了用拥**

```
拥塞控制有哪些控制算法？
```
拥塞控制主要是四个算法：
慢启动
拥塞避免
拥塞发生
快速恢复

### 慢启动

#### TCP 如果一上来就发大量的数据，这不是给网络添堵吗？在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，

慢启动的算法记住一个规则就行： **当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1 。**
这里假定拥塞窗口 cwnd 和发送窗口 swnd 相等，下面举个栗子：


```
连接建立完成后，一开始初始化 cwnd = 1，表示可以传一个 MSS 大小的数据。
当收到一个 ACK 确认应答后，cwnd 增加 1 ，于是一次能够发送 2 个
当收到 2 个的 ACK 确认应答后， cwnd 增加 2 ，于是就可以比之前多发 2 个，所以这一次能够发送 4 个
当这 4 个，所以这一次能够发送 4 个的 ACK 确认到来的时候，每个确认 8 个。 cwnd 增加 1 ， 4 个确认 cwnd 增加 4 ，于是就可以比之前多发
```
#### 可以看出慢启动算法，发包的个数是 指数性的增⻓ 。

#### 那慢启动涨到什么时候是个头呢？

有一个叫慢启动⻔限 ssthresh （slow start threshold）状态变量。
当 cwnd < ssthresh 时，使用慢启动算法。
当 cwnd >= ssthresh 时，就会使用「拥塞避免算法」。

### 拥塞避免算法

前面说道，当拥塞窗口 cwnd 「超过」慢启动⻔限 ssthresh 就会进入拥塞避免算法。
一般来说 ssthresh 的大小是 65535 字节。
那么进入拥塞避免算法后，它的规则是： **每当收到一个 ACK 时，cwnd 增加 1/cwnd。**


接上前面的慢启动的栗子，现假定 ssthresh 为 8 ：

当个 (^8) MSS个 ACK 大小的数据，变成了应答确认到来时，每个确认增加 **线性增⻓。** 1/8， 8 个 ACK 确认 cwnd 一共增加 1 ，于是这一次能够发送 9

#### 所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增⻓变成了线性增⻓，还是增⻓阶段，但是增⻓速度缓慢了一些。

#### 就这么一直增⻓着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

#### 当触发了重传机制，也就进入了「拥塞发生算法」。


### 拥塞发生

#### 当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

#### 超时重传

#### 快速重传

#### 这两种使用的拥塞发送算法是不同的，接下来分别来说说。

#### 发生超时重传的拥塞发生算法

#### 当发生了「超时重传」，则就会使用拥塞发生算法。

这个时候，ssthresh 和 cwnd 的值会发生变化：
ssthresh 设为 cwnd/2，
cwnd 重置为 1


#### 接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，⻢上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。

#### 就好像本来在秋名山高速漂移着，突然来个紧急刹⻋，轮胎受得了吗。。。

#### 发生快速重传的拥塞发生算法

#### 还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 ssthresh 和 cwnd 变化如下：
cwnd = cwnd/2 ，也就是设置为原来的一半;
ssthresh = cwnd;
进入快速恢复算法

### 快速恢复

#### 快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到糕，所以没有必要像 RTO 超时那么强烈。 3 个重复 ACK 说明网络也不那么糟

正如前面所说，进入快速恢复之前，cwnd 和 ssthresh 已被更新了：
cwnd = cwnd/2 ，也就是设置为原来的一半;
ssthresh = cwnd;
然后，进入快速恢复算法如下：
拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）；
重传丢失的数据包；
如果再收到重复的 ACK，那么 cwnd 增加 1 ；
如果收到新数据的明从 duplicated ACK ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说
入拥塞避免状态；


#### 也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增⻓。

### 拥塞算法示意图

#### 好了，以上就是拥塞控制的全部内容了，看完后，你再来看下面这张图片，每个过程我相信你都能明白：


#### 参考资料：

#### [1] 趣谈网络协议专栏.刘超.极客时间

[2] Web协议详解与抓包实战专栏.陶辉.极客时间
[3] TCP/IP详解 卷 1 ：协议.范建华 译.机械工业出版社
[4] 图解TCP/IP.竹下隆史.人⺠邮电出版社
[5] The TCP/IP Guide.Charles M. Kozierok.
[6] TCPhttps://coolshell.cn/articles/11564.html那些事（上）.陈皓.酷壳博客.

[7] TCP那些事（下）.陈皓.酷壳博客.https://coolshell.cn/articles/11609.html

## 读者问答^

#### 读者问：会去确认）：“整个看完收获很大，下面是我的一些疑问（稍后

```
1.ACK拥塞避免这一段，蓝色字体：每当收到一个时，cwnd增加1/cwnd。是否应该是
1/ssthresh?2.快速重传的拥塞发生算法，步骤一和步骤否则不符合线性增⻓。 2 是
否写反了？否则快速恢复算法中最后一步【如果
```

```
收到新数据的ssthresh,接看就进入了拥塞避免算法】没什么ACK后，设置cwnd为
意义。3.对ssthresh的变化介绍的比较含糊。”
```
1. 是 1/cwnd，你可以在 RFC2581 第 3 ⻚找到答案
2. 没有写反，同样你可以在 RFC2581 第 5 ⻚找到答案
3. ssthresh 就是慢启动⻔限，我觉得 ssthresh 我已经说的很清楚了，当然你可以找其他资料补充你的疑惑

## 最后^

#### 是吧？ TCP 巨复杂吧？看完很累吧？

#### 但这还只是 TCP 冰山一脚，它的更深处就由你们自己去探索啦。

**小林是专为大家图解的工具人，Goodbye，我们下次⻅！**

## 3.3 TCP 实战抓包分析

(^) 容易分析的数据包。为了让大家更容易「看得⻅」 TCP，我搭建不少测试环境，并且数据包抓很多次，花费了不少时间，才抓到比较
接下来丢包、乱序、超时重传、快速重传、选择性确认、流量控制等等 TCP 的特性，都能「一览无余」。


#### 没错，我把 TCP 的"衣服扒光"了，就为了给大家看的清楚，嘻嘻。

## 显形“不可⻅”的网络包^

#### 网络世界中的数据包交互我们肉眼是看不⻅的，它们就好像隐形了一样，我们对着课本学习计算机网络的时候就会觉得非常的抽象，加大了学习的难度。

#### 还别说，我自己在大学的时候，也是如此。

直到工作后，认识了两大分析网络的利器：在我们眼前，一目了然。 **tcpdump 和 Wireshark** ，这两大利器把我们“看不⻅”的数据包，呈现

唉，当初大学学习计网的时候，要是能知道这两个工具，就不会学的一脸懵逼。

```
tcpdump 和 Wireshark 有什么区别？
```
tcpdump 和 Wireshark 就是最常用的网络抓包和分析工具，更是分析网络性能必不可少的利器。


tcpdump 仅支持命令行格式使用，常用在 Linux 服务器中抓取和分析网络包。
Wireshark 除了可以抓包外，还提供了可视化分析网络包的图形⻚面。
所以，这两者实际上是搭配使用的，先用Windows 电脑后，用 Wireshark 可视化分析。 tcpdump 命令在 Linux 服务器上抓包，接着把抓包的文件拖出到

当然，如果你是在 Windows 上抓包，只需要用 Wireshark 工具就可以。

```
tcpdump 在 Linux 下如何抓包？
```
tcpdump 握一些常用选项和过滤表达式，就可以满足大部分场景的需要了。提供了大量的选项以及各式各样的过滤表达式，来帮助你抓取指定的数据包，不过不要担心，只需要掌

假设我们要抓取下面的 ping 的数据包：

要抓取上面的候，就可以指定只抓 ping 命令数据包，首先我们要知道 icmp 协议的数据包： ping 的数据包是 icmp 协议，接着在使用 tcpdump 抓包的时


那么当 tcpdump 抓取到 icmp 数据包后， 输出格式如下：

从request tcpdump 请求报文，接收方收到后回了一个抓取的 icmp 数据包，我们很清楚的看到 ICMP echo reply icmp echo 响应报文，之后 的交互过程了，首先发送方发起了 seq 是递增的。 ICMP echo

我在这里也帮你整理了一些最常⻅的用法，并且绘制成了表格，你可以参考使用。
首先，先来看看常用的选项类，在上面的和端口名称解析。其他常用的选项，如下表格： ping 例子中，我们用过 -i 选项指定网口，用过 -nn 选项不对 IP 地址


接下来，我们再来看看常用的过滤表用法，在上面的183.232.231.174，表示抓取 icmp 协议的数据包，以及源地址或目标地址为 ping 例子中，我们用过的是 183.232.231.174 icmp and host的包。其他常用的
过滤选项，我也整理成了下面这个表格。

说了这么多，你应该也发现了，tcpdump 虽然功能强大，但是输出的格式并不直观。
所以，在工作中后缀的文件，接着用 tcpdump Wireshark 只是用来抓取数据包，不用来分析数据包，而是把工具进行数据包分析。 tcpdump 抓取的数据包保存成 pcap

```
Wireshark 工具如何分析数据包？
```
Wireshark 除了可以抓包外，还提供了可视化分析网络包的图形⻚面，同时，还内置了一系列的汇总分析工具。
比如，拿上面的 ping 例子来说，我们可以使用下面的命令，把抓取的数据包保存到 ping.pcap 文件

接着把 ping.pcap 文件拖到电脑，再用 Wireshark 打开它。打开后，你就可以看到下面这个界面：


是吧？在来区分不同的协议，由于这次抓包只有 Wireshark 的⻚面里，可以更加直观的分析数据包，不仅展示各个网络包的头部信息，还会用不同的颜色 ICMP 协议，所以只有紫色的条目。

接着，在网络包列表中选择某一个网络包后，在其下面的网络包详情中， **可以更清楚的看到，这个网络包在协议栈
各层的详细信息** 。比如，以编号 1 的网络包为例子：

#### 可以在数据链路层，看到 MAC 包头信息，如源 MAC 地址和目标 MAC 地址等字段；

#### 可以在数值和含义； IP 层，看到 IP 包头信息，如源 IP 地址和目标 IP 地址、TTL、IP 包⻓度、协议等 IP 协议各个字段的

可以在 ICMP 层，看到 ICMP 包头信息，比如 Type、Code 等 ICMP 协议各个字段的数值和含义；
Wireshark 由学不好计算机网络吗？是不是用了分层的方式，展示了各个层的包头信息，把 **相⻅恨晚** ？ “不可⻅”的数据包，清清楚楚的展示了给我们，还有理


从作后就交给下一层，最终形成一个完整的网络包。 ping 的例子中，我们可以看到网络分层就像有序的分工，每一层都有自己的责任范围和信息，上层协议完成工

## 解密 TCP 三次握手和四次挥手^

既然学会了包，并理解 tcpdump TCP 三次握手和四次挥手的工作原理。和 Wireshark 两大网络分析利器，那我们快⻢加鞭，接下用它俩抓取和分析 HTTP 协议网络

本次例子，我们将要访问的 [http://192.168.3.200](http://192.168.3.200) 服务端。在终端一用 tcpdump 命令抓取数据包：

接着，在终端二执行下面的 curl 命令：


最后，回到终端一，按下 Ctrl+C 停止 tcpdump，并把得到的 http.pcap 取出到电脑。
使用 Wireshark 打开 http.pcap 后，你就可以在 Wireshark 中，看到如下的界面：

#### 我们都知道 HTTP 是基于 TCP 协议进行传输的，那么：

#### 最开始的 3 个包就是 TCP 三次握手建立连接的包

#### 中间是 HTTP 请求和响应的包

#### 而最后的 3 个包则是 TCP 断开连接的挥手包

Wireshark Graph)，然后，在弹出的界面中的「流量类型」选择可以用时序图的方式显示数据包交互的过程，从菜单栏中，点击 「TCP Flows」，你可以更清晰的看到，整个过程中 统计 (Statistics) -> 流量图 (Flow TCP (^) 流
的执行过程：


```
你可能会好奇，为什么三次握手连接过程的 Seq 是 0 ？
```
实际上是因为 Wireshark 工具帮我们做了优化，它默认显示的是序列号 seq 是相对值，而不是真实值。
如果你想看到实际的序列号的值，可以右键菜单，给取消，操作如下： 然后找到「协议首选项」，接着找到「Relative Seq」后，把它


取消后，Seq 显示的就是真实值了：

#### 可⻅，客户端和服务端的序列号实际上是不同的，序列号是一个随机值。


#### 这其实跟我们书上看到的流程，基本是这样的： TCP 三次握手和四次挥手很类似，作为对比，你通常看到的 TCP 三次握手和四次挥手的


#### 为什么抓到的 TCP 挥手是三次，而不是书上说的四次？

因为服务器端收到客户端的送，节省了一个包，变成了 (^) “三次挥手FIN 后，服务器端同时也要关闭连接，这样就可以把”。 ACK 和 FIN 合并到一起发
而通常情况下，服务器端收到客户端的包，稍等一会儿，完成所有数据包的发送后，才会发送 FIN 后，很可能还没发送完数据，所以就会先回复客户端一个 FIN 包，这也就是四次挥手了。 ACK
如下图，就是四次挥手的过程：

## TCP 三次握手异常情况实战分析^

#### TCP 三次握手的过程相信大家都背的滚瓜烂熟，那么你有没有想过这三个异常情况：

#### TCP 第一次握手的 SYN 丢包了，会发生了什么？

#### TCP 第二次握手的 SYN、ACK 丢包了，会发生什么？

#### TCP 第三次握手的 ACK 包丢了，会发生什么？

#### 有的小伙伴可能说：“很简单呀，包丢了就会重传嘛。”


#### 那我在继续问你：

#### 那会重传几次？

#### 超时重传的时间 RTO 会如何变化？

在 Linux 下如何设置重传次数？
....
是不是哑口无言，无法回答？
不知道没关系，接下里我用三个实验案例，带大家一起探究探究这三种异常。

### 实验场景

#### 本次实验用了两台虚拟机，一台作为服务端，一台作为客户端，它们的关系如下：

```
客户端和服务端都是 CentOs 6.5 Linux，Linux 内核版本 2.6.32
服务端 192.168.12.36，apache web 服务
客户端 192.168.12.37
```
### 实验一：TCP 第一次握手 SYN 丢包

为了模拟 TCP 第一次握手 SYN 丢包的情况，我是在拔掉服务器的网线后，立刻在客户端执行 curl 命令：


其间 tcpdump 抓包的命令如下：

过了一会， curl 返回了超时连接的错误：

从 date 返回的时间，可以发现在超时接近 1 分钟的时间后，curl 返回了错误。
接着，把 tcp_sys_timeout.pcap 文件用 Wireshark 打开分析，显示如下图：


#### 从上图可以发现，RTO 超时时间是不同的： 客户端发起了 SYN 包后，一直没有收到服务端的 ACK ，所以一直超时重传了 5 次，并且每次

#### 第一次是在 1 秒超时重传

#### 第二次是在 3 秒超时重传

#### 第三次是在 7 秒超时重传

#### 第四次是在 15 秒超时重传

#### 第五次是在 31 秒超时重传

#### 可以发现，每次超时时间 RTO 是 指数（翻倍）上涨的 ，当超过最大重传次数后，客户端不再发送 SYN 包。

在 Linux 中，第一次握手的 SYN 超时重传次数，是如下内核参数指定的：

tcp_syn_retries 默认值为 5 ，也就是 SYN 最大重传次数是 5 次。
接下来，我们继续做实验，把 tcp_syn_retries 设置为 2 次：

重传抓包后，用 Wireshark 打开分析，显示如下图：

#### 实验一的实验小结

#### 通过实验一的实验结果，我们可以得知，当客户端发起的ACK，就会在超时重传 SYN 数据包，每次超时重传的 RTO TCP 是翻倍上涨的，直到第一次握手 SYN 包，在超时时间内没收到服务端的 SYN 包的重传次数到达

```
tcp_syn_retries 值后，客户端不再发送 SYN 包。
```
```
$ cat 5 /proc/sys/net/ipv4/tcp_syn_retries
```
```
$ echo 2 > /proc/sys/net/ipv4/tcp_syn_retries
```


### 实验二：TCP 第二次握手 SYN、ACK 丢包

#### 为了模拟客户端收不到服务端第二次握手自服务端的数据都丢弃，防火墙的配置如下： SYN、ACK 包，我的做法是在客户端加上防火墙限制，直接粗暴的把来

接着，在客户端执行 curl 命令：

从 date 返回的时间前后，可以算出大概 1 分钟后，curl 报错退出了。
客户端在这其间抓取的数据包，用 Wireshark 打开分析，显示的时序图如下：


#### 从图中可以发现：

客户端发起包，当发生超时后，就会重传 SYN 后，由于防火墙屏蔽了服务端的所有数据包，所以 SYN 包 curl 是无法收到服务端的 SYN、ACK
服务端收到客户的了 SYN、ACK 包， SYN **接着一会，客户端超时重传的** 包后，就会回 SYN、ACK **SYN** 包，但是客户端一直没有回 **包又抵达了服务端，服务端收到后，超时定时器就重** ACK，服务端在超时后，重传
**新计时，然后回了 SYN、ACK 包，所以相当于服务端的超时定时器只触发了一次，又被重置了。**
最后，客户端 SYN 超时重传次数达到了 5 次（tcp_syn_retries 默认值 5 次），就不再继续发送 SYN 包了。
所以，我们可以发现， **SYN、ACK 包。 当第二次握手的 SYN、ACK 丢包时，客户端会超时重发 SYN 包，服务端也会超时重传**

```
咦？客户端设置了防火墙，屏蔽了服务端的网络包，为什么 tcpdump 还能抓到服务端的网络包？
```
添加 iptables 限制后， tcpdump 是否能抓到包 ，这要看添加的 iptables 限制条件：
如果添加的是 INPUT 规则，则可以抓得到包
如果添加的是 OUTPUT 规则，则抓不到包
网络包进入主机后的顺序如下：

```
进来的顺序 Wire -> NIC -> tcpdump -> netfilter/iptables
```

```
出去的顺序 iptables -> tcpdump -> NIC -> Wire
tcp_syn_retries 是限制 SYN 重传次数，那第二次握手 SYN、ACK 限制最大重传次数是多少？
```
TCP 第二次握手 SYN、ACK 包的最大重传次数是通过 tcp_synack_retries 内核参数限制的，其默认值如下：

#### 是的，TCP 第二次握手 SYN、ACK 包的最大重传次数默认值是 5 次。

为了验证 1 ，表示客户端 SYN、 SYN ACK 最大超时次数是包最大重传次数是 1 次，目的是为了防止多次重传 5 次，我们继续做下实验，我们先把客户端的 SYN，把服务端 SYN tcp_syn_retries、ACK 超时定时器重 设置为
置。
接着，还是如上面的步骤：

1. 客户端配置防火墙屏蔽服务端的数据包
2. 客户端 tcpdump 抓取 curl 执行时的数据包
把抓取的数据包，用 Wireshark 打开分析，显示的时序图如下：

#### 从上图，我们可以分析出：

```
客户端的 SYN 只超时重传了 1 次，因为 tcp_syn_retries 值为 1
服务端应答了客户端超时重传的SYN、ACK 包，每次的 RTO 也是指数上涨的，一共超时重传了 SYN 包后，由于一直收不到客户端的 5 次，因为 ACK 包，所以服务端一直在超时重传tcp_synack_retries 值为 5
```
```
$ cat 5 /proc/sys/net/ipv4/tcp_synack_retries
```

接着，我把 **tcp_synack_retries 设置为 2** ，tcp_syn_retries 依然设置为 1:

依然保持一样的实验步骤进行操作，接着把抓取的数据包，用 Wireshark 打开分析，显示的时序图如下：

#### 可⻅：

```
客户端的 SYN 包只超时重传了 1 次，符合 tcp_syn_retries 设置的值；
服务端的 SYN、ACK 超时重传了 2 次，符合 tcp_synack_retries 设置的值
实验二的实验小结
```
通过实验二的实验结果，我们可以得知，当传，服务端 SYN、ACK 也会发生超时重传。 TCP 第二次握手 SYN、ACK 包丢了后，客户端 SYN 包会发生超时重

客户端的最大次数，是由 SYN 包超时重传的最大次数，是由 tcp_synack_retries 决定的，默认值是 tcp_syn_retries 5 决定的，默认值是次。 5 次；服务端 SYN、ACK 包时重传

### 实验三：TCP 第三次握手 ACK 丢包

为了模拟ACK 的包，也就是当服务端收到客户端的 TCP 第三次握手 ACK 包丢，我的实验方法是在服务端配置防火墙，屏蔽客户端 TCP ACK 的报文时就会丢弃，iptables 配置命令如下： TCP 报文中标志位是

```
$ echo$ echo 21 > /proc/sys/net/ipv4/tcp_synack_retries > /proc/sys/net/ipv4/tcp_syn_retries
```

接着，在客户端执行如下 tcpdump 命令：

然后，客户端向服务端发起 telnet，因为 telnet 命令是会发起 TCP 连接，所以用此命令做测试：

#### 此时，由于服务端收不到第三次握手的 ACK 包，所以一直处于 SYN_RECV 状态：


#### 而客户端是已完成 TCP 连接建立，处于 ESTABLISHED 状态：

#### 过了 1 分钟后，观察发现服务端的 TCP 连接不⻅了：

#### 过了 30 分别，客户端依然还是处于 ESTABLISHED 状态：

接着，在刚才客户端建立的 telnet 会话，输入 123456 字符，进行发送：


持续「好⻓」一段时间，客户端的 telnet 才断开连接：

#### 以上就是本次的实现三的现象，这里存在两个疑点：

#### 为什么服务端原本处于 SYN_RECV 状态的连接，过 1 分钟后就消失了？

```
为什么客户端 telnet 输入 123456 字符后，过了好⻓一段时间，telnet 才断开连接？
```

不着急，我们把刚抓的数据包，用 Wireshark 打开分析，显示的时序图如下：

#### 上图的流程：

#### 客户端发送SYN_RECV SYN 状态；包给服务端，服务端收到后，回了个 SYN、ACK 包给客户端，此时服务端的 TCP 连接处于

#### 客户端收到服务端的ESTABLISHED 状态； SYN、ACK 包后，给服务端回了个 ACK 包，此时客户端的 TCP 连接处于

由于服务端配置了防火墙，屏蔽了客户端的ESTABLISHED 状态，tcpdump 之所以能抓到客户端的 ACK 包，所以服务端一直处于 ACK 包，是因为数据包进入系统的顺序是先进入 SYN_RECV 状态，没有进入 (^)
tcpudmp，后经过 iptables；


接着，服务端超时重传了 **5 ），然后就没有继续重传了，此时服务端的** SYN、ACK 包，重传了 **TCP** (^5) **连接主动中止了，所以刚才处于** 次后，也就是 **超过 tcp_synack_retries SYN_RECV 的值（默认值是状态的 TCP** (^)
**连接断开了** ，而客户端依然处于ESTABLISHED 状态；
虽然服务端telnet 会话输入了 TCP 断开了，但过了一段时间，发现客户端依然处于 123456 字符； ESTABLISHED 状态，于是就在客户端的
此时由于服务端已经断开连接， **⻓的，所以持续了好⻓一段时间，客户端的客户端发送的数据报文，一直在超时重传，每一次重传， telnet 才报错退出了，此时共重传了 15 次。RTO 的值是指数增**
通过这一波分析，刚才的两个疑点已经解除了：
服务端在重传开了。 SYN、ACK 包时，超过了最大重传次数 tcp_synack_retries，于是服务端的 TCP 连接主动断
客户端向服务端发送数据包时，由于服务端的 15 次， telnet 就断开了连接。 TCP 连接已经退出了，所以数据包一直在超时重传，共重传了
TCP 最大次数是由第一次握手的 tcp_synack_retries SYN 包超时重传最大次数是由指定，那 TCP 建立连接后的数据包最大超时重传次数是由什么参数指定呢？ tcp_syn_retries 指定，TCP 第二次握手的 SYN、ACK 包超时重传
TCP 建立连接后的数据包传输，最大超时重传次数是由 tcp_retries2 指定，默认值是 15 次，如下：

#### 如果 15 次重传都做完了，TCP 就会告诉应用层说：“搞不定了，包怎么都传不过去！”

#### 那如果客户端不发送数据，什么时候才会断开处于 ESTABLISHED 状态的连接？

#### 这里就需要提到 TCP 的 保活机制 。这个机制的原理是这样的：

#### 定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，隔，发送一个「探测报文」，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前TCP 保活机制会开始作用，每隔一个时间间

#### 的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：

tcp_keepalive_time=7200动，则会启动保活机制 ：表示保活时间是 7200 秒（ 2 小时），也就 2 小时内如果没有任何连接相关的活
tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；
tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。
也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。

```
$ cat /proc/sys/net/ipv4/tcp_retries2 15
```
```
net.ipv4.tcp_keepalive_time=7200net.ipv4.tcp_keepalive_intvl=75
net.ipv4.tcp_keepalive_probes=9
```

#### 这个时间是有点⻓的，所以如果我抓包足够久，或许能抓到探测报文。

#### 实验三的实验小结

#### 在建立客户端会处于 TCP 连接时，如果第三次握手的 ESTABLISHED 状态。 ACK，服务端无法收到，则服务端就会短暂处于 SYN_RECV 状态，而

由于服务端一直收不到tcp_synack_retries 值（默认值 TCP 第三次握手的 5 次）后，服务端就会断开 ACK，则会一直重传 TCP SYN连接。、ACK 包，直到重传次数超过

而客户端则会有两种情况：
如果客户端没发送数据包，一直处于「死亡」连接，于是客户端连接就会断开连接。 ESTABLISHED 状态，然后经过 2 小时 11 分 15 秒才可以发现一个
如果客户端发送了数据包，一直没有收到服务端对该数据包的确认报文，则会一直重传该数据包，直到重传次数超过 tcp_retries2 值（默认值 15 次）后，客户端就会断开 TCP 连接。

## TCP 快速建立连接^

#### 客户端在向服务端发起 HTTP GET 请求时，一个完整的交互过程，需要 2.5 个 RTT 的时延。

#### 由于第三次握手是可以携带数据的，这时如果在第三次握手发起 HTTP GET 请求，需要 2 个 RTT 的时延。

#### 但是在下一次（不是同个 TCP 连接的下一次）发起 HTTP GET 请求时，经历的 RTT 也是一样，如下图：


在 Linux 3.7 内核版本中，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。


在第一次建立连接的时候，服务端在第二次握手产生一个给客户端，于是客户端就会缓存这个 Cookie，所以第一次发起 Cookie HTTP Get （已加密）并通过请求的时候，还是需要 SYN、ACK 包一起发 2 个 RTT
的时延；
在下次请求的时候，客户端在Cookie 中维护了一些信息，服务端可以从 SYN 包带上 Cookie Cookie 发给服务端，就提前可以跳过三次握手的过程，因为 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就
只需要 1 个 RTT 的时延；
注：客户端在请求并存储了（通常为过期） Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为 Cookie 无效

```
在 Linux 上如何打开 Fast Open 功能？
```
可以通过设置 net.ipv4.tcp_fastopn 内核参数，来打开 Fast Open 功能。
net.ipv4.tcp_fastopn 各个值的意义:


#### 0 关闭

```
1 作为客户端使用 Fast Open 功能
2 作为服务端使用 Fast Open 功能
3 无论作为客户端还是服务器，都可以使用 Fast Open 功能
TCP Fast Open 抓包分析
```
在下图，数据包 7 号，客户端发起了第二次 TCP 连接时，SYN 包会携带 Cooike，并且⻓度为 5 的数据。
服务端收到后，校验1 = 6 Cooike 合法，于是就回了 SYN、ACK 包，并且确认应答收到了客户端的数据包，ACK = 5 +

## TCP 重复确认和快速重传^

#### 当接收方收到乱序数据包时，会发送重复的 ACK，以便告知发送方要重发该数据包， 当发送方收到 3 个重复 ACK

#### 时，就会触发快速重传，立刻重发丢失数据包。


TCP 重复确认和快速重传的一个案例，用 Wireshark 分析，显示如下：


数据包于是回了数据包 1 期望的下一个数据包 3 ，还是同样的 Seq Seq = 1是 1 ，但是数据包，Ack = 1，这表明是重复的 2 发送的 Seq 却是 ACK (^10945) ； ，说明收到的是乱序数据包，
数据包 4 和 6 依然是乱序的数据包，于是依然回了重复的 ACK；
当对方收到三次重复的 ACK 后，于是就快速重传了 Seq = 1 、Len = 1368 的数据包 8 ；
当收到重传的数据包后，发现 Seq = 1 是期望的数据包，于是就发送了个确认收到快速重传的 ACK
注意：快速重传和重复 ACK 标记信息是 Wireshark 的功能，非数据包本身的信息。
以上案例在据包之后还成功接收了其他数据包，也只需要重传丢失的数据包。如果不启用 TCP 三次握手时协商开启了 **选择性确认 SACK** ，因此一旦数据包丢失并收到重复 SACK，就必须重传丢失包之后的每 ACK ，即使在丢失数
个数据包。
如果要支持2.4 后默认打开）。 SACK，必须双方都要支持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux

## TCP 流量控制^

#### TCP 接收窗口来控制发送方要发送的数据量，也就是流量控制。为了防止发送方无脑的发送数据，导致接收方缓冲区被填满，所以就有了滑动窗口的机制，它可利用接收方的

#### 接收窗口是由接收方指定的值，存储在是给应用程序读取数据的空间： TCP 头部中，它可以告诉发送方自己的 TCP 缓冲空间区大小，这个缓冲区

#### 如果应用程序读取了缓冲区的数据，那么缓冲空间区就会把被读取的数据移除

#### 如果应用程序没有读取数据，则数据会一直滞留在缓冲区。


#### 接收窗口的大小，是在前的接收窗口的大小，以此来告知发送方。 TCP 三次握手中协商好的，后续数据传输时，接收方发送确认应答 ACK 报文时，会携带当

#### 假设接收方接收到数据后，应用层能很快的从缓冲区里读取数据，那么窗口大小会一直保持不变，过程如下：

#### 但是现实中服务器会出现繁忙的情况，当应用程序读取速度慢，那么缓存空间会慢慢被占满，于是为了保证发送方发送的数据不会超过缓冲区大小，服务器则会调整窗口大小的值，接着通过 ACK 报文通知给对方，告知现在的接

#### 收窗口大小，从而控制发送方发送的数据大小。


### 零窗口通知与窗口探测

#### 假设接收方处理数据的速度跟不上接收数据的速度，缓存就会被占满，从而导致接收窗口为窗口通知时，就会停止发送数据。 0 ，当发送方接收到零

#### 如下图，可以看到接收方的窗口大小在不断的收缩至 0 ：

#### 接着，发送方会 定时发送窗口大小探测报文 ，以便及时知道接收方窗口大小的变化。


以下图 Wireshark 分析图作为例子说明：

#### 发送方发送了数据包 1 给接收方，接收方收到后，由于缓冲区被占满，回了个零窗口通知；

```
发送方收到零窗口通知后，就不再发送数据了，直到过了就是窗口大小探测报文； 3.4 秒后，发送了一个 TCP Keep-Alive 报文，也
当接收方收到窗口探测报文后，就立⻢回一个窗口通知，但是窗口大小还是 0 ；
发送方发现窗口还是窗口为 0 的通知； 0 ，于是继续等待了 6.8（翻倍） 秒后，又发送了窗口探测报文，接收方依然还是回了
发送方发现窗口还是了窗口为 0 的通知； 0 ，于是继续等待了 13.5（翻倍） 秒后，又发送了窗口探测报文，接收方依然还是回
```
可以发现，这些窗口探测报文以 3.4s、6.5s、13.5s 的间隔出现，说明超时时间会 **翻倍** 递增。
这连接暂停了 25s，想象一下你在打王者的时候，25s 的延迟你还能上王者吗？

### 发送窗口的分析

```
在 Wireshark 看到的 Windows size 也就是 " win = "，这个值表示发送窗口吗？
```
这不是发送窗口，而是在向对方声明自己的接收窗口。
你可能会好奇，抓包文件里有「「Window size value」实际上并不是真实的窗口大小，真实窗口大小的计算公式如下：Window size scaling factor」，它其实是算出实际窗口大小的乘法因子，

「Window size value」 * 「Window size scaling factor」 = 「Caculated window size 」
对应的下图案例，也就是 32 * 2048 = 65536。


实际上是size value Caculated window size 的值是在 TCP 头部中，其中的值是 Window size scaling factor Wireshark 工具帮我们算好的，是在三次握手过程中确定的，如果你抓包的数Window size scaling factor 和 Windos
据没有 TCP 三次握手，那可能就无法算出真实的窗口大小的值，如下图：

#### 如何在包里看出发送窗口的大小？

很遗憾，没有简单的办法，发送窗口虽然是由接收窗口决定，但是它又可以被网络因素影响，也就是拥塞窗口，实际上发送窗口是值是 min(拥塞窗口，接收窗口)。


#### 发送窗口和 MSS 有什么关系？

#### 发送窗口决定了一口气能发多少字节，而 MSS 决定了这些字节要分多少包才能发完。

#### 举个例子，如果发送窗口为包。 16000 字节的情况下，如果 MSS 是 1000 字节，那就需要发送 1600/1000 = 16 个

```
发送方在一个窗口发出 n 个包，是不是需要 n 个 ACK 确认报文？
```
不一定，因为了。 TCP 有累计确认机制，所以当收到多个数据包时，只需要应答最后一个数据包的 ACK 报文就可以

## TCP 延迟确认与 Nagle 算法^

#### 当我们中都会有 TCP 20 报文的承载的数据非常小的时候，例如几个字节，那么整个网络的效率是很低的，因为每个个字节的 TCP 头部，也会有 20 个字节的 IP 头部，而数据只有几个字节，所以在整个报文中有效数据 TCP 报文

#### 占有的比重就会非常低。

#### 这就好像快递员开着大货⻋送一个小包裹一样浪费。

#### 那么就出现了常⻅的两种策略，来减少小报文的传输，分别是：

```
Nagle 算法
延迟确认
Nagle 算法是如何避免大量 TCP 小数据报文的传输？
```
Nagle 算法做了一些策略来避免过多的小数据报文发送，这可提高传输效率。
Nagle 算法的策略：
没有已发送未确认报文时，立刻发送数据。
存在未确认报文时，直到「没有已发送未确认报文」或「数据⻓度达到 MSS 大小」时，再发送数据。
只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。


上图右侧启用了 Nagle 算法，它的发送数据的过程：
一开始由于没有已发送未确认的报文，所以就立刻发了 H 字符；
接着，在还没收到对发送未确认的报文，于是就把囤积后的 H 字符的确认报文时，发送方就一直在囤积数据，直到收到了确认报文后，此时没有已 ELL 字符一起发给了接收方；
待收到对 ELL 字符的确认报文后，于是把最后一个 O 字符发送了出去
可以看出， **Nagle 算法一定会有一个小报文，也就是在最开始的时候。**
另外，性比较强的程序，则需要关闭Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如， Nagle 算法。 telnet 或 ssh 这样的交互

可以在自己的特点来关闭）。 Socket 设置 TCP_NODELAY 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用


#### 那延迟确认又是什么？

#### 事实上当没有携带数据的带数据报文。 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携

#### 为了解决 ACK 传输效率低问题，所以就衍生出了 TCP 延迟确认 。

#### TCP 延迟确认的策略：

#### 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方

#### 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送

#### 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK


延迟等待的时间是在 Linux 内核中定义的，如下图：


关键就需要大小是 1000 HZ，如下图： 这个数值大小，HZ 是跟系统的时钟频率有关，每个操作系统都不一样，在我的 Linux 系统中 HZ

#### 知道了 HZ 的大小，那么就可以算出：

最大延迟确认时间是 200 ms （1000/5）
最短延迟确认时间是 40 ms （1000/25）
TCP 延迟确认可以在 Socket 设置 TCP_QUICKACK 选项来关闭这个算法。

```
延迟确认 和 Nagle 算法混合使用时，会产生新的问题
```
当 TCP 延迟确认 和 Nagle 算法混合使用时，会导致时耗增⻓，如下图：


发送方使用了 Nagle 算法，接收方使用了 TCP 延迟确认会发生如下的过程：
发送方先发出一个小报文，接收方收到后，由于延迟确认机制，自己又没有要发送的数据，只能干等着发送方的下一个报文到达；
而发送方由于 Nagle 算法机制，在未收到第一个报文的确认前，是不会发送后续的数据；
所以接收方只能等待最大时间发送后续的数据。 200 ms 后，才回 ACK 报文，发送方收到第一个报文的确认报文后，也才可以

很明显，这两个同时使用会造成额外的时延，这就会使得网络"很慢"的感觉。
要解决这个问题，只有两个办法：
要不发送方关闭 Nagle 算法
要不接收方关闭 TCP 延迟确认


#### 参考资料：

[1] Wireshark网络分析的艺术.林沛满.人⺠邮电出版社.
[2] Wireshark网络分析就这么简单.林沛满.人⺠邮电出版社.
[3] Wireshark数据包分析实战.Chris Sanders .人⺠邮电出版社.读者问答

## 读者问答^

```
读者问：tcp_retries1 “两个问题，请教一下作者参数，是什么场景下生效？:
tcp_retries2是不是只受限于规定的次数，还是受限于次数和时间限制的最小值？”
```
tcp_retries1和tcp_retries2都是在TCP三次握手之后的场景。
当重传次数超过次数超过 tcp_retries2 tcp_retries1才会断开就会指示TCP流。 IP 层进行 MTU 探测、刷新路由等过程，并不会断开TCP连接，当重传
tcp_retries1 出来的，当重传时间超过和 tcp_retries2 timeout两个重传次数都是受一个，就不会继续重传了，即使次数还没到达。 timeout 值限制的，timeout 的值是根据它俩的值计算

```
读者问：“tcp_orphan_retries也是控制tcp连接的关闭。这个跟tcp_retries1 tcp_retries2有什么区别吗？”
```
主动方发送收不到对方返回的 FIN 报文后，连接就处于 ACK 时，此时，内核会定时重发 FIN_WAIT1 状态下，该状态通常应在数十毫秒内转为 FIN 报文，其中重发次数由 tcp_orphan_retries FIN_WAIT2参数控制。。如果迟迟

```
读者问：一个报文，只是拆开显示了？“请问，为什么连续两个报文的” seq会是一样的呢，比如三次握手之后的那个报文？还是说，序号相同的是同
```
1. 三次握手中的前两次，是 seq+1；
2. 三次握手中的最后一个第三次握手的 len=0 ，在数据传输阶段「下一个 ack，实际上是可以携带数据的，由于我文章的例子是没有发送数据的，你可以看到 seq=seq+len 」，所以第三次握手的 seq 和下一个数据报的
    seq 是一样的，因为 len 为 0 ；

## 最后^

文章中 **源文件，已分享到公众号了，大家在后台回复「抓包」，就可以获取了。** Wireshark 分析的截图，可能有些会看的不清楚，为了方便大家用 Wireshark 分析， **我已把文中所有抓包的**


**小林是专为大家图解的工具人，Goodbye，我们下次⻅！**


## 3.4 TCP 半连接队列和全连接队列

#### 网上许多博客针对增大 TCP 半连接队列和全连接队列的方式如下：

增大 TCP 半连接队列的方式是增大 /proc/sys/net/ipv4/tcp_max_syn_backlog；
增大 TCP 全连接队列的方式是增大 listen() 函数中的 backlog；
这里先跟大家说下， **上面的方式都是不准确的。**

```
“你怎么知道不准确？”
```
很简单呀，因为我做了实验和看了个参数就可以的。 TCP 协议栈的内核源码，发现要增大这两个队列⻓度，不是简简单单增大某一

接下来，就会以 **实战 + 源码分析，带大家解密 TCP 半连接队列和全连接队列。**

```
“源码分析，那不是劝退吗？我们搞 Java 的看不懂呀”
```
放心，本文的源码分析不会涉及很深的知识，因为都被我删减了，你只需要会条件判断语句加减法等基本语法，就可以看懂。 if、左移右移操作符、

另外，不仅有源码分析，还会介绍 Linux 排查半连接队列和全连接队列的命令。

```
“哦？似乎很有看头，那我姑且看一下吧！”
```
行，没有被劝退的小伙伴，值得鼓励，下面这图是本文的提纲：


## 什么是 TCP 半连接队列和全连接队列？^

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：
半连接队列，也称 SYN 队列；
全连接队列，也称 accepet 队列；
服务端收到客户端发起的户端会返回 ACK，服务端收到第三次握手的 SYN 请求后， **内核会把该连接存储到半连接队列** ACK 后， **内核会把连接从半连接队列移除，然后创建新的完全的连** ，并向客户端响应 SYN+ACK，接着客
**接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。**


#### 不管是半连接队列还是全连接队列，都有最大⻓度限制，超过限制时，内核会直接丢弃，或返回 RST 包。

## 实战 - TCP 全连接队列溢出^

#### 如何知道应用程序的 TCP 全连接队列大小？

在服务端可以使用 ss 命令，来查看 TCP 全连接队列的情况：


但需要注意的是同的。从下面的内核代码可以看出区别： ss 命令获取的 Recv-Q/Send-Q 在「LISTEN 状态」和「非 LISTEN 状态」所表达的含义是不

在「LISTEN 状态」时，Recv-Q/Send-Q 表示的含义如下：


```
Recv-Q：当前全连接队列的大小，也就是当前已完成三次握手并等待服务端 accept() 的 TCP 连接；
Send-Q 128 ； ：当前全连接最大队列⻓度，上面的输出结果说明监听 8088 端口的 TCP 服务，最大全连接⻓度为
```
在「非 LISTEN 状态」时，Recv-Q/Send-Q 表示的含义如下：

```
Recv-Q：已收到但未被应用进程读取的字节数；
Send-Q：已发送但未收到确认的字节数；
如何模拟 TCP 全连接队列溢出的场景？
```

#### 实验环境：

客户端和服务端都是 CentOs 6.5 ，Linux 内核版本 2.6.32
服务端 IP 192.168.3.200，客户端 IP 192.168.3.100
服务端是 Nginx 服务，端口为 8088
这里先介绍下高性能 I/O 机制，通过多线程和事件模式，对目标机器产生大量的负载。 wrk 工具，它是一款简单的 HTTP 压测工具，它能够在单机多核 CPU 的条件下，使用系统自带的

本次模拟实验就使用生什么？有什么观察指标？ wrk 工具来压力测试服务端，发起大量的请求，一起看看服务端 TCP 全连接队列满了会发

客户端执行 wrk 命令对服务端发起压力测试，并发 3 万个连接：


在服务端可以使用 ss 命令，来查看当前 TCP 全连接队列的情况：

其间共执行了两次TCP 全连接队列。 ss 命令，从上面的输出结果，可以发现当前 TCP 全连接队列上升到了 129 大小，超过了最大

**当超过了** 我们可以使用 **TCP** netstat -s **最大全连接队列，服务端则会丢掉后续进来的** 命令来查看： **TCP 连接** ，丢掉的 TCP 连接的个数会被统计起来，


上面看到的一直在增加的话肯定全连接队列偶尔满了。 41150 times ，表示全连接队列溢出的次数，注意这个是累计值。可以隔几秒钟执行下，如果这个数字

从上面的模拟结果，可以得知， **TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生**

```
Linux 有个参数可以指定当 TCP 全连接队列满了会使用什么策略来回应客户端。
```
实际上，丢弃连接只是立失败。 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建


tcp_abort_on_overflow 共有两个值分别是 0 和 1 ，其分别表示：
0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；
1 ：如果全连接队列满了，server 发送一个 reset 包给 client，表示废掉这个握手过程和这个连接；

如果要想知道客户端连接不上服务端，是不是服务端tcp_abort_on_overflow 设置为 1 ，这时如果在客户端异常中可以看到很多 TCP 全连接队列满的原因，那么可以把 connection reset by peer (^) 的错误，那
么就可以证明是由于服务端 TCP 全连接队列溢出的问题。
通常情况下，应当把 tcp_abort_on_overflow 设置为 0 ，因为这样更有利于应对突发流量。
举个例子，当 TCP 全连接队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，进
程就在建立好的连接上发送请求。只要服务器没有为请求回复只是 **短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报文由于含有** ACK，请求就会被多次 **重发** 。如果服务器上的进程 **ACK，
仍然会触发服务器端成功建立连接。**
所以，时，才能设置为tcp_abort_on_overflow 1 以尽快通知客户端。设为 0 可以提高连接建立的成功率，只有你非常肯定 TCP 全连接队列会⻓期溢出
如何增大 TCP 全连接队列呢？
是的，当发现求。 TCP 全连接队列发生溢出的时候，我们就需要增大该队列的大小，以便可以应对客户端大量的请
**TCP** 下面的 **全连接队列的最大值取决于** Linux 内核代码可以得知： **somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)** 。从


值；somaxconn^ 是 Linux 内核的参数，默认值是^128 ，可以通过^ /proc/sys/net/core/somaxconn^ 来设置其
配置文件设置其⻓度；backlog^ 是^ listen(int sockfd, int backlog)^ 函数中的 backlog 大小，Nginx 默认值是^511 ，可以通过修改
前面模拟测试中，我的测试环境：
somaxconn 是默认值 128 ；
Nginx 的 backlog 是默认值 511
所以测试环境的 TCP 全连接队列最大值为 min(128, 511)，也就是 128 ，可以执行 ss 命令查看：


现在我们重新压测，把 TCP 全连接队列 **搞大** ，把 somaxconn 设置成 5000 ：

接着把 Nginx 的 backlog 也同样设置成 5000 ：

最后要重启 Nginx 服务，因为只有重新调用 listen() 函数 TCP 全连接队列才会重新初始化。
重启完后 Nginx 服务后，服务端执行 ss 命令，查看 TCP 全连接队列大小：

#### 从执行结果，可以发现 TCP 全连接最大值为 5000 。


#### 增大 TCP 全连接队列后，继续压测

#### 客户端同样以 3 万个连接并发发送请求给服务端：

服务端执行 ss 命令，查看 TCP 全连接队列使用情况：

从上面的执行结果，可以发现全连接队列使用增⻓的很快，但是一直都没有超过最大值，所以就不会溢出，那么netstat -s 就不会有 TCP 全连接队列溢出个数的显示：


#### 说明出的现象了。 TCP 全连接队列最大值从 128 增大到 5000 后，服务端抗住了 3 万连接并发请求，也没有发生全连接队列溢

**如果持续不断地有连接因为 TCP 全连接队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。**

## 实战 - TCP 半连接队列溢出^

#### 如何查看 TCP 半连接队列⻓度？

很遗憾，TCP 半连接队列⻓度的⻓度，没有像全连接队列那样可以用 ss 命令查看。
但是我们可以抓住 TCP 半连接的特点，就是服务端处于 SYN_RECV 状态的 TCP 连接，就是 TCP 半连接队列。
于是，我们可以使用如下命令计算当前 TCP 半连接队列⻓度：

#### 如何模拟 TCP 半连接队列溢出场景？

#### 模拟会使得服务端有大量的处于 TCP 半连接溢出场景不难，实际上就是对服务端一直发送 SYN_RECV 状态的 TCP 连接。 TCP SYN 包，但是不回第三次握手 ACK，这样就


这其实也就是所谓的 SYN 洪泛、SYN 攻击、DDos 攻击。

#### 实验环境：

客户端和服务端都是 CentOs 6.5 ，Linux 内核版本 2.6.32
服务端 IP 192.168.3.200，客户端 IP 192.168.3.100
服务端是 Nginx 服务，端口为 8088
注意：本次模拟实验是没有开启 tcp_syncookies，关于 tcp_syncookies 的作用，后续会说明。
本次实验使用 hping3 工具模拟 SYN 攻击：

当服务端受到连接队列大小： SYN 攻击后，连接服务端 ssh 就会断开了，无法再连上。只能在服务端主机上执行查看当前 TCP 半


同时，还可以通过 netstat -s 观察半连接队列溢出的情况：

#### 上面输出的数值是 累计值 ，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。 隔几秒执行几次，如果有上

#### 升的趋势，说明当前存在半连接队列溢出的现象 。

```
大部分人都说 tcp_max_syn_backlog 是指定半连接队列的大小，是真的吗？
```
很遗憾，半连接队列的大小并不单单只跟 tcp_max_syn_backlog 有关系。
上面模拟 SYN 攻击场景时，服务端的 tcp_max_syn_backlog 的默认值如下：

#### 但是在测试的时候发现，服务端最多只有 256 个半连接队列，而不是 512 ，所以 半连接队列的最大⻓度不一定由

**tcp_max_syn_backlog 值决定的** 。


```
接下来，走进 Linux 内核的源码，来分析 TCP 半连接队列的最大值是如何决定的。
```
TCP 列溢出的处理逻辑：第一次握手（收到 SYN 包）的 Linux 内核代码如下，其中缩减了大量的代码，只需要重点关注 TCP 半连接队


#### 从源码中，我可以得出共有三个条件因队列⻓度的关系而被丢弃的：


1. **如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；**
2. **若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；**
3. **如果没有开启(max_syn_backlog >> 2) tcp_syncookies，则会丢弃；，并且 max_syn_backlog 减去 当前半连接队列⻓度小于**

关于中一个手段。 tcp_syncookies 的设置，后面在详细说明，可以先给大家说一下，开启 tcp_syncookies 是缓解 SYN 攻击其

接下来，我们继续跟一下检测半连接队列是否满的函数函数 sk_acceptq_is_full ： inet_csk_reqsk_queue_is_full 和 检测全连接队列是否满的


#### 从上面源码，可以得知：

```
全 的，也就是连接队列的最大值是 min(somaxconn, backlog) sk_max_ack_backlog； 变量，sk_max_ack_backlog 实际上是在 listen() 源码里指定
半 续跟进；连接队列的最大值是 max_qlen_log 变量，max_qlen_log 是在哪指定的呢？现在暂时还不知道，我们继
```
我们继续跟进代码，看一下是哪里初始化了半连接队列的最大值 max_qlen_log：



从上面的代码中，我们可以算出reqsk_queue_is_full ： max_qlen_log 是 8 ，于是代入到 检测半连接队列是否满的函数

也就是= 1。 qlen >> 8 什么时候为 1 就代表半连接队列满了。这计算这不难，很明显是当 qlen 为 256 时，256 >> 8

至此，总算知道为什么上面模拟测试 SYN 攻击的时候，服务端处于 SYN_RECV 连接最大只有 256 个。
可⻅， **半连接队列最大值不是单单由 max_syn_backlog 决定，还跟 somaxconn 和 backlog 有关系。**
在 Linux 2.6.32 内核版本，它们之间的关系，总体可以概况为：


```
当backlog) * 2; max_syn_backlog > min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = min(somaxconn,
当max_syn_backlog * 2; max_syn_backlog < min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log =
```
```
半连接队列最大值 max_qlen_log 就表示服务端处于 SYN_REVC 状态的最大个数吗？
```
依然很遗憾，并不是。
max_qlen_log 是 **理论** 半连接队列最大值，并不一定代表服务端处于 SYN_REVC 状态的最大个数。
在前面我们在分析 TCP 第一次握手（收到 SYN 包）时会被丢弃的三种条件：

1. 如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；
2. 若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于^1 个，则会丢弃；
3. **如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列⻓度小于**
    **(max_syn_backlog >> 2)，则会丢弃；**
    假设条件则依然会丢弃 1 当前半连接队列的⻓度 SYN 包，也就会使得服务端处于 「没有超过」理论的半连接队列最大值 SYN_REVC 状态的最大个数不会是理论值 max_qlen_log，那么如果条件 max_qlen_log。 3 成立，

似乎很难理解，我们继续接着做实验，实验⻅真知。
服务端环境如下：

配置完后，服务端要重启 Nginx，因为全连接队列最大值和半连接队列最大值是在 listen() 函数初始化。
根据前面的源码分析，我们可以计算出半连接队列 max_qlen_log 的最大值为 256 ：


客户端执行 hping3 发起 SYN 攻击：

#### 服务端执行如下命令，查看处于 SYN_RECV 状态的最大个数：

可以发现，服务端处于 SYN_RECV 状态的最大个数并不是 max_qlen_log 变量的值。


这就是前面所说的原因： **如果条件 3 成立，则依然会丢弃如果当前半连接队列的⻓度 SYN 包，也就会使得服务端处于 「没有超过」理论半连接队列最大值 SYN_REVC 状态的最大个数不会是理论值 max_qlen_log，那么
max_qlen_log。**
我们来分析一波条件 3 :

#### 从上面的分析，可以得知如果触发「当前半连接队列⻓度的。 > 192」条件，TCP 第一次握手的 SYN 包是会被丢弃


#### 在前面我们测试的结果，服务端处于SYN_RECV 状态的个数还没到「理论半连接队列最大值 SYN_RECV 状态的最大个数是 256 」，就已经把 193 ，正好是触发了条件 SYN 包丢弃了。 3 ，所以处于

#### 所以，服务端处于 SYN_RECV 状态的最大个数分为如下两种情况：

```
如果「当前半连接队列」(max_syn_backlog >> 2)，那么处于 没超过 「理论半连接队列最大值」，但是 SYN_RECV 状态的最大个数就是 超过 max_syn_backlog - max_syn_backlog -
(max_syn_backlog >> 2)；
如果「当前半连接队列」半连接队列最大值」； 超过 「理论半连接队列最大值」，那么处于 SYN_RECV 状态的最大个数就是「理论
```
```
每个 Linux 内核版本「理论」半连接最大值计算方式会不同。
```
在上面我们是针对 Linux 2.6.32 版本分析的「理论」半连接最大值的算法，可能每个版本有些不同。
比如在 Linux 5.0.0 的时候，「理论」半连接最大值就是全连接队列最大值，但依然还是有队列溢出的三个条件：



#### 如果 SYN 半连接队列已满，只能丢弃连接吗？

并不是这样，析也可以看到这点，当开启了 **开启 syncookies** syncookies **功能就可以在不使用** 功能就不会丢弃连接。 **SYN 半连接队列的情况下成功建立连接** ，在前面我们源码分

syncookies 返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端

syncookies 参数主要有以下三个值：
0 值，表示关闭该功能；
1 值，表示仅当 SYN 半连接队列放不下时，再启用它；
2 值，表示无条件开启功能；
那么在应对 SYN 攻击时，只需要设置为 1 即可：

#### 如何防御 SYN 攻击？

#### 这里给出几种防御 SYN 攻击的方法：


#### 增大半连接队列；

开启 tcp_syncookies 功能
减少 SYN+ACK 重传次数
方式一：增大半连接队列
在前面源码和实验中，得知 **同增大 somaxconn 和 backlog要想增大半连接队列，我们得知不能只单纯增大，也就是增大全连接队列** 。否则，只单纯增大 **tcp_max_syn_backlog** tcp_max_syn_backlog **的值，还需一** 是无效的。

增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：

增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：

最后，改变了如上这些参数后，要重启 Nginx 服务，因为半连接队列和全连接队列都是在 listen() 初始化的。
方式二：开启 _tcp_syncookies_ 功能
开启 tcp_syncookies 功能的方式也很简单，修改 Linux 内核参数：


#### 方式三：减少 SYN+ACK 重传次数

#### 当服务端受到SYN+ACK ，当重传超过次数达到上限后，就会断开连接。 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传

#### 那么针对开。 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断

#### 参考资料：

#### [1] 系统性能调优必知必会.陶辉.极客时间.

[2] https://www.cnblogs.com/zengkefu/p/5606696.html
[3] https://blog.cloudflare.com/syn-packet-handling-in-the-wild/

## 读者问答^

#### 读者问：“咦 我比较好奇博主都是从哪里学到这些知识的呀？书籍？视频？还是多种参考资料”

#### 你可以看我的参考文献呀，知识点我主要是在极客专栏学的，实战模拟实验和源码解析是自己瞎折腾出来的。

```
读者问：“syncookies 启用后就不需要半链接了？那请求的数据会存在哪里？”
```

syncookies = 1 会计算一个 cookie 时，半连接队列满后，后续的请求就不会存放到半连接队列了，而是在第二次握手的时候，服务端值，放入到 SYN +ACK 包中的序列号发给客户端，客户端收到后并回 ack ，服务端就会校验连
接是否合法，合法就直接把连接放入到全连接队列。

## 最后^

本文是以看到 TCP Linux 2.6.32 半连接队列「并不是」如网上说的那样版本的内核用实验 + 源码的方式，给大家说明了 tcp_max_syn_backlog TCP 表示半连接队列。半连接队列和全连接队列，我们可以

TCP TCP 半连接队列的大小对于不同的半连接队列的大小。 Linux 内核版本会有不同的计算方式，所以并不要求大家要死记住本文计算

重要的是要学会自我源码分析，这样不管碰到什么版本的 Linux 内核，都不再怕了。
网上搜索出来的信息，并不一定针对你的系统，通过自我分析一波，你会更了解你当前使用的 Linux 内核版本！
**小林是专为大家图解的工具人，Goodbye，我们下次⻅！**


## 3.5 TCP 内核参数

#### TCP 性能的提升不仅考察 TCP 的理论知识，还考察了对于操作系统提供的内核参数的理解与应用。

#### TCP 协议是由操作系统实现，所以操作系统提供了不少调节 TCP 的参数。

#### 如何正确有效的使用这些参数，来提高症下药，而不是病急乱投医。 TCP 性能是一个不那么简单事情。我们需要针对 TCP 每个阶段的问题来对

#### 接下来，将以三个⻆度来阐述提升 TCP 的策略，分别是：

#### TCP 三次握手的性能提升；

#### TCP 四次挥手的性能提升；

#### TCP 数据传输的性能提升；


## TCP 三次握手的性能提升^

#### TCP 是面向连接的、可靠的、双向传输的传输层通信协议，所以在传输数据之前需要经过三次握手才能建立连接。


#### 那么，三次握手的过程在一个击等场景中，如果不能有效正确的调节三次握手中的参数，就会对性能产生很多的影响。 HTTP 请求的平均时间占比 10% 以上，在网络状态不佳、高并发或者遭遇 SYN 攻

如何正确有效的使用这些参数，来提高现问题时，先用 netstat 命令查看是哪个握手阶段出现了问题，再来对症下药，而不是病急乱投医。 TCP 三次握手的性能，这就需要理解「三次握手的状态变迁」，这样当出


#### 客户端和服务端都可以针对三次握手优化性能。主动发起连接的客户端优化相对简单些，而服务端需要监听端口，属于被动连接方，其间保持许多的中间状态，优化方法相对复杂一些。

#### 所以，客户端（主动发起连接方）和服务端（被动连接方）优化的方式是不同的，接下来分别针对客户端和服务端优化。

### 客户端优化

#### 三次握手建立连接的首要目的是「同步序列号」。

只有同步了序列号才有可靠传输，手中的报文称为 SYN 的原因，SYN TCP 的全称就叫许多特性都依赖于序列号实现，比如流量控制、丢包重传等，这也是三次握 _Synchronize Sequence Numbers_ （同步序列号）。


#### SYN_SENT 状态的优化

#### 客户端作为主动发起连接方，首先它将发送 SYN 包，于是客户端的连接就会处于 SYN_SENT 状态。

客户端在等待服务端回复的没有收到 SYN+ACK 报文，则会重发 ACK 报文，正常情况下，服务器会在几毫秒内返回 SYN 包， **重发的次数由 tcp_syn_retries** SYN+ACK **参数控制** ，默认是，但如果客户端⻓时间 5 次：

#### 通常，第一次超时重传是在在 8 秒后，第五次是在超时重传 1 秒后，第二次超时重传是在 16 秒后。没错， 每次超时的时间是上一次的 2 秒，第三次超时重传是在 2 倍 。 4 秒后，第四次超时重传是

#### 当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就会终止三次握手。

#### 所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。



#### 你可以根据网络的稳定性和目标服务器的繁忙程度修改内网中通讯时，就可以适当调低重试次数，尽快把错误暴露给应用程序。 SYN 的重传次数，调整客户端的三次握手时间上限。比如

### 服务端优化

#### 当服务端收到列号发给对方。 SYN 包后，服务端会立⻢回复 SYN+ACK 包，表明确认收到了客户端的序列号，同时也把自己的序

此时，服务端出现了新连接，状态是护「未完成」的握手信息，当半连接队列溢出后，服务端就无法再建立新的连接。 SYN_RCV。在这个状态下，Linux 内核就会建立一个「半连接队列」来维


#### SYN 攻击，攻击的是就是这个半连接队列。

#### 如何查看由于 SYN 半连接队列已满，而被丢弃连接的情况？

我们可以通过该 netstat -s 命令给出的统计结果中， 可以得到由于半连接队列已满，引发的失败次数：


#### 上面输出的数值是 升的趋势，说明当前存在半连接队列溢出的现象累计值 ，表示共有多少个 TCP 。连接因为半连接队列溢出而被丢弃。 隔几秒执行几次，如果有上

#### 如何调整 SYN 半连接队列大小？

要想增大半连接队列， **就是增大 accept 队列。否则，只单纯增大不能只单纯增大 tcp_max_syn_backlog tcp_max_syn_backlog 的值，还需一同增大是无效的。 somaxconn 和 backlog，也**

增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：

增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：


最后，改变了如上这些参数后，要重启的。 Nginx 服务，因为 SYN 半连接队列和 accept 队列都是在 listen() 初始化

```
如果 SYN 半连接队列已满，只能丢弃连接吗？
```
并不是这样， **开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接** 。
syncookies 返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。的工作原理：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端

syncookies 参数主要有以下三个值：
0 值，表示关闭该功能；


#### 1 值，表示仅当 SYN 半连接队列放不下时，再启用它；

#### 2 值，表示无条件开启功能；

#### 那么在应对 SYN 攻击时，只需要设置为 1 即可：

#### SYN_RCV 状态的优化

#### 当客户端接收到服务器发来的转换为 ESTABLISHED，表示连接建立成功。 SYN+ACK 报文后，就会回复 ACK 给服务器，同时客户端连接状态从 SYN_SENT

#### 服务器端连接成功建立的时间还要再往后，等到服务端收到客户端的ESTABLISHED。 ACK 后，服务端的连接状态才变为

#### 如果服务器没有收到 ACK，就会重发 SYN+ACK 报文，同时一直处于 SYN_RCV 状态。

当网络繁忙、不稳定时，报文丢失就会变严重，此时应该调大重发次数。反之则可以调小重发次数。 **的方法是，调整 tcp_synack_retries 参数** ： **修改重发次数**

tcp_synack_retries 一次重传后会继续等待的默认重试次数是 32 秒，如果服务端仍然没有收到 5 次，与客户端重传 ACK SYN ，才会关闭连接，故共需要等待类似，它的重传会经历 1 、 2 、 63 4 、秒。 8 、 16 秒，最后

服务器收到加到 accept ACK 队列，等待进程调用后连接建立成功，此时，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添 accept 函数时把连接取出来。

如果进程不能及时地调用连接被丢弃。 accept 函数，就会造成 accept 队列（也称全连接队列）溢出，最终导致建立好的 TCP


```
accept 队列已满，只能丢弃连接吗？
```
丢弃连接只是打开这一功能需要将 Linux 的默认行为，我们还可以选择向客户端发送 tcp_abort_on_overflow 参数设置为 1 。 RST 复位报文，告诉客户端连接已经建立失败。

tcp_abort_on_overflow 共有两个值分别是 0 和 1 ，其分别表示：
0 ：如果 accept 队列满了，那么 server 扔掉 client 发过来的 ack ；
1 ：如果 accept 队列满了，server 发送一个 RST 包给 client，表示废掉这个握手过程和这个连接；

如果要想知道客户端连接不上服务端，是不是服务端tcp_abort_on_overflow 设置为 1 ，这时如果在客户端异常中可以看到很多 TCP 全连接队列满的原因，那么可以把 connection reset by peer (^) 的错误，那
么就可以证明是由于服务端 TCP 全连接队列溢出的问题。
通常情况下，应当把 tcp_abort_on_overflow 设置为 0 ，因为这样更有利于应对突发流量。
举个例子，当进程就在建立好的连接上发送请求。只要服务器没有为请求回复 accept 队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ACK，客户端的请求就会被多次「重发」。 ESTABLISHED，客户端 **如果
服务器上的进程只是短暂的繁忙造成 accept 队列满，那么当 accept 队列有空位时，再次接收到的请求报文由于
含有 ACK，仍然会触发服务器端成功建立连接。**


所以，时，才能设置为tcp_abort_on_overflow 1 以尽快通知客户端。设为 0 可以提高连接建立的成功率，只有你非常肯定 TCP 全连接队列会⻓期溢出

```
如何调整 accept 队列的⻓度呢？
```
accept 队列的⻓度取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)，其中：
somaxconn 是 Linux 内核的参数，默认值是 128 ，可以通过 net.core.somaxconn 来设置其值；
backlog 是 listen(int sockfd, int backlog) 函数中的 backlog 大小；
Tomcat、Nginx、Apache 常⻅的 Web 服务的 backlog 默认值都是 511 。

```
如何查看服务端进程 accept 队列的⻓度？
```

可以通过 ss -ltn 命令查看：

```
Recv-Q：当前 accept 队列的大小，也就是当前已完成三次握手并等待服务端 accept() 的 TCP 连接；
Send-Q为 128 ；：accept 队列最大⻓度，上面的输出结果说明监听 8088 端口的 TCP 服务，accept 队列的最大⻓度
```
```
如何查看由于 accept 连接队列已满，而被丢弃的连接？
```
当超过了可以使用 accept netstat -s 连接队列，服务端则会丢掉后续进来的命令来查看： TCP 连接，丢掉的 TCP 连接的个数会被统计起来，我们

上面看到的字一直在增加的话，说明 41150 times accept ，表示 accept 连接队列偶尔满了。队列溢出的次数，注意这个是累计值。可以隔几秒钟执行下，如果这个数

如果持续不断地有连接因为 accept 队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。


### 如何绕过三次握手？

#### 以上我们只是在对三次握手的过程进行优化，接下来我们看看如何绕过三次握手发送数据。

#### 三次握手建立连接造成的后果就是，送。 HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发

在 Linux 3.7 内核版本之后，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。

```
接下来说说，TCP Fast Open 功能的工作方式。
```


#### 在客户端首次建立连接时的过程：

1. 客户端发送Open Cookie SYN ； 报文，该报文包含 Fast Open 选项，且该选项的 Cookie 为空，这表明客户端请求 Fast
2. 支持端； TCP Fast Open 的服务器生成 Cookie，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户
3. 客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。
所以，第一次发起 HTTP GET 请求的时候，还是需要正常的三次握手流程。
之后，如果客户端再次向服务器建立连接时的过程：
1. 客户端发送据」）以及此前记录的 SYN 报文，该报文包含「数据」（对于非 Cookie； TFO 的普通 TCP 握手过程，SYN 报文中不包含「数
2. 支持对 SYN TCP Fast Open 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；如果的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 Cookie SYN-ACK 无效，服务器将报文中
丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；
3. 如果服务器接受了 **1 个 RTT 的时间消耗** SYN ；报文中的「数据」，服务器可在握手完成之前发送「数据」， **这就减少了握手带来的**
4. 客户端将发送据」没有被确认，则客户端将重新发送「数据」； ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报文中发送的「数
5. 此后的 TCP 连接的数据传输过程和非 TFO 的正常情况一致。
所以，之后发起 HTTP GET 请求的时候，可以绕过三次握手，这就减少了握手带来的 1 个 RTT 的时间消耗。
开启了 TFO 功能，cookie 的值是存放到 TCP option 字段里的：


注：客户端在请求并存储了（通常为过期）。 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为 Cookie 无效

```
Linux 下怎么打开 TCP Fast Open 功能呢？
```
在 Linux 系统中，可以通过 **设置 tcp_fastopn 内核参数，来打开 Fast Open 功能** ：

tcp_fastopn 各个值的意义:
0 关闭


1 作为客户端使用 Fast Open 功能
2 作为服务端使用 Fast Open 功能
3 无论作为客户端还是服务器，都可以使用 Fast Open 功能
**TCP Fast Open 功能需要客户端和服务端同时支持，才有效果。**

### 小结

#### 本小结主要介绍了关于优化 TCP 三次握手的几个 TCP 参数。

#### 客户端的优化

当客户端发起 SYN 包时，可以通过 tcp_syn_retries 控制其重传的次数。

```
服务端的优化
```
当服务端果 SYN 半连接队列溢出情况比较严重，可以通过 SYN 半连接队列溢出后，会导致后续连接被丢弃，可以通过 tcp_max_syn_backlog netstat -s、somaxconn 观察半连接队列溢出的情况，如、backlog 参数来调整
SYN 半连接队列的大小。
服务端回复tcp_syncookies SYN+ACK 参数设置为的重传次数由 1 ，表示仅在 tcp_synack_retries SYN 队列满后开启 参数控制。如果遭受 syncookie 功能，可以保证正常的连接成功建立。 SYN 攻击，应把


服务端收到客户端返回的 ACK，会把连接移入 accpet 队列，等待进行调用 accpet() 函数取出连接。
可以通过tcp_abort_on_overflow ss -lnt 查看服务端进程的 设置为 1 ，表示用 accept RST 队列⻓度，如果通知客户端连接建立失败。 accept 队列溢出，系统默认丢弃 ACK，如果可以把

如果accept accpet 队列⻓度取决于队列溢出严重，可以通过 min(backlog, somaxconn) listen 函数的。 backlog 参数和 somaxconn 系统参数提高队列大小，

```
绕过三次握手
```
TCP Fast Open tcp_fastopen 开启该功能，同时必须保证服务端和客户端同时支持。功能可以绕过三次握手，使得 HTTP 请求减少了 1 个 RTT 的时间，Linux 下可以通过

## TCP 四次挥手的性能提升^

#### 接下来，我们一起看看针对 TCP 四次挥手关闭连接时，如何优化性能。

#### 在开始之前，我们得先了解四次挥手状态变迁的过程。

#### 客户端和服务端双方都可以主动断开连接， 通常先关闭连接的一方称为主动方，后关闭连接的一方称为被动方。


#### 可以看到， 四次挥手过程只涉及了两种报文，分别是 FIN 和 ACK ：

#### FIN 道；就是结束连接的意思，谁发出 FIN 报文，就表示它将不会再发送任何数据，关闭这一方向上的传输通

#### ACK 就是确认的意思，用来通知对方：你方的发送通道已经关闭；

#### 四次挥手的过程:

#### 当主动方关闭连接时，会发送 FIN 报文，此时发送方的 TCP 连接将从 ESTABLISHED 变成 FIN_WAIT1。

```
当被动方收到表示被动方在等待进程调用 FIN 报文后，内核会自动回复 close 函数关闭连接。 ACK 报文，连接状态将从 ESTABLISHED 变成 CLOSE_WAIT，
```

#### 当主动方收到这个 了 。 ACK 后，连接状态由 FIN_WAIT1 变为 FIN_WAIT2，也就是表示 主动方的发送通道就关闭

当被动方进入调用 close 函数，进而触发内核发送 CLOSE_WAIT 时，被动方还会继续处理数据，等到进程的 FIN 报文，此时被动方的连接状态变为 read LAST_ACK函数返回 (^0) 。后，应用程序就会
当主动方收到这个TIME_WAIT， **在 Linux** FIN 报文后，内核会回复 **系统下大约等待 1 分钟后，** ACK 报文给被动方，同时主动方的连接状态由 **TIME_WAIT 状态的连接才会彻底关闭** 。 FIN_WAIT2 变为
当被动方收到最后的 ACK 报文后， **被动方的连接就会关闭** 。
你可以看到，每个方向都需要 **一个 FIN 和一个 ACK** ，因此通常被称为 **四次挥手** 。
这里一点需要注意是： **主动关闭连接的，才有 TIME_WAIT 状态。**
主动关闭方和被动关闭方优化的思路也不同，接下来分别说说如何优化他们。

### 主动方的优化

#### 关闭连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。

#### 如果进程异常退出了，内核就会发送 RST 报文来关闭，它可以不走四次挥手流程，是一个暴力关闭连接的方式。

安全关闭连接的方式必须通过四次挥手，它由进程调用数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。 close 和 shutdown 函数发起 FIN 报文（shutdown 参

```
调用 close 函数和 shutdown 函数有什么区别？
```
调用了 close 函数意味着完全断开连接， **完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了
close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。**
使用 **一个方向的连接** close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的： shutdown 函数， **它可以控制只关闭**

#### 第二个参数决定断开连接的方式，主要有以下三种方式：

#### SHUT_RD(0)： 关闭连接的「读」这个方向 ，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收


#### 到新的数据，会对数据进行不知道数据已经被丢弃了。 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本

#### SHUT_WR(1)送的数据，将被立即发送出去，并发送一个： 关闭连接的「写」这个方向 ，这就是常被称为「半关闭」的连接。如果发送缓冲区还有未发 FIN 报文给对端。

#### SHUT_RDWR(2)：相当于 SHUT_RD 和 SHUT_WR 操作各一次， 关闭套接字的读和写两个方向 。

close 也不相同。和 shutdown 函数都可以关闭连接，但这两种方式关闭的连接，不只功能上有差异，控制它们的 Linux 参数

```
FIN_WAIT1 状态的优化
```
主动方发送为 FIN_WAIT2 FIN 状态。报文后，连接就处于 FIN_WAIT1 状态，正常情况下，如果能及时收到被动方的 ACK，则会很快变

但是当迟迟收不到对方返回的 **其中重发次数由 tcp_orphan_retries** ACK 时，连接就会一直处于 **参数控制** （注意，orphan FIN_WAIT1 虽然是孤儿的意思，该参数却不只对孤儿连接有状态。此时， **内核会定时重发 FIN 报文，**
效，事实上，它对所有 FIN_WAIT1 状态下的连接都有效），默认值是 0 。

#### 你可能会好奇，这 0 表示几次？ 实际上当为 0 时，特指 8 次 ，从下面的内核源码可知：


如果tcp_orphan_retries FIN_WAIT1 状态连接很多，我们就需要考虑降低时，连接就会直接关闭掉。 tcp_orphan_retries 的值，当重传次数超过

对于普遍正常情况时，调低这由 TCP 两个特性导致的： tcp_orphan_retries 就已经可以了。如果遇到恶意攻击，FIN 报文根本无法发送出去，

首先，也不能提前发送。TCP 必须保证报文是有序发送的，FIN 报文也不例外，当发送缓冲区还有数据没有发送时，FIN 报文
其次，文件时，就可以通过接收窗口设为TCP 有流量控制功能，当接收方接收窗口为 0 ，这就会使得 FIN 0 时，发送方就不能再发送数据。所以，当攻击者下载大报文都无法发送出去，那么连接会一直处于
FIN_WAIT1 状态。
解决这种问题的方法，是 **调整 tcp_max_orphans 参数，它定义了「孤儿连接」的最大数量** ：

当进程调用了为了防止孤儿连接过多，导致系统资源⻓时间被占用，就提供了 close 函数关闭连接，此时连接就会是「孤儿连接」，因为它无法再发送和接收数据。 tcp_max_orphans 参数。如果孤儿连接数量大Linux 系统
于它，新增的孤儿连接将不再走四次挥手，而是直接发送 RST 复位报文强制关闭。


#### FIN_WAIT2 状态的优化

#### 当主动方收到FIN 报文，关闭对方的发送通道。 ACK 报文后，会处于 FIN_WAIT2 状态，就表示主动方的发送通道已经关闭，接下来将等待对方发送

这时， **数据。但对于如果连接是用 close shutdown 函数关闭的孤儿连接，由于无法再发送和接收数据，所以这个状态不可以持续太久，而函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收
tcp_fin_timeout 控制了这个状态下连接的持续时⻓** ，默认值是 60 秒：

它意味着对于孤儿连接（调用 close 关闭的连接），如果在 60 秒后还没有收到 FIN 报文，连接就会直接关闭。
这个 60 秒不是随便决定的，它与 TIME_WAIT 状态持续的时间是相同的，后面我们再来说说为什么是 60 秒。

```
TIME_WAIT 状态的优化
```
TIME_WAIT 是主动方四次挥手的最后一个状态，也是最常遇⻅的状态。
当收到被动方发来的TIME_WAIT 状态。在 FIN Linux 报文后，主动方会立刻回复系统，TIME_WAIT 状态会持续 ACK，表示确认对方的发送通道已经关闭，接着就处于 60 秒后才会进入关闭状态。

TIME_WAIT LAST_ACK 状态。如果这个状态的连接，在主动方看来确实快已经关闭了。然后，被动方没有收到 ACK 报文没有到达被动方，被动方就会重发 FIN 报文。重发次数仍然由前面介绍过的 ACK 报文前，还是处于 (^)
tcp_orphan_retries 参数控制。
TIME-WAIT 的状态尤其重要，主要是两个原因：
防止具有相同「四元组」的「旧」数据包被收到；
保证「被动关闭连接」的一方能被正确的关闭，即保证最后的闭； ACK 能让被动关闭方接收，从而帮助其正常关
原因一：防止旧连接的数据包
TIME-WAIT 的一个作用是 **防止收到历史数据，从而导致数据错乱的问题。**


#### 假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？

#### 如上图⻩色框框服务端在关闭连接之前发送的 SEQ = 301 报文，被网络延迟了。

#### 这时有相同端口的这个过期的报文，这就会产生数据错乱等严重的问题。 TCP 连接被复用后，被延迟的 SEQ = 301 抵达了客户端，那么客户端是有可能正常接收

#### 所以， 连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。 TCP 就设计出了这么一个机制，经过 2MSL 这个时间， 足以让两个方向上的数据包都被丢弃，使得原来

#### 原因二：保证连接正确关闭


#### TIME-WAIT 的另外一个作用是 等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。

#### 假设 TIME-WAIT 没有等待时间或时间过短，断开连接会造成什么问题呢？

#### 如上图红色框框客户端四次挥手的最后一个WAIT 过短或没有，则就直接进入了 CLOSE ACK 状态了，那么服务端则会一直处在 报文如果在网络中被丢失了，此时如果客户端 LAST-ACK 状态。 TIME-

#### 当客户端发起建立连接的终止。 SYN 请求报文后，服务端会发送 RST 报文给客户端，连接建立的过程就会被

#### 我们再回过头来看看，为什么 TIME_WAIT 状态要保持 60 秒呢？这与孤儿连接 FIN_WAIT2 状态默认保留 60 秒的

原理是一样的， **一个报文在网络中的最⻓生存时间因为这两个状态都需要保持** （报文每经过一次路由器的转发， **2MSL 时⻓。MSL 全称是** IP **Maximum Segment Lifetime** 头部的 TTL 字段就会减 1 ，减到 **，它定义了** 0 时报文
就被丢弃，这就限制了报文的最⻓存活时间）。
为什么是动方重发的 2 MSL FIN 会在第的时⻓呢？这其实是相当于 2 个 MSL 内到达，TIME_WAIT **至少允许报文丢失一次** 状态的连接可以应对。。比如，若 ACK 在一个 MSL 内丢失，这样被

为什么不是万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。 4 或者 8 MSL 的时⻓呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有


**因此，所以它们都是TIME_WAIT 60 秒。和 FIN_WAIT2 状态的最大时⻓都是 2 MSL，由于在 Linux 系统中，MSL 的值固定为 30 秒，**

虽然 **满了所有端口资源，则会导致无法创建新连接。** TIME_WAIT 状态有存在的必要，但它毕竟会消耗系统资源。 **如果发起连接一方的 TIME_WAIT 状态过多，占**

```
客户端受端口资源限制 占满就会导致无法创建新的连接；：如果客户端 TIME_WAIT 过多，就会导致端口资源被占用，因为端口就 65536 个，被
服务端受系统资源限制 听一个端口，但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么：由于一个四元组表示TCP连接，理论上服务端可以建立很多连接，服务端确实只监
多一直不断的连接了。所以当服务端出现大量接； TIME_WAIT 时，系统资源被占满时，会导致处理不过来新的连
```
另外， **再经历Linux TIME_WAIT 提供了 tcp_max_tw_buckets 而直接关闭： 参数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不**

当服务器的并发连接增多时，相应地，同时处于tcp_max_tw_buckets 参数，减少不同连接间数据错乱的概率。 TIME_WAIT 状态的连接数量也会变多，此时就应当调大

tcp_max_tw_buckets 也不是越大越好，毕竟内存和端口都是有限的。
**有一种方式可以在建立新连接时，复用处于注意，该参数是只用于客户端（建立连接的发起方），因为是在调用 TIME_WAIT 状态的连接，那就是打开 connect() 时起作用的，而对于服务端（被动 tcp_tw_reuse 参数。但是需要
连接方）是没有用的。**

tcp_tw_reuse 从协议⻆度理解是安全可控的，可以复用处于 TIME_WAIT 的端口为新的连接所用。
什么是协议⻆度理解的安全可控呢？主要有两点：


#### 只适用于连接发起方，也就是 C/S 模型中的客户端；

#### 对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复用。

#### 使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持（对方也要打开 ）：

#### 由于引入了时间戳，它能带来了些好处：

#### 我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃；

#### 同时，它还可以防止序列号绕回，也是因为重复的数据包会由于时间戳过期被自然丢弃；

#### 时间戳是在 TCP 的选项字段里定义的，开启了时间戳功能，在 TCP 报文传输的时候会带上发送报文的时间戳。


我们来看看开启了 tcp_tw_reuse 功能，如果四次挥手中的最后一次 ACK 在网络中丢失了，会发生什么？

#### 上图的流程：

#### 四次挥手中的最后一次 ACK 在网络中丢失了，服务端一直处于 LAST_ACK 状态；

客户端由于开启了的连接。 **但客户端新发的** tcp_tw_reuse **SYN 包会被忽略（由于时间戳），因为服务端比较了客户端的上一个报文与** 功能，客户端再次发起新连接的时候，会复用超过 1 秒后的 time_wait **SYN** 状态
**报文的时间戳，过期的报文就会被服务端丢弃** ；
服务端 FIN 报文迟迟没有收到四次挥手的最后一次 ACK，于是超时重发了 FIN 报文给客户端；
**处于LAST_ACK SYN_SENT 状态；状态的客户端，由于收到了 FIN 报文，则会回 RST 给服务端，于是服务端就离开了
最初的客户端 SYN 报文超时重发了（ 1 秒钟后）** ，此时就与服务端能正确的三次握手了。
所以大家都会说开启了在 SYN 包重传。 tcp_tw_reuse，可以在复用了 time_wait 状态的 1 秒过后成功建立连接，这 1 秒主要是花费

另外，老版本的 Linux 还提供了 tcp_tw_recycle 参数，但是当开启了它，就有两个坑：
**Linux 会加快客户端和服务端 TIME_WAIT 状态的时间** ，也就是它会使得 TIME_WAIT 状态会小于 60 秒，很


#### 容易导致数据错乱；

```
另外，是说要使用该选项，则必须保证数据包的时间戳是单调递增的。那么，问题在于，此处的时间戳并不是我们 Linux 会丢弃所有来自远端时间戳小于上次记录的时间戳（由同一个远端发送的）的任何数据包 。就
通常意义上面的绝对时间，而是一个相对时间。很多情况下，我们是没法保证时间戳单调递增的，比如使用了 NAT、LVS 等情况；
```
所以，不建议设置为 1 ，在 Linux 4.12 版本后，Linux 内核直接取消了这一参数，建议关闭它：

另外，我们可以在程序中设置 socket 选项，来设置调用 close 关闭连接行为。

如果 **将跳过四次挥手，也就跳过了** l_onoff 为非 0 ， 且 l_linger **TIME_WAIT** 值为 0 ， **状态，直接关闭。那么调用 close 后，会立该发送一个 RST 标志给对端，该 TCP 连接**

但这为跨越 TIME_WAIT 状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。

### 被动方的优化

当被动方收到进程调用 close FIN 函数关闭连接。报文时，内核会自动回复 ACK，同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用

内核没有权利替代进程去关闭连接，因为如果主动方是通过收数据或发送数据。因此，Linux 并没有限制 CLOSE_WAIT shutdown 状态的持续时间。关闭连接，那么它就是想在半关闭连接上接

当然，大多数应用程序并不使用 **态。就需要排查你的应用程序，因为可能因为应用程序出现了** shutdown 函数关闭连接。所以， **Bug当你用，read netstat 函数返回命令发现大量 0 时，没有调用 CLOSE_WAIT close 函数。状**


处于状态，等待主动方返回 CLOSE_WAIT 状态时，调用了 ACK 来确认连接关闭。 close 函数，内核就会发出 FIN 报文关闭发送通道，同时连接进入 LAST_ACK

如果迟迟收不到这个重发 FIN 报文的优化策略一致。 ACK，内核就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与主动方

还有一点我们需要注意的， **送，这样看起来，四次挥手会变成三次挥手，这只是一种特殊情况，不用在意。如果被动方迅速调用 close 函数，那么被动方的 ACK 和 FIN 有可能在一个报文中发**

```
如果连接双方同时关闭连接，会怎么样？
```
由于 TCP 是双全工的协议，所以是会出现两方同时关闭连接的现象，也就是同时发送了 FIN 报文。
此时，上面介绍的优化策略仍然适用。两方发送态，FIN 报文的重发次数仍由 tcp_orphan_retries FIN 参数控制。报文时，都认为自己是主动方，所以都进入了 FIN_WAIT1 状


接下来， **CLOSING 双方在等待的新状态，它替代了 ACK 报文的过程中，都等来了 FIN_WAIT2 状态** 。接着，双方内核回复 **FIN 报文。这是一种新情况，所以连接会进入一种叫做** ACK 确认对方发送通道的关闭后，进入 (^)
TIME_WAIT 状态，等待 2MSL 的时间后，连接自动关闭。

### 小结

#### 针对 TCP 四次挥手的优化，我们需要根据主动方和被动方四次挥手状态变化来调整系统 TCP 内核参数。


#### 主动方的优化

主动发起tcp_orphan_retries FIN 报文断开连接的一方，如果迟迟没收到对方的 参数决定。 ACK 回复，则会重传 FIN 报文，重传的次数由

当主动方收到 ACK 报文后，连接就进入 FIN_WAIT2 状态，根据关闭的方式不同，优化的方式也不同：
如果这是文，连接就直接关闭。同时，为了应对孤儿连接占用太多的资源， close 函数关闭的连接，那么它就是孤儿连接。如果 tcp_fin_timeouttcp_max_orphans 秒内没有收到对方的 定义了最大孤儿连接 FIN 报
的数量，超过时连接就会直接释放。
反之是 shutdown 函数关闭的连接，则不受此参数限制；
当主动方接收到防止 TIME_WAIT FIN 状态占用太多的资源，报文，并返回 ACK 后，主动方的连接进入tcp_max_tw_buckets TIME_WAIT 定义了最大数量，超过时连接也会直接释放。状态。这一状态会持续 1 分钟，为了

当端口复用于作为客户端的新连接，注意该参数只适用于客户端。 TIME_WAIT 状态过多时，还可以通过设置 tcp_tw_reuse 和 tcp_timestamps 为 1 ，将 TIME_WAIT 状态的

```
被动方的优化
```
被动关闭的连接方应对非常简单，它在回复接。因此，出现大量 CLOSE_WAIT 状态的连接时，应当从应用程序中找问题。 ACK 后就进入了 CLOSE_WAIT 状态，等待进程调用 close 函数关闭连


当被动方发送制下重发 FIN FIN 报文。报文后，连接就进入 LAST_ACK 状态，在未等到 ACK 时，会在 tcp_orphan_retries 参数的控

## TCP 传输数据的性能提升^

#### 在前面介绍的是三次握手和四次挥手的优化策略，接下来主要介绍的是 TCP 传输数据时的优化策略。

#### TCP 连接是由内核维护的，内核会为每个连接建立内存缓冲区：

#### 如果连接的内存配置过小，就无法充分使用网络带宽，TCP 传输效率就会降低；

#### 如果连接的内存配置过大，很容易把服务器资源耗尽，这样就会导致新连接无法建立；

因此，我们必须理解 Linux 下 TCP 内存的用途，才能正确地配置内存大小。

### 滑动窗口是如何影响传输速度的？

#### TCP ACK，如果迟迟未收到，就会超时重发该报文，直到收到对方的会保证每一个报文都能够抵达对方，它的机制是这样：报文发出去后，必须接收到对方返回的确认报文 ACK 为止。

#### 所以，TCP 报文发出去后，并不会立⻢从内存中删除，因为重传时还需要用到它。

由于buff/cache TCP 是内核维护的，所以报文存放在内核缓冲区。如果连接非常多，我们可以通过 内存是会增大。 free 命令观察到

如果就有点像我和你面对面聊天，你一句我一句，但这种方式的缺点是效率比较低的。 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。这个模式


#### 所以，这样的传输方式有一个缺点：数据包的 往返时间越⻓，通信的效率就越低 。

#### 要解决这一问题不难，并行批量发送报文，再批量确认报文即可。


#### 然而，这引出了另一个问题，发送方可以随心所欲的发送报文吗？ 力。 当然这不现实，我们还得考虑接收方的处理能

#### 当接收方硬件不如发送方，或者系统繁忙、资源紧张时，是无法瞬间处理这么多报文的。于是，这些报文只能被丢掉，使得网络效率非常低。

#### 为了解决这种现象发生，这就是滑动窗口的由来。TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，

接收方根据它的缓冲区，可以计算出后续能够接收多少字节的报文，这个数字叫做接收窗口。当内核接收到报文时，必须用缓冲区存放它们，这样剩余缓冲区空间变小，接收窗口也就变小了；当进程调用 read 函数后，数据被
读入了用户空间，内核缓冲区就被清空，这意味着主机可以接收更多的报文，接收窗口就会变大。
因此，接收窗口并不是恒定不变的，接收方会把当前可接收的大小放在起到窗口大小通知的作用。 TCP 报文头部中的 **窗口字段** ，这样就可以

发送方的窗口等价于接收方的窗口吗？如果不考虑拥塞控制，发送方的窗口大小「约等于」接收方的窗口大小，因为窗口通知报文在网络传输是存在时延的，所以是约等于的关系。


#### 从上图中可以看到，窗口字段只有 2 个字节，因此它最多能表达 65535 字节大小的窗口，也就是 64KB 大小。

#### 这个窗口大小最大值，在当今高速网络下，很明显是不够用的。所以后续有了扩充窗口的方法： 在 TCP 选项字段

#### 定义了窗口扩大因子，用于扩大位（2^16 * 2^ 14 = 2^30），所以此时窗口的最大值可以达到 TCP 通告窗口，其值大小是 2^14 1GB，这样就使。 TCP 的窗口大小从 16 位扩大为 30


Linux 中打开这一功能，需要把 tcp_window_scaling 配置设为 1 （默认打开）：

#### 要使用窗口扩大选项，通讯双方必须在各自的 SYN 报文中发送这个选项：

#### 主动建立连接的一方在 SYN 报文中发送这个选项；

#### 而被动建立连接的一方只有在收到带窗口扩大选项的 SYN 报文之后才能发送这个选项。

这样看来，只要进程能及时地调用地放大，发送方也就无限地提升发送速度。 read 函数读取数据，并且接收缓冲区配置得足够大，那么接收窗口就可以无限

**这是不可能的，因为网络的传输能力是有限的，当发送方依据发送窗口，发送超过网络处理能力的报文时，路由器会直接丢弃这些报文。因此，缓冲区的内存并不是越大越好。**


### 如何确定最大传输速度？

#### 在前面我们知道了核缓冲区大小决定。如果缓冲区与网络传输能力匹配，那么缓冲区的利用率就达到了最大化。 TCP 的传输速度，受制于发送窗口与接收窗口，以及网络设备传输能力。其中，窗口大小由内

#### 问题来了，如何计算网络的传输能力呢？

#### 相信大家都知道网络是有「带宽」限制的，带宽描述的是网络传输能力，它与内核缓冲区的计量单位不同:

带宽是单位时间内的流量，表达是「速度」，比如常⻅的带宽 100 MB/s；
缓冲区单位是字节，当网络速度乘以时间才能得到字节数；
这里需要说一个概念，就是带宽时延积，它决定网络中⻜行报文的大小，它的计算方式：

比如最大带宽是* 0.01s = 1MB 的字节。 100 MB/s，网络时延（RTT）是 10ms 时，意味着客户端到服务端的网络一共可以存放 100MB/s

这个时，这 1MB 1MB 是带宽和时延的乘积，所以它就叫「带宽时延积」（缩写为也表示「⻜行中」的 TCP 报文大小，它们就在网络线路、路由器等网络设备上。如果⻜行报文超过了 BDP，Bandwidth Delay Product）。同
1 MB，就会导致网络过载，容易丢包。
**由于发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了「已发送未确认」的⻜行报文的上限。因此，发送缓冲区不能超过「带宽时延积」。**

发送缓冲区与带宽时延积的关系：
如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的网络传输，同时导致网络过载，容易丢包；
如果发送缓冲区「小于」带宽时延积，就不能很好的发挥出网络的传输效率。
所以，发送缓冲区的大小最好是往带宽时延积靠近。

### 怎样调整缓冲区大小？

在 Linux 中发送缓冲区和接收缓冲都是可以用参数调节的。设置完后，Linux 会根据你设置的缓冲区进行 **动态调
节** 。

```
调节发送缓冲区范围
```

先来看看发送缓冲区，它的范围通过 tcp_wmem 参数配置；

#### 上面三个数字单位都是字节，它们分别表示：

第一个数值是动态范围的最小值，4096 byte = 4K；
第二个数值是初始默认值，87380 byte ≈ 86K；
第三个数值是动态范围的最大值，4194304 byte = 4096K（4M）；
**发送缓冲区是自行调节的** 放掉。 ，当发送方发送的数据被确认后，并且没有新的数据要发送，就会把发送缓冲区的内存释

```
调节接收缓冲区范围
```
而接收缓冲区的调整就比较复杂一些，先来看看设置接收缓冲区范围的 tcp_rmem 参数：

#### 上面三个数字单位都是字节，它们分别表示：

第一个数值是动态范围的最小值，表示即使在内存压力下也可以保证的最小接收缓冲区大小，4K； 4096 byte =
第二个数值是初始默认值，87380 byte ≈ 86K；
第三个数值是动态范围的最大值，6291456 byte = 6144K（6M）；
**接收缓冲区可以根据系统空闲内存的大小来调节接收窗口：**
如果系统的空闲内存很多，就可以自动把缓冲区增大一些，这样传给对方的接收窗口也会变大，因而提升发送方发送的传输数据数量；
反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常工作；


发送缓冲区的调节功能是自动开启的， **而接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能** ：

#### 调节 TCP 内存范围

接收缓冲区调节时，怎么知道当前内存是否紧张或充分呢？这是通过 tcp_mem 配置完成的：

#### 上面三个数字单位不是字节，而是「⻚面大小」， 1 ⻚表示 4KB，它们分别表示：

#### 当 TCP 内存小于第 1 个值时，不需要进行自动调节；

#### 在第 1 和第 2 个值之间时，内核开始调节接收缓冲区的大小；

#### 大于第 3 个值时，内核不再为 TCP 分配新内存，此时新连接是无法建立的；

一般情况下这些值是在系统启动时根据系统内存数量计算得到的。根据当前 177120 ，当内存为 (177120 * 4) / 1024K ≈ 692M 时，系统将无法为新的 TCP tcp_mem 连接分配内存，即最大内存⻚面数是 TCP 连接将被拒
绝。

```
根据实际场景调节的策略
```
在高并发服务器中，为了兼顾网速与大量的并发连接， **我们应当保证缓冲区的动态调整的最大值达到带宽时延积，
而最小值保持默认的 4K 不变即可。而对于内存紧张的服务而言，调低默认值是提高并发的有效手段。**
同时，如果这是网络 **提升并发能力** 。需要注意的是， IO 型服务器，那么，tcp_wmem **调大** 和 tcp_rmem **tcp_mem** 的单位是字节，而 **的上限可以让 TCP** tcp_mem **连接使用更多的系统内存，这有利于** 的单位是⻚面大小。而且，
**千万不要在 socket 上直接设置 SO_SNDBUF 或者 SO_RCVBUF，这样会关闭缓冲区的动态调整功能。**


### 小结

#### 本节针对 TCP 优化数据传输的方式，做了一些介绍。

#### TCP 可靠性是通过 ACK 确认报文实现的，又依赖滑动窗口提升了发送速度也兼顾了接收方的处理能力。

可是，默认的滑动窗口最大值只有上限，在 Linux 下是通过设置 tcp_window_scaling 64 KB，不满足当今的高速网络的要求，要想提升发送速度必须提升滑动窗口的 为 1 做到的，此时最大值可高达 1GB。

滑动窗口定义了网络中⻜行报文的最大字节数，当它超过带宽时延积时，网络过载，就会发生丢包。而当它小于带宽时延积时，就无法充分利用网络带宽。因此，滑动窗口的设置，必须参考带宽时延积。

内核缓冲区决定了滑动窗口的上限，缓冲区可分为：发送缓冲区 tcp_wmem 和接收缓冲区 tcp_rmem。
Linux 而接收缓冲区需要把会对缓冲区动态调节，我们应该把缓冲区的上限设置为带宽时延积。发送缓冲区的调节功能是自动打开的， tcp_moderate_rcvbuf 设置为 1 来开启。其中，调节的依据是 TCP 内存范围 tcp_mem。

但需要注意的是，如果程序中的不建议在程序设置它俩，而是交给内核自动调整比较好。 socket 设置 SO_SNDBUF 和 SO_RCVBUF，则会关闭缓冲区的动态整功能，所以

有效配置这些参数后，既能够最大程度地保持并发性，也能让资源充裕时连接传输速度达到最大值。

参考资料：


#### [1] 系统性能调优必知必会.陶辉.极客时间.

#### [2] 网络编程实战专栏.盛延敏.极客时间.

[3] [http://www.blogjava.net/yongboy/archive/2013/04/11/397677.html](http://www.blogjava.net/yongboy/archive/2013/04/11/397677.html)
[4] [http://blog.itpub.net/31559359/viewspace-2284113/](http://blog.itpub.net/31559359/viewspace-2284113/)
[5] https://blog.51cto.com/professor/1909022
[6] https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux

## 读者问答^

```
读者问：backlog是通过系统调用间隔地修改“小林，请教个问题，somaxconnsomaxconn和backlog，比如是不是都是指的是Linux中listen()函数？accept” 队列？然后somaxconn是内核参数，
```
两者取最小值才是 accpet 队列。

```
读者问：TCP连接还是位于半连接队列中，没有丢弃吗？“小林，还有个问题要请教下，“如果 accept ” 队列满了，那么 server 扔掉 client 发过来的 ack”，也就是说该
```
1. 当 accept 队列满了，后续新进来的syn包都会被丢失
2. 我文章的突发流量例子是，那个连接进来的时候列突然满了，就会导致 ack 被丢弃，就一直处于半连接队列。 accept 队列还没满，但是在第三次握手的时候，accept 队

## 最后^

#### 跟大家说个沉痛的事情。

#### 我想大部分小伙伴都发现了，最近公众号改版， 顺序。 订阅号里的信息流不再是以时间顺序了，而是以推荐算法方式显示

#### 这对小林这种「 周更 」的作者，真的一次重重打击，非常的不友好。

#### 因为⻓时间没发文，公众号可能会把推荐的权重降低，这就会导致很多读者，会收不到我的「最新」的推文，如此下去，那小林文章不就无人问津了？（抱头痛哭 ...）

#### 另外，小林更文时间⻓的原因，不是因为偷懒。


#### 而是为了把知识点「写的更清楚，画的更清晰」，所以这必然会花费更多更⻓的时间。

#### 如果你认可和喜欢小林的文章，不想错过文章的第一时间推送，可以动动你的小手手，给小林公众号一个「 标 」。 星

**平时没事，就让「小林coding」静静地躺在你的订阅号底部，但是你要知道它在这其间并非无所事事，而是在努力
地准备着更好的内容，等准备好了，它自然会「蹦出」在你面前。
小林是专为大家图解的工具人，Goodbye，我们下次⻅！**

# 四、IP 篇

## 4 .1 IP 基础知识全家桶

#### 前段时间，有读者希望我写一篇关于 IP 分类地址、子网划分等的文章，他反馈常常混淆，摸不着头脑。

#### 那么，说来就来！而且要盘就盘全一点，顺便挑战下小林的图解功力，所以就来个 IP 基础知识全家桶 。

#### 吃完这个 IP 基础知识全家桶，包你撑着肚子喊出：“ 真香！ ”

#### 不多说，直接上菜，共分为 三道菜 ：

#### 首先是前菜 「 IP 基本认识 」


#### 其次是主菜 「IP 地址的基础知识」

#### 最后是点心 「IP 协议相关技术」

#### 为啥要比喻成菜？因为小林是 菜狗 （押韵不？）

## 前菜 —— IP 基本认识^

#### IP 在 TCP/IP 参考模型中处于第三层，也就是 网络层 。

网络层的主要作用是： **实现主机与主机之间的通信，也叫点对点（end to end）通信。**


#### 网络层与数据链路层有什么关系呢？

#### 有的小伙伴分不清 IP（网络层） 和 MAC （数据链路层）之间的区别和关系。

#### 其实很容易区分，在上面我们知道 之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。 IP 的作用是主机之间通信用的，而 MAC 的作用则是实现「直连」的两个设备

#### 举个生活的栗子，小林要去一个很远的地方旅行，制定了一个行程表，其间需先后乘坐⻜机、地铁、公交⻋才能抵达目的地，为此小林需要买⻜机票，地铁票等。

#### ⻜机票和地铁票都是去往特定的地点的，每张票只能够在某一限定区间内移动，此处的「区间内」就如同通信网络中数据链路。


#### 在区间内移动相当于数据链路层，充当区间内两个节点传输的功能，区间内的出发点好比源好比目的 MAC 地址。 MAC 地址，目标地点

#### 整个旅游行程表就相当于网络层，充当远程定位的功能，行程的开始好比源 IP，行程的终点好比目的 IP 地址。

#### 如果小林只有行程表而没有⻋票，就无法搭乘交通工具到达目的地。相反，如果除了⻋票而没有行程表，恐怕也很难到达目的地。因为小林不知道该坐什么⻋，也不知道该在哪里换乘。

#### 因此，只有两者兼备，既有某个区间的⻋票又有整个旅行的行程表，才能保证到达目的地。与此类似， 计算机网络

#### 中也需要「数据链路层」和「网络层」这个分层才能实现向最终目标地址的通信。

#### 还有重要一点，旅行途中我们虽然不断变化了交通工具，但是旅行行程的起始地址和目的地址始终都没变。其实，

#### 在网络中数据包传输中也是如此， MAC 一直在变化。 源IP地址和目标IP地址在传输过程中是不会变化的，只有源 MAC 地址和目标

## 主菜 —— IP 地址的基础知识^

#### 在 TCP/IP 网络通信时，为了保证能正常通信，每个设备都需要配置正确的 IP 地址，否则无法实现正常的通信。

IP 地址（IPv4 地址）由 32 位正整数来表示，IP 地址在计算机是以二进制的方式处理的。
而人类为了方便记忆采用了「.」隔开，再将每组转换成十进制。 **点分十进制** 的标记方式，也就是将 32 位 IP 地址以每 8 位为组，共分为 4 组，每组以


#### 那么，IP 地址最大值也就是

#### 也就说，最大允许 43 亿台计算机连接到网络。

#### 实际上，就是它们会有IP 地址并不是根据主机台数来配置的，而是以网卡。像服务器、路由器等设备都是有 2 个以上的 IP 地址。 2 个以上的网卡，也

#### 因此，让成的，所以实际能够连接到网络的计算机个数更是少了很多。 43 亿台计算机全部连网其实是不可能的，更何况 IP 地址是由「网络标识」和「主机标识」这两个部分组

```
可能有的小伙伴提出了疑问，现在不仅电脑配了亿啦，那是怎么能够支持这么多 IP 的呢？ IP， 手机、IPad 等电子设备都配了 IP 呀，照理来说肯定会超过 43
```
因为会根据一种可以更换论和说明。 IP 地址的技术 NAT，使得可连接计算机数超过 43 亿台。 NAT 技术后续会进一步讨

### IP 地址的分类

#### 互联网诞生之初，IP 地址显得很充裕，于是计算机科学家们设计了 分类地址 。

#### IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。


#### 上图中⻩色部分为分类号，用以区分 IP 地址类别。

#### 什么是 A、B、C 类地址？

#### 其中对于你是 B 小区 A、 1 B栋、 101 C 类主要分为两个部分，分别是号。 网络号和主机号 。这很好理解，好比小林是 A 小区 1 栋 101 号，

#### 我们可以用下面这个表格， 就能很清楚的知道 A、B、C 分类对应的地址范围、最大主机个数。


#### A、B、C 分类地址最大主机个数是如何计算的呢？

#### 最大主机个数，就是要看主机号的位数，如 C 类地址的主机号占 8 位，那么 C 类地址的最大主机个数：

#### 为什么要减 2 呢？

#### 因为在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和 全为 0 地址。


#### 主机号全为 1 指定某个网络下的所有主机，用于广播

#### 主机号全为 0 指定某个网络

#### 因此，在分配过程中，应该去掉这两种情况。

#### 广播地址用于什么？

#### 广播地址用于在 同一个链路中相互连接的主机之间发送数据包 。

#### 学校班级中就有广播的例子，在准备上课的时候，通常班⻓会喊：不是全部都站起来了？这个句话就有广播的含义。 “上课， 全体起立！”，班里的同学听到这句话是

#### 当主机号全为 1 时，就表示该网络的广播地址。例如把 172.20.0.0/16 用二进制表示如下：

#### 10101100.00010100.00000000.00000000

#### 将这个地址的 主机部分全部改为 1 ，则形成广播地址：

#### 10101100.00010100.11111111.11111111

#### 再将这个地址用十进制表示，则为 172.20.255.255 。

#### 广播地址可以分为本地广播和直接广播两种。

#### 在本网络内广播的叫做本地广播 因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达。例如网络地址为 192.168.0.0/24 192.168.0.0/24 的情况下，广播地址是以外的其他链路上。 192.168.0.255 。

#### 在不同网络之间的广播叫做直接广播 。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地


#### 址发送192.168.1.1~192.168.1.254 IP 包。收到这个包的路由器，将数据转发给的主机都能收到这个包（由于直接广播有一定的安全问题，多数情况下会在路由 192.168.1.0/24，从而使得所有

#### 器上设置为不转发。） 。


#### 什么是 D、E 类地址？

#### 而用。 D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于 多播 ，E 类是预留的分类，暂时未使

#### 多播地址用于什么？

#### 多播用于 将包发送给特定组内的所有主机。

#### 还是举班级的栗子，老师说：播的含义了。 “最后一排的同学，上来做这道数学题。”，老师指定的是最后一排的同学，也就是多

#### 由于广播无法穿透路由，若想给其他网段发送同样的包，就可以使用可以穿透路由的多播。


#### 多播使用的 D 类地址，其前四位是 1110 就表示是多播地址，而剩下的 28 位是多播的组编号。

#### 从 224.0.0.0 ~ 239.255.255.255 都是多播的可用范围，其划分为以下三类：

#### 224.0.0.0 ~ 224.0.0.255 为预留的组播地址，只能在局域网中，路由器是不会进行转发的。


```
224.0.1.0 ~ 238.255.255.255 为用户可用的组播地址，可以用于 Internet 上。
239.0.0.0 ~ 239.255.255.255 为本地管理组播地址，可供内部网在内部使用，仅在特定的本地范围内有效。
IP 分类的优点
```
不管是路由器还是主机解析到一个能很快的找出网络地址和主机地址。 IP 地址时候，我们判断其 IP 地址的首位是否为 0 ，为 0 则为 A 类地址，那么就

其余分类判断方式参考如下图：


#### 所以，这种分类地址的优点就是 简单明了、选路（基于网络地址）简单 。

#### IP 分类的缺点

#### 缺点一

#### 同一网络下没有地址层次 分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就，比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划 缺少地址的灵活性 。

#### 缺点二

#### A、B、C类有个尴尬处境，就是 不能很好的与现实网络匹配 。

#### C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计一个网吧都不够用。

#### 而规模，闲着的地址就是浪费。 B 类地址能包含的最大主机数量又太多了， 6 万多台机器放在一个网络下面，一般的企业基本达不到这个

#### 这两个缺点，都可以在 CIDR 无分类地址解决。


### 无分类地址 CIDR

#### 正因为 IP 分类存在许多缺点，所以后面提出了无分类地址的方案，即 CIDR。

#### 这种方式不再有分类地址的概念， 32 比特的 IP 地址被划分为两部分，前面是 网络号 ，后面是 主机号 。

#### 怎么划分网络号和主机号的呢？

表示形式性。 a.b.c.d/x，其中 /x 表示前 x 位属于 **网络号** ， x 的范围是 0 ~ 32，这就使得 IP 地址更加具有灵活

比如 10.100.122.2/24，这种地址表示形式就是 CIDR，/24 表示前 24 位是网络号，剩余的 8 位是主机号。


#### 还有另一种划分网络号与主机号形式，那就是 子网掩码 ，掩码的意思就是掩盖掉主机号，剩余的就是网络号。

#### 将子网掩码和 IP 地址按位计算 AND，就可得到网络号。


#### 为什么要分离网络号和主机号？

#### 因为两台计算机要通讯，首先要判断是否处于同一个广播域内，即网络地址是否相同。如果网络地址相同，表明接受方在本网络上，那么可以把数据包直接发送到目标主机。

#### 路由器寻址工作中，也就是通过这样的方式来找到对应的网络号的，进而把数据包转发给对应的网络内。


#### 怎么进行子网划分？

#### 在上面我们知道可以通过子网掩码划分出网络号和主机号，那实际上子网掩码还有一个作用，那就是 划分子网 。

#### 子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址 。形式如下：


未做子网划分的 ip 地址：网络地址＋主机地址
做子网划分后的 ip 地址：网络地址＋（子网网络地址＋子网主机地址）
假设对 C 类地址进行子网划分，网络地址 192.168.1.0，使用子网掩码 255.255.255.192 对其进行子网划分。
C 类地址中前 24 位是网络号，最后 8 位是主机号，根据子网掩码可知 **从 8 位主机号中借用 2 位作为子网号** 。

#### 由于子网网络地址被划分成 2 位，那么子网地址就有 4 个，分别是 00 、 01 、 10 、 11 ，具体划分如下图：



#### 划分后的 4 个子网如下表格：


### 公有 IP 地址与私有 IP 地址

#### 在 A、B、C 分类地址，实际上有分公有 IP 地址和私有 IP 地址。

#### 平时我们办公室、家里、学校用的理、自己分配，而且可以重复。因此，你学校的某个私有 IP 地址，一般都是私有 IP IP 地址和我学校的可以是一样的。地址。因为这些地址允许组织内部的 IT 人员自己管

就像每个小区都有自己的楼编号和⻔牌号，你小区家可以叫问题。但一旦出了小区，就需要带上中山路 666 号（公网 IP (^1) 地址），是国家统一分配的，不能两个小区都叫中山栋 101 号，我小区家也可以叫 1 栋 101 ，没有任何
路 666 。
所以，公有样全世界的人才能访问。并且公有 IP 地址是有个组织统一分配的，假设你要开一个博客网站，那么你就需要去申请购买一个公有 IP 地址基本上要在整个互联网范围内保持唯一。 IP，这


#### 公有 IP 地址由谁管理呢？

#### 私有配机构」。 IP 地址通常是内部的 IT 人员管理，公有 IP 地址是由 ICANN 组织管理，中文叫「互联网名称与数字地址分

#### IANA 是 ICANN 的其中一个机构，它负责分配互联网 IP 地址，是按州的方式层层分配。


#### ARIN 北美地区

#### LACNIC 拉丁美洲和一些加勒比群岛

#### RIPE NCC 欧洲、中东和中亚

AfriNIC 非洲地区
APNIC 亚太地区
其中，在中国是由 CNNIC 的机构进行管理，它是中国国内唯一指定的全局 IP 地址管理的组织。

### IP 地址与路由控制

#### IP地址的 网络地址 这一部分是用于进行路由控制。

#### 路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。

#### 在发送根据该记录将 IP 包时，首先要确定 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有 相同网络地址 的记录，

#### 数最多的网络地址，也就是最⻓匹配。

#### 下面以下图的网络链路作为例子说明：

#### 1. 主机找到与目标地址 A 要发送一个 10.1.2.10 IP 包，其源地址是 的网络地址，于是包被转发到默认路由（路由器 10.1.1.30 和目标地址是 10.1.2.10，由于没有在主机 1 ） A 的路由表

#### 2. 路由器 1 收到 IP 包后，也在路由器 1 的路由表匹配与目标地址相同的网络地址记录，发现匹配到了，于


#### 是就把 IP 数据包转发到了 10.1.0.2 这台路由器 2

#### 3. 路由器口出去，最终经过交换机把 2 收到后，同样对比自身的路由表，发现匹配到了，于是把 IP 数据包转发到了目标主机 IP 包从路由器 2 的 10.1.2.1 这个接

#### 环回地址是不会流向网络

#### 环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。

计算机使用一个特殊的名。使用这个 IP 或主机名时，数据包不会流向网络。 IP 地址 **127.0.0.1 作为环回地址** 。与该地址具有相同意义的是一个叫做 localhost 的主机

### IP 分片与重组

#### 每种数据链路的最大传输单元等。 MTU 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节

#### 每种数据链路的MTU 也就不同。 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的

#### 其中，我们最常⻅数据链路是以太网，它的 MTU 是 1500 字节。

#### 那么当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。

#### 经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。

#### 假设发送方发送一个输，再交由接收方重组成大数据报。 4000 字节的大数据报，若要传输在以太网链路，则需要把数据报分片成 3 个小数据报进行传

#### 在分片传输中，一旦某个分片丢失，则会造成整个分片不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 IP 数据报作废，所以 MTU TCP 的数据报文。引入了 MSS 也就是在 TCP 层进行


### IPv6 基本认识

IPv4 的地址是 32 位的，大约可以提供 42 亿个地址，但是早在 2011 年 IPv4 地址就已经被分配完了。
但是 **被分配到一个** IPv6 的地址是 **IP 地址。** 128 位的，这可分配的地址数量是大的惊人，说个段子 **IPv6 可以保证地球上的每粒沙子都能**

但体验。 IPv6 除了有更多的地址之外，还有更好的安全性和扩展性，说简单点就是 IPv6 相比于 IPv4 能带来更好的网络

但是因为备进行升级，所以这可能是 IPv4 和 IPv6 不能相互兼容，所以不但要我们电脑、手机之类的设备支持，还需要网络运营商对现有的设 IPv6 普及率比较慢的一个原因。

```
IPv6 的亮点
```
IPv6 不仅仅只是可分配的地址变多了，它还有非常多的亮点。

```
IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址，真是 便捷到即插即用 啊。
IPv6 大 提高了传输的性能 包头包首部⻓度采用固定的值。 40 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大
IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大 提升了安全性 。
... （由你发现更多的亮点）
IPv6 地址的标识方法
```
IPv4 地址⻓度共 32 位，是以每 8 位作为一组，并用点分十进制的表示方式。
IPv6 地址⻓度是 128 位，是以每 16 位作为一组，每组用冒号 「:」 隔开。

#### 如果出现连续的连续的冒号。 0 时还可以将这些 0 省略，并用两个冒号 「::」隔开。但是，一个 IP 地址中只允许出现一次两个


```
IPv6 地址的结构
```
IPv6 类似 IPv4，也是通过 IP 地址的前几位标识 IP 地址的种类。
IPv6 的地址主要有以下类型地址：
单播地址，用于一对一的通信
组播地址，用于一对多的通信
任播地址，用于通信最近的节点，最近的节点是由路由协议决定
没有广播地址

```
IPv6 单播地址类型
```
对于一对一通信的 IPv6 地址，主要划分了三类单播地址，每类地址的有效范围都不同。
在同一链路单播通信，不经过路由器，可以使用 **链路本地单播地址** ，IPv4 没有此类型
在内网里单播通信，可以使用 **唯一本地地址** ，相当于 IPv4 的私有 IP
在互联网通信，可以使用 **全局单播地址** ，相当于 IPv4 的公有 IP


### IPv4 首部与 IPv6 首部

IPv4 首部与 IPv6 首部的差异如下图：

IPv6 相比 IPv4 的首部改进：


```
取消了首部校验和字段。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。
取消了分片 种操作只能在源与目标主机，这将大大提高了路由器转发的速度。 /重新组装相关字段。 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这
取消选项字段。 「下一个首部」指出的位置上。删除该选项字段使的 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 的首部成为固定⻓度的 40 字节。 IPv6 首部中的
```
## 点心 —— IP 协议相关技术^

#### 跟 IP 协议相关的技术也不少，接下来说说与 IP 协议相关的重要且常⻅的技术。

#### DNS 域名解析

#### ARP 与 RARP 协议

#### DHCP 动态获取 IP 地址

#### NAT 网络地址转换

#### ICMP 互联网控制报文协议

#### IGMP 因特网组管理协

### DNS

#### 我们在上网的时候，通常使用的方式是域名，而不是 IP 地址，因为域名方便人类记忆。

#### 那么实现这一技术的就是 DNS 域名解析 ，DNS 可以将域名网址自动转换为具体的 IP 地址。

#### 域名的层级关系

DNS 中的域名都是用 **句点** 来分隔的，比如 [http://www.server.com，这里的句点代表了不同层次之间的](http://www.server.com，这里的句点代表了不同层次之间的) **界限** 。
在域名中， **越靠右** 的位置表示其层级 **越高** 。
毕竟域名是外国人发明，所以思维和中国人相反，比如说一个城市地点的时候，外国喜欢从小到大的方式顺序说起（如 XX 街道 XX 区 XX 市 XX 省），而中国则喜欢从大到小的顺序（如 XX 省 XX 市 XX 区 XX 街道）。

根域是在最顶层，它的下一层就是 com 顶级域，再下面是 server.com。
所以域名的层级关系类似一个树状结构：
根 DNS 服务器
顶级域 DNS 服务器（com）
权威 DNS 服务器（server.com）


#### 根域的根域 DNS DNS 服务器了。服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问

#### 因此，客户端只要能够找到任意一台位于下层的某台目标 DNS 服务器。 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到

#### 域名解析的工作流程

浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件hosts ，如果还是没有，就会 DNS 服务器进行查询，查询的过程如下：

1. 客户端首先会发出一个的 TCP/IP 设置中填写的 DNS DNS 请求，问服务器地址）。 [http://www.server.com](http://www.server.com) 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端
2. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 [http://www.server.com](http://www.server.com) [http://www.server.com，则它直接返回](http://www.server.com，则它直接返回) 的 IP 地址吗？ IP ” 地址。根域名
    服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
3. 根理 DNS ”，我给你收到来自本地 .com 顶级域名服务器地址给你，你去问问它吧。 DNS 的请求后，发现后置是 .com，说：”“www.server.com 这个域名归 .com 区域管
4. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 [http://www.server.com](http://www.server.com) 的 IP 地址吗？”
5. 顶级域名服务器说：“我给你负责 [http://www.server.com](http://www.server.com) 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
6. 本地DNS DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威


#### 7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。

#### 8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。

#### 至此，我们完成了 DNS 的解析过程。现在总结一下，整个过程我画成了一个图。

#### DNS 域名解析的过程蛮有意思的，整个过程就和我们日常生活中找人问路的过程类似， 只指路不带路 。

### ARP

#### 在传输一个跳。然而，网络层的下一层是数据链路层，所以我们还要知道「下一跳」的 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 MAC 地址。 IP 数据包下一

#### 由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 ARP 协议 ，求得下一跳的 MAC 地址。

#### 那么 ARP 又是如何知道对方 MAC 地址的呢？

#### 简单地说，ARP 是借助 ARP 请求与 ARP 响应 两种类型的包确定 MAC 地址的。


#### 主机会通过 广播发送 ARP 请求 ，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。

#### 当同个链路中的所有设备收到地址与自己的 IP 地址一致，那么这个设备就将自己的 ARP 请求时，会去拆开 ARP MAC 请求包里的内容，如果地址塞入 ARP 响应包 返回给主机。 ARP 请求包中的目标 IP

#### 操作系统通常会把第一次通过地址。 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC

#### 不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除。

#### RARP 协议你知道是什么吗？

#### ARP 务器等小型嵌入式设备接入到网络时就经常会用得到。协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是 已知 MAC 地址求 IP 地址 。例如将打印机服

#### 通常这需要架设一台入到网络，接着： RARP 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接

#### 该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。

#### RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。


#### 最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。

### DHCP

#### DHCP 琐的过程。在生活中我们是很常⻅的了，我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁

#### 接下来，我们来看看我们的电脑是如何通过 4 个步骤的过程，获取到 IP 的。



#### 先说明一点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。

#### 这 4 个步骤：

#### 客户端首先发起 DHCP 发现报文（DHCP DISCOVER） 的 IP 数据报，由于客户端没有 IP 地址，也不知道

#### DHCP 67 ） 并且使用服务器的地址，所以使用的是 0.0.0.0（端口 68 ） 作为源 UDP IP 广播 地址。通信，其使用的广播目的地址是DHCP 客户端将该 IP 数据报传递给链路层，链路层然后 255.255.255.255（端口

#### 将帧广播到所有的网络中设备。

#### DHCP 然使用 IP 服务器收到广播地址 DHCP 255.255.255.255发现报文时，用，该报文信息携带服务器提供可租约的 DHCP 提供报文（DHCP OFFER IP ） 向客户端做出响应。该报文仍地址、子网掩码、默认网关、

#### DNS 服务器以及 IP 地址租用期 。

#### 客户端收到一个或多个服务器的 求报文（DHCP REQUEST 进行响应，回显配置的参数。 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 DHCP 请

#### 最后，服务端用 DHCP ACK 报文 对 DHCP 请求报文进行响应，应答所要求的参数。

#### 一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。

#### 如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：

#### 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延⻓租期。

#### 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。

#### 可以发现，DHCP 交互中， 全程都是使用 UDP 广播通信 。

#### 咦，用的是广播，那如果都要配一个 DHCP 服务器？ DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，那不是每个网络

#### 所以，为了解决这一问题，就出现了 可以由一个 DHCP 服务器统一进行管理。 DHCP 中继代理 。有了 DHCP 中继代理以后， 对不同网段的 IP 地址分配也


#### DHCP 播 的形式发给客户端会向 DHCP DHCP 服务器。中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以 单

#### 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端 。

#### 因此，DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理IP地址。


### NAT

IPv4 户增速是非常惊人的，所以的地址是非常紧缺的，在前面我们也提到可以通过无分类地址来减缓 IPv4 地址依然有被耗尽的危险。 IPv4 地址耗尽的速度，但是互联网的用

于是，提出了一种 **网络地址转换 NAT** 的方法，再次缓解了 IPv4 地址耗尽的问题。
简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。

```
那不是 N 个私有 IP 地址，你就要 N 个公有 IP 地址？这怎么就缓解了 IPv4 地址耗尽的问题？这不瞎扯吗？
```
确实是，普通的 NAT 转换没什么意义。
由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。
因此，可以把 IP 地址 + 端口号一起进行转换。
这样，就用一个全球 IP 地址就可以了，这种转换技术就叫 **网络地址与端口转换 NAPT。**
很抽象？来，看下面的图解就能瞬间明白了。


#### 图中有两个客户端本地端口都是 1025 192.168.1.10 。 和 192.168.1.11 同时与服务器 183.232.231.172 进行通信，并且这两个客户端的

#### 此时， 两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分。

#### 于是，生成一个间进行通信。 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之

#### 这种转换表在就会生成这个表。而后又随着收到关闭连接时发出 NAT 路由器上自动生成。例如，在 TCP FIN 的情况下，建立包的确认应答从表中被删除。 TCP 连接首次握手时的 SYN 包一经发出，

#### NAT 那么牛逼，难道就没缺点了吗？

#### 当然有缺陷，肯定没有十全十美的方案。

#### 由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：

#### 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。

#### 转换表的生成与转换操作都会产生性能开销。

#### 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。

#### 如何解决 NAT 潜在的问题呢？

#### 解决的方法主要有两种方法。


第一种就是改用 _IPv6_
IPv6 IPv6 可用范围非常大，以至于每台设备都可以配置一个公有普及速度还需要一些时间。 IP 地址，就不搞那么多花里胡哨的地址转换了，但是

第二种 _NAT_ 穿透技术
NAT 备的公有穿越技术拥有这样的功能，它能够让网络应用程序主动发现自己位于 IP，并为自己建立端口映射条目，注意这些都是 NAT设备后的应用程序自动完成的。 NAT 设备之后，并且会主动获得 NAT 设

也就是说，在的数据包，于是它主动配合 NAT 穿透技术中， NAT NAT设备的操作，主动地建立好映射，这样就不像以前由设备后的应用程序处于主动地位，它已经明确地知道 NAT NAT 设备来建立映射了。设备要修改它外发

说人话，就是客户端主动从就不需要 NAT 设备来进行转换了。 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，

### ICMP

ICMP 全称是 **Internet Control Message Protocol** ，也就是 **互联网控制报文协议** 。
里面有个关键词 —— **控制** ，如何控制的呢？
网络包在复杂的网络传输环境里，常常会遇到各种问题。
当遇到问题的时候，总不能死个不明不白，没头没脑的作⻛不是计算机网络的⻛格。所以需要传出消息，报告遇到了什么问题，这样才可以调整传输策略，以此来控制整个局面。

ICMP 功能都有啥？
ICMP 主要的功能包括： **确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置
等。**
在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将 **由 ICMP 负责通知** 。


#### 如上图例子，主机这时，路由器 2 就会向主机A 向主机 AB 发送一个发送了数据包，由于某种原因，途中的路由器 ICMP 目标不可达数据包，说明发往主机 2 未能发现主机 B 的包未能成功。 B 的存在，

#### ICMP 的这种通知消息会使用 IP 进行发送 。

#### 因此，从路由器包的主机 A 则分解 2 返回的 ICMP ICMP 的首部和数据域以后得知具体发生问题的原因。包会按照往常的路由控制先经过路由器 1 再转发给主机 A 。收到该 ICMP

#### ICMP 类型

#### ICMP 大致可以分为两大类：

#### 一类是用于诊断的查询消息，也就是「 查询报文类型 」

#### 另一类是通知出错原因的错误消息，也就是「 差错报文类型 」


### IGMP

#### ICMP 跟 IGMP 是一点关系都没有的，就好像周杰与周杰伦的区别，大家不要混淆了。

#### 在前面我们知道了组播地址，也就是的主机不能收到数组包，怎么管理是否是在一组呢？那么，就需要 D 类地址，既然是组播，那就说明是只有一组的主机能收到数据包，不在一组 IGMP 协议了。


#### IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间 ，如上图中的蓝色部分。

#### IGMP 通过 IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转

#### 发组播包到对应的主机了。

#### IGMP 的路由器之间。报文采用 IP 封装，IP 头部的协议号为 2 ，而且 TTL 字段值通常为 1 ，因为 IGMP 是工作在主机与连接

#### IGMP 工作机制

IGMP 分为了三个版本分别是，IGMPv1、IGMPv2、IGMPv3。
接下来，以 IGMPv2 作为例子，说说 **常规查询与响应和离开组播组** 这两个工作机制。
常规查询与响应工作机制


#### 1. 路由器会周期性发送目的地址为 224.0.0.1（表示同一网段内所有主机和路由器） IGMP 常规查询报文 。

#### 2. 主机 1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10

#### 秒，计时器超时后主机就会发送组播地址）。如果在定时器超时之前，收到同一个组内的其他主机发送的成员关系报告报文，则自己不再发 IGMP 成员关系报告报文 （源 IP 地址为自己主机的 IP 地址，目的 IP 地址为

#### 送，这样可以减少网络中多余的 IGMP 报文数量。

#### 3. 路由器收到主机的成员关系报文后，就会在据到达路由器，它会把数据包转发出去。 IGMP 路由表中加入该组播组，后续网络中一旦该组播地址的数

#### 离开组播组工作机制

#### 离开组播组的情况一，网段中仍有该组播组：


1. 主机路由器） 1 要离开组 224.1.1.1，发送 IGMPv2 离组报文，报文的目的地址是 224.0.0.2（表示发向网段内的所有

2. 路由器否还有 (^) 224.1.1.1 收到该报文后，以组的其他成员。 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个），以便确认该网络是

3. 主机的成员，于是继续向该网络转发 3 仍然是组 224.1.1.1 的成员，因此它立即响应这个特定组查询。路由器知道该网络中仍然存在该组播组 224.1.1.1 的组播数据包。

离开组播组的情况二，网段中没有该组播组：

#### 1. 主机 1 要离开组播组 224.1.1.1，发送 IGMP 离组报文。


#### 2. 路由器收到该报文后，以组 224.1.1.1 已经没有其他成员了，因此没有主机响应这个查询。 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个）。此时在该网段内，

#### 3. 一定时间后，路由器认为该网段中已经没有数据包。 224.1.1.1 组播组成员了，将不会再向这个网段转发该组播地址的

#### 参考资料：

#### [1] 计算机网络-自顶向下方法.陈鸣 译.机械工业出版社

#### [2] TCP/IP详解 卷 1 ：协议.范建华 译.机械工业出版社

#### [3] 图解TCP/IP.竹下隆史.人⺠邮电出版社

## 读者问答^

```
读者问题：dhcp重新请求个“组播不太懂。。。假设一台机器加入组播地址，需要把IP吗？” IP改成组播地址吗？如果离开某个组播地址，需要
```
组播地址不是用于机器udp协议，机器发送UDPip地址的，因为组播地址没有网络号和主机号，所以跟组播数据时，目标地址填的是组播地址，那么在组播组内的机器都能收到数据包。dhcp没关系。组播地址一般是用于

是否加入组播组和离开组播组，是由socket一个接口实现的，主机ip是不用改变的。

## 最后^

#### 哈喽，我是小林，就爱图解计算机基础，如果觉得文章对你有帮助，别忘记关注我哦！


## 4.2 ping 的工作原理

在日常生活或工作中，我们在判断与对方 **网络是否畅通** ，使用的最多的莫过于 ping 命令了。
“ **那你知道 ping 是如何工作的吗？** ” —— 来自小林的灵魂拷问
可能有的小伙伴奇怪的问：“我虽然不明白它的工作，但 ping 我也用的贼 6 啊！”
你用的是 6 ，但你在面试官面前，你就 6 不起来了，毕竟他们也爱问。
所以，我们要抱有「 **知其然，知其所以然** 」的态度，这样就能避免面试过程中，出⻔右拐的情况了。


#### 不知道的小伙伴也没关系，今天我们就来搞定它，搞懂它。消除本次的问号， 让问号少一点 。


## IP协议的助手 —— ICMP 协议^

ping 是基于 ICMP 协议工作的，所以要明白 ping 的工作，首先我们先来熟悉 **ICMP 协议** 。

```
ICMP 是什么？
```
ICMP 全称是 **Internet Control Message Protocol** ，也就是 **互联网控制报文协议** 。
里面有个关键词 —— **控制** ，如何控制的呢？
网络包在复杂的网络传输环境里，常常会遇到各种问题。当遇到问题的时候，总不能死的不明不白，没头没脑的作⻛不是计算机网络的⻛格。所以需要传出消息，报告遇到了什么问题，这样才可以调整传输策略，以此来控制整个
局面。

```
ICMP 功能都有啥？
```
**等。** ICMP^ 主要的功能包括： **确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置**
在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将 **由 ICMP 负责通知** 。


#### 如上图例子，主机这时，路由器 2 就会向主机A 向主机 AB 发送一个发送了数据包，由于某种原因，途中的路由器 ICMP 目标不可达数据包，说明发往主机 2 未能发现主机 B 的包未能成功。 B 的存在，

#### ICMP 的这种通知消息会使用 IP 进行发送 。

#### 因此，从路由器包的主机 A 则分解 2 返回的 ICMP ICMP 的首部和数据域以后得知具体发生问题的原因。包会按照往常的路由控制先经过路由器 1 再转发给主机 A 。收到该 ICMP

#### ICMP 包头格式

#### ICMP 报文是封装在 IP 包里面，它工作在网络层，是 IP 协议的助手。


#### ICMP 包头的 类型 字段，大致可以分为两大类：

#### 一类是用于诊断的查询消息，也就是「 查询报文类型 」

#### 另一类是通知出错原因的错误消息，也就是「 差错报文类型 」


## 查询报文类型^

#### 回送消息 —— 类型 0 和 8

**回送消息** 就是利用这个消息实现的。用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息，ping 命令


可以向对端主机发送的 **回送应答** 消息（ICMP Echo Reply Message **回送请求** 的消息（ICMP Echo Request Message，类型 0 ）。 ，类型 8 ），也可以接收对端主机发回来

#### 相比原生的 ICMP，这里多了两个字段：

#### 标识符 ：用以区分是哪个应用程序发 ICMP 包，比如用进程 PID 作为标识符；

#### 序号 ：序列号从 0 开始，每发送一次新的回送请求就会加 1 ， 可以用来确认网络包是否有丢失。

在 **选项数据** 中，ping 还会存放发送请求的时间值，来计算往返时间，说明路程的⻓短。

## 差错报文类型^

#### 接下来，说明几个常用的 ICMP 差错报文的例子：

#### 目标不可达消息 —— 类型 为 3

#### 原点抑制消息 —— 类型 4


#### 重定向消息 —— 类型 5

#### 超时消息 —— 类型 11

```
目标不可达消息（Destination Unreachable Message） —— 类型为 3
```
IP 中显示不可达的具体原因，原因记录在路由器无法将 IP 数据包发送给目标地址时，会给发送端主机返回一个 ICMP 包头的 **代码** 字段。 **目标不可达** 的 ICMP 消息，并在这个消息

由此，根据 ICMP 不可达的具体消息，发送端主机也就可以了解此次发送 **不可达的具体原因** 。
举例 6 种常⻅的目标不可达类型的 **代码** ：

#### 网络不可达代码为 0

#### 主机不可达代码为 1

#### 协议不可达代码为 2

#### 端口不可达代码为 3

#### 需要进行分片但设置了不分片位代码为 4


#### 为了给大家说清楚上面的目标不可达的原因， 小林牺牲自己给大家送 5 次外卖。

#### 为什么要送外卖？别问，问就是为 35 岁的老林做准备 ...

**a. 网络不可达代码为 0**
外卖版本：
小林第一次送外卖时，小区里只有没这个地方。 A 和 B 区两栋楼，但送餐地址写的是 C 区楼，小林表示头上很多问号，压根就

正常版本：
IP **网络不可达** 地址是分为网络号和主机号的，所以当路由器中的路由器表匹配不到接收方（Network Unreachable）的原因告知主机。 IP 的网络号，就通过 ICMP 协议以

自从不再有网络分类以后，网络不可达也渐渐不再使用了。
**b. 主机不可达代码为 1**
外卖版本：
小林第二次送外卖时，这次小区有找不到这个房间。 5 层楼高的 C 区楼了，找到地方了，但送餐地址写的是 C 区楼 601 号房 ，说明

正常版本：
当路由表中没有该主机的信息，或者该主机没有连接到网络，那么会通过Unreachable）的原因告知主机。 ICMP 协议以 **主机不可达** （Host


**c. 协议不可达代码为 2**
外卖版本：
小林第三次送外卖时，这次小区有人说的是英语，我说的是中文！语言不通，外卖送达失败 C 区楼，也有 601 号房，找到地方了，也找到房间了，但是一开⻔人家是外国~

正常版本：
当主机使用么会通过 ICMP TCP 协议以协议访问对端主机时，能找到对端的主机了，可是对端主机的防火墙已经禁止 **协议不可达** 的原因告知主机。 TCP 协议访问，那

**d. 端口不可达代码为 3**
外卖版本：
小林第四次送外卖时，这次小区有的人了，但是人家说他要的不是外卖，而是快递。。。 C 区楼，也有 601 号房，找到地方了，也找到房间了，房间里的人也是说中文

正常版本：

当主机访问对端主机 8080 端口，那么会通过 (^8080) ICMP 端口时，这次能找到对端主机了，防火墙也没有限制，可是发现对端主机没有进程监听协议以 **端口不可达** 的原因告知主机。
**e. 需要进行分片但设置了不分片位代码为 4**
外卖版本：
小林第五次送外卖时，这次是个吃播博主点了台电动⻋装不下呀，这样就没办法送达了。 100 份外卖，但是吃播博主要求一次性要把全部外卖送达，小林的一
正常版本：
发送端主机发送MTU 大小的数据包时，不会进行分片，而是直接抛弃。 IP 数据报时，将 IP 首部的 **分片禁止标志位** 设置为 1 。根据这个标志位，途中的路由器遇到超过
随后，通过一个 ICMP 的不可达消息类型， **代码为 4** 的报文，告知发送端主机。
原点抑制消息（ICMP Source Quench Message） —— 类型 4
在使用低速广域线路的情况下，连接 WAN 的路由器可能会遇到网络拥堵的问题。
ICMP 原点抑制消息的目的就是 **为了缓和这种拥堵情况** 。


#### 当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个

#### ICMP 原点抑制消息 。

#### 收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况，从而增大的情况。 IP 包的传输间隔，减少网络拥堵

#### 然而，由于这种 ICMP 可能会引起不公平的网络通信，一般不被使用。

```
重定向消息（ICMP Redirect Message） —— 类型 5
```
如果路由器发现发送端主机使用了「不是最优」的路径发送数据，那么它会返回一个机。 ICMP **重定向消息** 给这个主

在这个消息中包含了过这样的 ICMP 消息告知发送端，让它下次发给另外一个路由器。 **最合适的路由信息和源数据** 。这主要发生在路由器持有更好的路由信息的情况下。路由器会通

好比，小林本可以过条⻢路就能到的地方，但小林不知道，所以绕了一圈才到，后面小林知道后，下次小林就不会那么 **傻** 再绕一圈了。

```
超时消息（ICMP Time Exceeded Message） —— 类型 11
```
IP **0 时该** 包中有一个字段叫做 **IP 包会被丢弃。** TTL （Time To Live，生存周期），它的 **值随着每经过一次路由器就会减 1 ，直到减到**

此时，路由器将会发送一个 ICMP **超时消息** 给发送端主机，并通知该包已被丢弃。
设置发。 IP 包生存周期的主要目的，是为了在路由控制遇到问题发生循环状况时，避免 IP 包无休止地在网络上被转


#### 此外，有时可以用 TTL 控制包的到达范围，例如设置一个 较小的 TTL 值 。

## ping —— 查询报文类型的使用^

接下来，我们重点来看 ping 的 **发送和接收过程** 。
同个子网下的主机 A 和 主机 B，主机 A 执行ping 主机 B 后，我们来看看其间发送了什么？

ping 命令执行的时候，源主机首先会构建一个 **ICMP 回送请求消息** 数据包。
ICMP 数据包内包含多个字段，最重要的是两个：
第一个是 **类型** ，对于回送请求消息而言该字段为 8 ；


另外一个是 **序号** ，主要用于区分连续 ping 的时候发出的多个数据包。
每发出一个请求数据包，序号会自动加间。 1 。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时

#### 然后，由本机 IP 地址作为 ICMP 协议将这个数据包连同地址 源地址 ， 协议 字段设置为 192.168.1.2 1 表示是 ICMP一起交给 协议，再加上一些其他控制信息，构建一个 IP 层。IP 层将以 192.168.1.2 作为 目的地址 IP， 数

#### 据包。

#### 接下来，需要加入以直接使用；如果没有，则需要发送 MAC 头。如果在本地 ARP ARP 协议查询映射表中查找出 MAC 地址，获得 IP 地址 MAC 192.168.1.2 地址后，由数据链路层构建一个数据所对应的 MAC 地址，则可

#### 帧，目的地址是的介质访问规则，将它们传送出去。 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网

#### 主机丢弃。 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就

#### 接收后检查该数据帧，将交给 ICMP 协议。 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后

#### 主机中的序号，然后再发送出去给主机 B 会构建一个 ICMP 回送响应消息 A。 数据包，回送响应数据包的 类型 字段为 0 ， 序号 为接收到的请求数据包


#### 在规定的时候间内，源主机如果没有接到消息，则说明目标主机可达。 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应

#### 此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。

#### 针对上面发送的事情，总结成了如下图：

#### 当然这只是最简单的，同一个局域网里面的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等等。

#### 但是对于路由器到达一个新的局域网，需要换 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 MAC 头里面的 MAC 地址。 IP 地址，选择路由的下一跳，还有每经过一个

说了这么多，可以看出 **（类型为 0 ）** 。 ping 这个程序是 **使用了 ICMP 里面的 ECHO REQUEST（类型为 8 ） 和 ECHO REPLY**

## traceroute —— 差错报文类型的使用^

有一款充分利用对等的命令叫做 ICMP tracert **差错报文类型** ）。 的应用叫做 traceroute（在UNIX、MacOS中是这个命令，而在Windows中

_1. traceroute_ 作用一
traceroute 的第一个作用就是 **故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。**
traceroute 的参数指向某个 **目的 IP 地址** ：
    traceroute 192 .168.1.100


#### 这个作用是如何工作的呢？

#### 它的原理就是利用种方法。 IP 包的 生存期限 从 1 开始按照顺序递增的同时发送 UDP 包 ，强制接收 ICMP 超时消息 的一

#### 比如，将 时 。 TTL 设置 为 1 ，则遇到第一个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是 时间超

#### 接下来将包，如此往复，直到到达目的主机。 TTL 设置为 2 ，第一个路由器过了，遇到第二个路由器也牺牲了，也同时返回了 ICMP 差错报文数据

这样的过程，traceroute 就可以拿到了所有的路由器 IP。
当然有的路由器根本就不会返回这个 ICMP，所以对于有的公网地址，是看不到中间经过的路由的。

```
发送方如何知道发出的 UDP 包是否到达了目的主机呢？
```
traceroute 在发送 UDP 包时，会填入一个 **不可能的端口号** 值作为 UDP 目标端口号（大于 3000 ）。当目的主
机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「 **端口不可达** 」。
所以， **当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机。**

_2. traceroute_ 作用二
traceroute 还有一个作用是 **故意设置不分片，从而确定路径的 MTU** 。

```
这么做是为了什么？
```
这样做的目的是为了 **路径MTU发现** 。
因为有的时候我们并不知道路由器的外网的 MTU 值就不一样了，所以我们要知道 MTU 大小，以太网的数据链路上的 MTU 的大小，从而控制发送的包大小。 MTU 通常是 1500 字节，但是非以


#### 它的工作原理如下：

#### 首先在发送端主机发送器不会对大数据包进行分片，而是将包丢弃。 IP 数据报时，将 IP 包首部的 分片禁止标志位设置为 1 。根据这个标志位，途中的路由

#### 随后，通过一个 片但设置了不分片位 ICMP 」。的不可达消息将 数据链路上 MTU 的值 一起给发送主机，不可达消息的类型为「 需要进行分


#### 发送主机端每次收到机。 ICMP 差错报文时就 减少 包的大小，以此来定位一个合适的 MTU 值，以便能到达目标主

#### 参考资料：

#### [1] 竹下隆史.图解TCP/IP.人⺠邮电出版社.

#### [2] 刘超.趣谈网络协议.极客时间.

## 读者问答^

```
读者问：“有个问题就是A的icmp到了B后，B为啥会自动给A一个回执 0 ？这是操作系统的底层设计吗？”
```
你说的操作系统协议栈发现是个回送请求“回执0”是指 ICMP 类型为 (^0) ICMP 吗？如果是的话，那么报文，那么协议栈就会组装一个回送应答（类型为 B 收到 A 的回送请求（类型为 8 ） 0 ICMP ）的 IMCP 报文，回应给B 主机
A。

## 最后^

#### 哈喽，我是小林，就爱图解计算机基础，如果觉得文章对你有帮助，别忘记关注我哦！


# 五、网络综合篇

## 5.1 键入网址到网⻚显示，期间发生了什么？

#### 想必不少小伙伴面试过程中，会遇到「 当键入网址后，到网⻚显示，其间发生了什么 」的面试题。

#### 还别说，这真是挺常问的这题，前几天坐在我旁边的主管电话面试应聘者的时候，也问了这个问题。

#### 接下来以下图较简单的网络拓扑模型作为例子，探究探究其间发生了什么？

## 孤单小弟 —— HTTP^

#### 浏览器做的第一步工作是解析 URL

首先浏览器做的第一步工作就是要对 URL 进行解析，从而生成发送给 Web 服务器的请求信息。
让我们看看一条⻓⻓的 URL 里的各个元素的代表什么，⻅下图：


#### 所以图中的⻓⻓的 URL 实际上是请求服务器里的文件资源。

#### 要是上图中的蓝色部分 URL 元素都省略了，那应该是请求哪个文件呢？


当没有路径名时，就代表访问根目录下事先设置的件，这样就不会发生混乱了。 **默认文件** ，也就是 /index.html 或者 /default.html 这些文

```
生产 HTTP 请求信息
```
对了。 URL 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息

#### 一个孤单一程呢？谁能保护我呢？我的目的地在哪呢？ HTTP 数据包表示：“我这么一个小小的数据包，没亲没友，直接发到浩瀚的网络，谁会知道我呢？谁能载我”。充满各种疑问的它，没有停滞不前，依然踏上了征途！


## 真实地址查询 —— DNS^

通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。
但在发送之前，还有一项工作需要完成，那就是必须提供通信对象的 IP 地址。 **查询服务器域名对应的 IP 地址** ，因为委托操作系统发送消息时，

比如我们打电话的时候，必须要知道对方的电话号码，但由于电话号码难以记忆，所以通常我们会将对方电话号姓名保存在通讯录里。 +

所以，有一种服务器就专⻔保存了 Web 服务器域名与 IP 的对应关系，它就是 DNS 服务器。

```
域名的层级关系
```
DNS 中的域名都是用 **句点** 来分隔的，比如 [http://www.server.com，这里的句点代表了不同层次之间的](http://www.server.com，这里的句点代表了不同层次之间的) **界限** 。
在域名中， **越靠右** 的位置表示其层级 **越高** 。
毕竟域名是外国人发明，所以思维和中国人相反，比如说一个城市地点的时候，外国喜欢从小到大的方式顺序说起（如 XX 街道 XX 区 XX 市 XX 省），而中国则喜欢从大到小的顺序（如 XX 省 XX 市 XX 区 XX 街道）。

根域是在最顶层，它的下一层就是 com 顶级域，再下面是 server.com。
所以域名的层级关系类似一个树状结构：
根 DNS 服务器
顶级域 DNS 服务器（com）
权威 DNS 服务器（server.com）


#### 根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。

#### 这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。

#### 因此，客户端只要能够找到任意一台位于下层的某台目标 DNS 服务器。 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到

#### 域名解析的工作流程

1. 客户端首先会发出一个的 TCP/IP 设置中填写的 DNS DNS 请求，问服务器地址）。 [http://www.server.com](http://www.server.com) 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端
2. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 [http://www.server.com](http://www.server.com) [http://www.server.com，则它直接返回](http://www.server.com，则它直接返回) 的 IP 地址吗？ IP ” 地址。根域名
    服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
3. 根理 DNS ”，我给你收到来自本地 .com 顶级域名服务器地址给你，你去问问它吧。 DNS 的请求后，发现后置是 .com，说：”“www.server.com 这个域名归 .com 区域管
4. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 [http://www.server.com](http://www.server.com) 的 IP 地址吗？”
5. 顶级域名服务器说：“我给你负责 [http://www.server.com](http://www.server.com) 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
6. 本地DNS DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威
7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。


#### 至此，我们完成了 DNS 的解析过程。现在总结一下，整个过程我画成了一个图。

#### DNS 域名解析的过程蛮有意思的，整个过程就和我们日常生活中找人问路的过程类似， 只指路不带路 。

#### 数据包表示：“DNS 老大哥厉害呀，找到了目的地了！我还是很迷茫呀，我要发出去，接下来我需要谁的帮助呢?”

## 指南好帮手 —— 协议栈^

#### 通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的 协议栈 。

#### 协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。


应用程序（浏览器）通过调用TCP 和 UDP 协议，它们两会接受应用层的委托执行收发数据的操作。 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的

协议栈的下面一半是用将网络包发送给对方的操作就是由 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而 IP 负责的。

此外 IP 中还包括 ICMP 协议和 ARP 协议。
ICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。
ARP 用于根据 IP 地址查询相应的以太网 MAC 地址。


#### IP 行发送和接收操作。下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执

#### 数据包看了这份指南表示：“原来我需要那么多大佬的协助啊，那我先去找找 TCP 大佬！”

## 可靠传输 —— TCP^

#### HTTP 是基于 TCP 协议传输的，所以在这我们先了解下 TCP 协议。

#### TCP 包头格式

#### 我们先看看 TCP 报文头部的格式：

#### 首先， 源端口号 和 目标端口 号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。


#### 接下来有包的 序 号，这个是为了解决包乱序的问题。

#### 还有应该有的是了解决不丢包的问题。 确认号 ，目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为

#### 接下来还有一些等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。 状态位 。例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接， FIN 是结束连接

#### 还有一个重要的就是处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。 窗口大小 。TCP 要做 流量控制 ，通信双方各声明一个窗口（缓存大小），标识自己当前能够的

#### 除了做流量控制以外，己，也即控制发送的速度。不能改变世界，就改变自己嘛。TCP还会做 拥塞控制 ，对于真正的通路堵⻋不堵⻋，它无能为力，唯一能做的就是控制自

#### TCP 传输数据之前，要先三次握手建立连接

#### 在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为 三次握手 。

#### 这个所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。

#### 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。

#### 然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。

#### 服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。

#### 客户端收到服务端发送的因为它一发一收成功了。 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED 状态，

#### 服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。

#### 所以三次握手目的是 保证双方都有发送和接收的能力 。

#### 如何查看 TCP 的连接状态？

TCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。


#### TCP 分割数据

#### 如果而不是一次性发送所有数据。 HTTP 请求消息比较⻓，超过了 MSS 的⻓度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，

#### MTU：一个网络包的最大⻓度，以太网中一般为 1500 字节。

#### MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大⻓度。

#### 数据会被以拆分的数据加上 MSS TCP 的⻓度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被头信息，然后交给 IP 模块来发送数据。


#### TCP 报文生成

TCP （HTTP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是默认端口号是 80 ， HTTPS 默认端口号是 443 ）。 Web 服务器监听的端口

在双方建立了连接后，的网络层处理。 TCP 报文中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报文之后，就需交给下面

至此，网络包的报文如下图。

#### 此时，遇上了了，安全感十足啊！有大佬可以保护我的可靠送达！但我应该往哪走呢？ TCP 的 数据包激动表示：“太好了，碰到了可靠传输的 TCP ”传输，它给我加上 TCP 头部，我不再孤单


## 远程定位 —— IP^

#### TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成 网络包 发送给通信对象。

#### IP 包头格式

#### 我们先看看 IP 报文头部的格式：


#### 在 IP 协议里面需要有 源地址 IP 和 目标地址 IP ：

#### 源地址IP，即是客户端输出的 IP 地址；

目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。
因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的 **协议号** ，要填写为 06 （十六进制），表示协议为 TCP。

```
假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？
```
当存在多个网卡时，在填写源地址应该使用哪个一块网卡来发送包。 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断

这个时候就需要根据 **路由表** 规则，来判断哪一个网卡作为源地址 IP。
在 Linux 操作系统，我们可以使用 route -n 命令查看当前系统的路由表。


举个例子，根据上面的路由表，我们假设 Web 服务器的目标地址是 192.168.10.200。

1. 首先先和第一条目的子网掩码（Destination 是 192.168.3.0，两者不一致所以匹配失败。Genmask）进行 **与运算** ，得到结果为 192.168.10.0，但是第一个条目的
2. 再与第二条目的子网掩码进行192.168.10.0 匹配成功，所以将使用 **与运算** ，得到的结果为 eth1 网卡的 IP 192.168.10.0地址作为 IP 包头的源地址。，与第二条目的 Destination


那么假设三条目匹配。 Web 服务器的目标地址是 10.100.20.100，那么依然依照上面的路由表规则判断，判断后的结果是和第

第三条目比较特殊，它目标地址和子网掩码都是自动匹配这一行。并且后续就把包发给路由器， (^) Gateway0.0.0.0，这表示 即是路由器的 **默认网关** IP ，如果其他所有条目都无法匹配，就会地址。
IP 报文生成
至此，网络包的报文如下图。


#### 此时，加上了力！不会害怕在浩瀚的互联网迷茫了！可是目的地好远啊，我下一站应该去哪呢？ IP 头部的数据包表示 ：“有 IP 大佬给我指路了，感谢 IP 层给我加上了” IP 包头，让我有了远程定位的能

## 两点传输 —— MAC^

#### 生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部 。

#### MAC 包头格式

#### MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。


#### 在 MAC 包头里需要 发送方 MAC 地址 和 接收方目标 MAC 地址 ，用于 两点之间的传输 。

#### 一般在 TCP/IP 通信里，MAC 包头的 协议类型 只使用：

#### 0800 ： IP 协议

#### 0806 ： ARP 协议

#### MAC 发送方和接收方如何确认?

#### 发送方 到 MAC 的头部就可以了。 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入

#### 接收方 很显然这里应该填写对方的的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 地址。 MAC 的地址，以太网就会帮我们把包发送过去，那么


所以先得搞清楚应该把包发给谁，这个只要查一下Gateway 列中的 IP 地址就可以了。 **路由表** 就知道了。在路由表中找到相匹配的条目，然后把包发给

```
既然知道要发给谁，按如何获取对方的 MAC 地址呢？
```
不知道对方 MAC 地址？不知道就喊呗。
此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。

#### ARP 我”。协议会在以太网中以 广播 的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉

#### 然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。

#### 如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的地址写入 MAC 头部，MAC 头部就完成了。 MAC 地址。然后，我们将这个 MAC

#### 好像每次都要广播获取，这不是很麻烦吗？


#### 放心，在后续操作系统会把本次查询结果放到一块叫做钟。 ARP 缓存 的内存空间留着以后用，不过缓存的时间就几分

#### 也就是说，在发包时：

#### 先查询的地址。 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中

#### 而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。

#### 查看 ARP 缓存内容

在 Linux 系统中，我们可以使用 arp -a 命令来查看 ARP 缓存的内容。

#### MAC 报文生成

#### 至此，网络包的报文如下图。



#### 此时，加上了兄弟，相信我可以到达最终的目的地！ MAC 头部的数据包万分感谢，说道”。 ：“感谢 MAC 大佬，我知道我下一步要去哪了！我现在有很多头部

#### 带着众多头部兄弟的数据包，终于准备要出⻔了。

## 出口 —— 网卡^

#### 网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将 信号 ，才能在网线上传输，也就是说，这才是真正的数据发送过程。 数字信息转换为电

#### 负责执行这一操作的是 网卡 ，要控制网卡还需要靠 网卡驱动程序 。

#### 网卡驱动从 在末尾加上用于检测错误的帧校验序列 IP 模块获取到包之后，会将其。 复制 到网卡内的缓存区中，接着会在其 开头加上报头和起始帧分界符，

#### 起始帧分界符是一个用来表示包起始位置的标记

#### 末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏

#### 最后网卡会将包转为电信号，通过网线发送出去。

#### 唉，真是不容易，发一个包，真是历经千辛万苦。致此，一个带有许多头部的数据终于踏上寻找目的地的征途了！

## 送别者 —— 交换机^

#### 下面来看一下包是如何通过交换机的。交换机的设计是将网络包为 二层网络设备 。 原样 转发到目的地。交换机工作在 MAC 层，也称


#### 交换机的包接收操作

#### 首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。

#### 然后通过包末尾的的工作方式和网卡不同。 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机

#### 计算机的网卡本身具有给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，并通过核对收到的包的接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因 MAC 地址判断是不是发给自己的，如果不是发

#### 此，和网卡不同， 交换机的端口不具有 MAC 地址 。

#### 将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。

#### 交换机的 MAC 地址表主要包含两个信息：

#### 一个是设备的 MAC 地址，

#### 另一个是该设备连接在交换机的哪个端口上。

#### 举个例子，如果收到的包的接收方的信息，可知这个地址位于 3 号端口上，然后就可以通过交换电路将包发送到相应的端口了。 MAC 地址为 00-02-B3-1C-9C-F9，则与图中表中的第 3 行匹配，根据端口列

#### 所以， 交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口 。


#### 当 MAC 地址表找不到指定的 MAC 地址会怎么样？

#### 地址表中找不到指定的时间没有工作导致地址被从地址表中删除了。 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段

#### 这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。

#### 这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后 只有相应的接收者才接收包，

#### 而其他设备则会忽略这个包 。

#### 有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”

#### 其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。

#### 局域网中每秒可以传输上千个包，多出一两个包并无大碍。

#### 此外，如果接收方 MAC 地址是一个 广播地址 ，那么交换机会将包发送到除源端口之外的所有端口。

#### 以下两个属于广播地址：

#### MAC 地址中的 FF:FF:FF:FF:FF:FF

#### IP 地址中的 255.255.255.255

#### 数据包通过交换机转发抵达了路由器，准备要离开土生土⻓的子网了。此时，数据包和交换机离别时说道：机兄弟，帮我转发到出境的大⻔，我要出远⻔啦！” “感谢交换

## 出境大⻔ —— 路由器^

#### 路由器与交换机的区别

#### 网络包经过交换机之后，现在到达了 路由器 ，并在此被转发到下一个路由器或目标设备。

#### 这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。

#### 不过在具体的操作过程上，路由器和交换机是有区别的。

#### 因为 路由器 是基于 IP 设计的，俗称 三层 网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；

#### 而 交换机 是基于以太网设计的，俗称 二层 网络设备，交换机的端口不具有 MAC 地址。


#### 路由器基本原理

#### 路由器的端口具有说，它和计算机的网卡是一样的。 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来

#### 当转发包时，首先路由器端口会接收发给自己的以太网包，然后将以太网包发送出去。 路由表 查询转发目标，再由相应的端口作为发送方

#### 路由器的包接收操作

#### 首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的校验。 FCS 进行错误

#### 如果没问题则检查则就丢弃这个包。 MAC 头部中的 接收方 MAC 地址 ，看看是不是发给自己的包，如果是就放到接收缓冲区中，否

#### 总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。

#### 查询路由表确定输出端口

#### 完成包接收操作之后，路由器就会 去掉 包开头的 MAC 头部。

#### MAC 头部的作用就是将包送达路由器 ，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路

#### 由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会 被丢弃 。

#### 接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。

#### 转发操作分为几个阶段，首先是查询 路由表 判断转发目标。


#### 具体的工作流程根据上图，举个例子。

#### 假设地址为器。 10.10.1.101 的计算机要向地址为 192.168.1.100 的服务器发送一个包，这个包先到达图中的路由

#### 判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。

#### 路由匹配和前面讲的一样，每个条目的子网掩码和标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。 192.168.1.100 IP 做 & 与运算 后，得到的结果与对应条目的目

#### 如第二条目的子网掩码第二条目的目标地址 192.168.1.0 255.255.255.0 匹配，该第二条目记录就会被作为转发目标。 与 192.168.1.100 IP 做 & 与运算 后，得到结果是 192.168.1.0 ，这与

#### 实在找不到匹配路由时，就会选择 默认路由 ，路由表中子网掩码为 0.0.0.0 的记录表示「默认路由」。

#### 路由器的发送操作

#### 接下来就会进入包的 发送操作 。

#### 首先，我们需要根据 路由表的网关列 判断对方的地址。

#### 如果网关是一个转发。 IP 地址，则这个IP 地址就是我们要转发到的目标地址， 还未抵达终点 ，还需继续需要路由器


#### 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地

#### 址了，说明 已抵达终点 。

#### 知道对方的MAC 地址。 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方

#### 路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。

#### 接下来是发送方制）表示 IP 协议。 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 0800 （十六进

#### 网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。

#### 发送出去的网络包会通过会根据这一地址将包传输到下一个路由器。 交换机 到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机

#### 接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。

#### 不知你发现了没有，在网络包传输的过程中，要 MAC 地址在以太网内进行 两个设备 之间的包传输。 源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址 ，因为需

#### 数据包通过多个路由器道友的帮助，在网络世界途经了很多路程，最终抵达了目的地的城⻔！城⻔值守的路由器，发现了这个小兄弟数据包原来是找城内的人，于是它就将数据包送进了城内，再经由城内的交换机帮助下，最终转发到

#### 了目的地了。数据包感慨万千的说道：“多谢这一路上，各路大侠的相助！”

## 互相扒皮 —— 服务器 与 客户端^

#### 数据包抵达了服务器，服务器肯定高兴呀，正所谓有朋自远方来，不亦乐乎？

#### 服务器高兴的不得了，于是开始扒数据包的皮！就好像你收到快递，能不兴奋吗？


#### 数据包抵达服务器后，服务器会先扒开数据包的包收起来。 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将

#### 接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。

#### 于是，扒开个 ACK，如果不是就丢弃。 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。

#### 于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。

#### 服务器的 HTTP 进程看到，原来这个请求是要访问一个⻚面，于是就把这个网⻚封装在 HTTP 响应报文里。


#### HTTP 址。 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地

#### 穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。

#### 最后跳到了客户端的城⻔把手的路由器，路由器扒开机，再由交换机转发到客户端。 IP 头部发现是要找城内的人，于是又把包发给了城内的交换

#### 客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！

#### 于是，客户端开始扒皮，把收到的数据包的皮扒剩快递，就这样显示出来了！ HTTP 响应报文后，交给浏览器去渲染⻚面，一份特别的数据包

#### 最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。

## 一个数据包臭不要脸的感受^

#### 下面内容的 「我」，代表「臭美的数据包⻆色」。注：（括号的内容）代表我的吐槽，三连呸！

#### 我一开始我虽然孤单、不知所措，但没有停滞不前。我依然满怀信心和勇气开始了征途。（ 用层数据，后面有底层兄弟当靠山，我呸！ ） 你当然有勇气，你是应

#### 我很庆幸遇到了各路神通广大的大佬，有可靠传输的 TCP、有远程定位功能的 IP、有指明下一站位置的 MAC 等

#### （ 你当然会遇到，因为都被计算机安排好的，我呸！ ）。

#### 这些大佬都给我前面加上了头部，使得我能在交换机和路由器的转发下，抵达到了目的地！（ 吐槽了，放过你！ ） 哎，你也不容易，不

#### 这一路上的经历，让我认识到了网络世界中各路大侠协作的重要性，是他们维护了网络世界的秩序，感谢他们！（ 我呸，你应该感谢众多计算机科学家！ ）

#### 参考资料

#### [1] 户根勤.网络是怎么连接的.人⺠邮电出版社.

#### [2] 刘超.趣谈网络协议.极客时间.

## 读者问答^


#### 读者问：“笔记本的是自带交换机的吗？交换机现在我还不知道是什么”

#### 笔记本不是交换机，交换机通常是 2 个网口以上。

#### 现在家里的路由器其实有了交换机的功能了。交换机可以简单理解成一个设备，三台电脑网线接到这个设备，这三台电脑就可以互相通信了，交换机嘛，交换数据这么理解就可以。

```
读者问：“如果知道你电脑的mac地址，我可以直接给你发消息吗？”
```
Mac地址只能是两个设备之间传递时使用的，如果你要从大老远给我发消息，是离不开 IP 的。

```
读者问：机器的 Mac “请问公网服务器的地址吧？” Mac 地址是在什么时机通过什么方式获取到的？我看 arp 获取Mac地址只能获取到内网
```
在发送数据包时，如果目标主机不是本地局域网，填入的器一直转发下一个路由器，直到转发到目标主机的路由器，发现MAC地址是路由器，也就是把数据包转发给路由器，路由 IP 地址是自己局域网内的主机，就会 arp 请求获
取目标主机的 MAC 地址，从而转发到这个服务器主机。
转发的过程中，源IP地址和目标IP地址是不会变的，源MAC地址和目标MAC地址是会变化的。

## 最后^

#### 哈喽，我是小林，就爱图解计算机基础，如果觉得文章对你有帮助，别忘记关注我哦！


## 5.2 Linux 系统是如何收发网络包的？

#### 这次，就围绕一个问题来说。

**Linux 系统是如何收发网络包的？**

## 网络模型^

为了使得多种设备能通过网络相互通信，和为了解决各种不同设备在网络互联中的兼容性问题，国际标标准化组织制定了开放式系统互联通信参考模型（ _pen System Interconnection Reference Model_ ），也就是 OSI 网络模型，
该模型主要有 7 层，分别是应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层。
每一层负责的职能都不同，如下：
应用层，负责给应用程序提供统一的接口；
表示层，负责把数据转换成兼容另一个系统能识别的格式；
会话层，负责建立、管理和终止表示层实体之间的通信会话；
传输层，负责端到端的数据传输；
网络层，负责数据的路由、转发、分片；
数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；
物理层，负责在物理网络中传输数据帧；
由于⻅，也比较实用的是四层模型，即 OSI 模型实在太复杂，提出的也只是概念理论上的分层，并没有提供具体的实现方案。事实上，我们比较常 TCP/IP 网络模型，Linux 系统正是按照这套网络模型来实现网络协议栈的。

TCP/IP 网络模型共有 4 层，分别是应用层、传输层、网络层和网络接口层，每一层负责的职能如下：
应用层，负责向用户提供一组应用程序，比如 HTTP、DNS、FTP 等;
传输层，负责端到端的通信，比如 TCP、UDP 等；
网络层，负责网络包的封装、分片、路由、转发，比如 IP、ICMP 等；
网络接口层，负责网络包在物理网络中的传输，比如网络包的封帧、输网络帧等； MAC 寻址、差错检测，以及通过网卡传

TCP/IP 网络模型相比 OSI 网络模型简化了不少，也更加易记，它们之间的关系如下图：


#### 不过，我们常说的七层和四层负载均衡，是用层。 OSI 网络模型来描述的，七层对应的是应用层，四层对应的是传输

## Linux 网络协议栈^

#### 我们可以把自己的身体比作应用层中的数据，打底衣服比作传输层中的鞋子分别比作网络接口层的帧头和帧尾。 TCP 头，外套比作网络层中 IP 头，帽子和


#### 在冬天这个季节，当我们要从家里出去玩的时候，自然要先穿个打底衣服，再套上保暖外套，最后穿上帽子和鞋子才出⻔，这个过程就好像我们把 TCP 协议通信的网络包发出去的时候，会把应用层的数据按照网络协议栈层层封

#### 装和处理。

#### 你从下面这张图可以看到，应用层数据在每一层的封装格式。

#### 其中：

#### 传输层，给应用数据前面增加了 TCP 头；

#### 网络层，给 TCP 数据包前面增加了 IP 头；

#### 网络接口层，给 IP 数据包前后分别增加了帧头和帧尾；

#### 这些新增和头部和尾部，都有各自的作用，也都是按照特定的协议格式填充，这每一层都增加了各自的协议头，那自然网络包的大小就增大了，但物理链路并不能传输任意大小的数据包，所以在以太网中，规定了最大传输单元

#### （MTU）是 1500 字节，也就是规定了单次传输的最大 IP 包大小。

#### 当网络包超过要的分包就越多，那么网络吞吐能力就越差，相反的，如果 MTU 的大小，就会在网络层分片，以确保分片后的 MTU IP 越大，需要的分包就越小，那么网络吞吐能力就包不会超过 MTU 大小，如果 MTU 越小，需

#### 越好。

知道了就类似于 TCP/IP TCP/IP 网络模型，以及网络包的封装原理后，那么的四层结构： Linux 网络协议栈的样子，你想必猜到了大概，它其实



#### 从上图的的网络协议栈，你可以看到：

```
应用程序需要通过系统调用，来跟 Socket 层进行数据交互；
Socket 层的下面就是传输层、网络层和网络接口层；
最下面的一层，则是网卡驱动程序和硬件网卡设备；
```
## Linux 接收网络包的流程^

网卡是计算机里的一个硬件，专⻔负责接收和发送网络包，当网卡接收到一个网络包后，会通过络包放入到 Ring Buffer，这个是一个环形缓冲区。 DMA 技术，将网

那接收到网络包后，应该怎么告诉操作系统这个网络包已经到达了呢？
最简单的一种方式就是触发中断，也就是每当网卡收到一个网络包，就触发一个中断告诉操作系统。
但是，这存在一个问题，在高性能网络场景下，网络包的数量会非常多，那么就会触发非常多的中断，要知道当CPU 收到了中断，就会停下手里的事情，而去处理这些网络包，处理完毕后，才会回去继续其他事情，那么频繁
地触发中断，则会导致效率。 CPU 一直没玩没了的处理中断，而导致其他任务可能无法继续前进，从而影响系统的整体

所以为了解决频繁中断带来的性能开销，方式来接收网络包，它的核心概念就是 **不采用中断的方式读取数据** Linux 内核在 2.6 版本中引入了，而是首先采用中断唤醒数据接收的服务程序， **NAPI 机制** ，它是混合「中断和轮询」的
然后 poll 的方法来轮询数据。
比如，当有网络包到达时，网卡发起硬件中断，于是会执行网卡硬件中断处理函数， **时屏蔽中断」，然后唤醒「软中断」来轮询处理数据，直到没有新数据时才恢复中断，这样一次中断处理多个网络中断处理函数处理完需要「暂
包** ，于是就可以降低网卡中断带来的性能开销。
那软中断是怎么处理网络包的呢？它会从个网络包交给网络协议栈进行逐层处理。 Ring Buffer 中拷⻉数据到内核 struct sk_buff 缓冲区中，从而可以作为一

首先，会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给网络层。


#### 到了网络层，则取出发送给本机后，就会从 IP IP 包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。

传输层取出Socket，并把数据拷⻉到 TCP 头或 UDP Socket 头，根据四元组「源的接收缓冲区。 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的

最后，应用层程序调用 Socket 接口，从内核的 Socket 接收缓冲区读取新到来的数据到应用层。
至此，一个网络包的接收过程就已经结束了，你也可以从下图左边部分看到网络包接收的流程，右边部分刚好反过来，它是网络包发送的流程。

## Linux 发送网络包的流程^

#### 如上图的有半部分，发送网络包的流程正好和接收流程相反。

首先，应用程序会调用Socket 层，Socket 层会将应用层数据拷⻉到 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 发送缓冲区中。


接下来，网络协议栈从 Socket 发送缓冲区中取出数据包，并按照 TCP/IP 协议栈从上到下逐层处理。
如果使用的是IP 包，然后通过查询路由表确认下一跳的 TCP 传输协议发送数据，那么会在传输层增加 IP，并按照 MTU 大小进行分片。 TCP 包头，然后交给网络层，网络层会给数据包增加

分片后的网络包，就会被送到网络接口层，在这里会通过尾，放到发包队列中。 ARP 协议获得下一跳的 MAC 地址，然后增加帧头和帧

这一些准备好后，会触发软中断告诉网卡驱动程序，这里有新的网络包需要发送，最后驱动程序通过包队列中读取网络包，将其放入到硬件网卡的队列中，随后物理网卡再将它发送出去。 DMA，从发

## 总结^

#### 电脑与电脑之间通常都是通话网卡、交换机、路由器等网络设备连接到一起，那由于网络设备的异构性，国际标准化组织定义了一个七层的 OSI 网络模型，但是这个模型由于比较复杂，实际应用中并没有采用，而是采用了更为简

化的 TCP/IP 模型，Linux 网络协议栈就是按照了该模型来实现的。
TCP/IP 协议栈主要构成部分。模型主要分为应用层、传输层、网络层、网络接口层四层，每一层负责的职责都不同，这也是 Linux 网络

当应用程序通过中，随后由网卡将网络包发送出去。 Socket 接口发送数据包，数据包会被网络协议栈从上到下进行逐层处理后，才会被送到网卡队列

而在接收网络包时，同样也要先经过网络协议栈从下到上的逐层处理，最后才会被送到应用程序。

## 最后^

#### 哈喽，我是小林，就爱图解计算机基础，如果觉得文章对你有帮助，别忘记关注我哦！


# 六、学习心得

#### 最近收到不少读者留言，关于怎么学「操作系统」和「计算机网络」的留言，小林写这一块的内容也有半年多了，啃非常多的书，也看了很多视频，有好的有差的，今天就 掏心掏肺 地分享给大家。

#### 操作系统和计算机网络有多重要呢？如果没有操作系统，我们的手机和电脑可以说是废铁了，自然它们都没有使用价值了，另外如果没有计算机网络，我们的手机和电脑就是一座「孤岛」了，孤岛的世界很单调，也没有什么色

#### 彩，也正是因为计算机网络，才创造出这么丰富多彩的互联网世界。

#### 身为程序员的我们，那更应该深刻理解和掌握它们，虽然我们日常碍我们写代码，但是当出现问题时，没有这些基础知识，你是无厘头的，根本没有思路下手，这时候和别人差距就 CURD 的工作中，即使不熟悉它们，也不妨

#### 显现出来了，可以说是程序员之间的分水岭。

#### 事实上，我们工作中会有大量的时间都是在排查和解决问题，编码的时间其实比较少，如果计算机基础学的很扎实，虽然不敢保证我们能 100% 解决，但是至少遇到问题时，我们有一个排查的方向，或者直接就定位到问题所

#### 在，然后再一步一步尝试解决，解决了问题，自然就体现了我们自身的实力和价值，职场也会越走越远。

我自己工作中就深刻体会到了它们多重要性，我最近项目就遇到久之后，就无法与客户端正常建立连接了，使用 tcpdump 抓包发现 TCP TCP 比较底层的问题，我们的一个三次握手过程中，服务端把客户端握手过 Web 服务运行
程中最后 1 个 ack 给丢掉了。
刚开始觉得非常的莫名奇妙，后面想起自己写过一篇于是执行 netstat -s 命令查看 TCP error 相关的信息，发现 TCP 半连接和全连接队列 TCP 全连接队列溢出了，接着再通过的文章，就往这个方向排查问题， ss -lnt 命令进一
步确认，当前 TCP 全连接队列确实超过了 TCP 全连接队列最大值，这个问题就很快定位出来了。


另外，当过来的 ack TCP ，如果你把该参数设置为全连接队列溢出后，由于 1 ，那现象将变成，服务端会给客户端发送 tcp_abort_on_overflow 内核参数默认为 RST 0 ，所以服务端会丢掉客户端发报文，废弃掉连接。


那要扩大全连接队列也不难，min(somaxconn, backlog) ，其中TCP 全连接队列最大值取决于 somaxconn 是内核参数，而 somaxconn backlog 和是我们程序 backlog 之间的最小值，也就是 listen 方法中指定的参数。

上面这个小例子，很明显是无法通过看应用层的代码来解决的，必须了解 TCP 的机制，才能找到解决之道。
铺垫了那么多，接下里进入正题。

## 6.1 计算机网络怎么学？

#### 计算机网络相比操作系统好学非常多，因为计算机网络不抽象，你要想知道网络中的细节，你都可以通过抓包来分析，而且不管是手机、个人电脑和服务器，它们所使用的计算网络协议是一致的。

#### 也就是说，计算机网络不会因为设备的不同而不同，大家都遵循这一套「规则」来相互通信，这套规则就是TCP/IP 网络模型。

#### TCP/IP 链路层和物理层）我们只需要做简单的了解就可以了。网络参考模型共有 4 层，其中需要我们熟练掌握的是应用层、传输层和网络层，至于网络接口层（数据


对于应用层，当然重点要熟悉最常⻅的IPv6 可以做简单点了解。 HTTP 和 HTTPS，传输层 TCP 和 UDP 都要熟悉，网络层要熟悉 IPv4，

我觉得学习一个东⻄，就从我们常⻅的事情开始着手。
比如，的过程中发生的事情都搞明白，这样就基本知道一个数据包是怎么转发的了，于是你就知道了网络层、数据链路层 ping 命令可以说在我们判断网络环境的时候，最常使用的了，你可以先把你电脑 ping 你舍友或同事的电脑
和物理层之间是如何工作，如何相互配合的了。
搞明白了在学习 ping ping 的时候就已经明白了，这时就只需要认真掌握传输层中的过程，我相信你学起 HTTP 请求过程的时候，会很快就能掌握了，因为网络层以下的工作方式，你 TCP 和应用层中的 HTTP 协议，就能搞明白
访问网⻚的整个过程了，这也是面试常⻅的题目了，毕竟它能考察你网络知识的全面性。
重中之重的知识就是数据可靠传输的特性，又可以拆解为 TCP 了，TCP 不管是超时重新、流量控制、滑动窗口、拥塞控制建立连接、断开连接的过程，还是数据传输的过程，都不能放过，针对等等知识点，学完这些只能算对
TCP 遇到的问题。有个「 **感性** 」的认识，另外我们还得知道 Linux 提供的 TCP 内核的参数的作用，这样才能从容地应对工作中

接下来，推荐我看过并觉得不错的计算机网络相关的书籍和视频。

## 入⻔系列^

#### 此系列针对没有任何计算机基础的朋友，如果已经对计算机轻⻋熟路的大佬，也不要忽略，不妨看看我推荐的正确吗。

#### 如果你要入⻔还是从这里偷学到不少，书籍不厚，相信优秀的你，几天就可以看完了。 HTTP，首先最好书籍就是《 图解 HTTP 》了，作者真的做到完完全全的「图解」，小林的图解功夫


#### 如果要入⻔的每一层，但是这个书籍的顺序不是从「应用层 TCP/IP 网络模型，我推荐的是《 图解 —> TCP/IP 物理层」，而是从「物理层》，这本书也是以大量的图文来介绍了 -> 应用层」顺序开始讲的，这一 TCP/IP 网络模式

#### 点我觉得不太好，这样一上来就把最枯燥的部分讲了，很容易就被劝退了，所以我建议先跳过前面几个章节，先看网络层和传输层的章节，然后再回头看前面的这几个章节。


#### 另外，你想了解网络是怎么传输，那我推荐《的过程讲解了一遍，其中关于电信等运营商是怎么传输的，这部分你可以跳过，当然你感兴趣也可以看，只是我觉 网络是怎样连接的 》，这本书相对比较全面的把访问一个网⻚的发生

#### 得没必要看。


#### 如果你觉得书籍过于枯燥，你可以结合作的，PPT 的动图是我⻅过做的最用心的了，一看就懂的佳作。 B 站《 计算机网络微课堂 》视频一起学习，这个视频是湖南科技大学老师制


```
B 站视频地址：https://www.bilibili.com/video/BV1c4411d7jb?p=1
```
## 深入学习系列^

#### 看完入⻔系列，相信你对计算机网络已经有个大体的认识了，接下来我们也不能放慢脚步，快⻢加鞭，借此机会继续深入学习，因为隐藏在背后的细节还是很多的。

#### 对于起，一层一层的说到最后物理层的，有种挖地洞的感觉，这样的内容编排顺序相对是比较合理的。 TCP/IP 网络模型深入学习的话，推荐《 计算机网络 - 自顶向下方法 》，这本书是从我们最熟悉 HTTP 开始说


#### 但如果要深入书，是进一步深入学习的好资料，这本书的作者用各种实验的方式来细说各种协议，但不得不说，这本书真的很枯 TCP，前面的这些书还远远不够，赋有计算机网络圣经的之说的《 TCP/IP 详解 卷一：协议 》这本

#### 燥，当时我也啃的很难受，但是它质量是真的很高，这本书我只看了你一定要过几遍这本书的 TCP 部分，涵盖的内容非常全且细。 TCP 部分，其他部分你可以选择性看，但是


要说我看过最好的的网址可以白嫖看这本书的内容，图片都是彩色，看起来很舒服很鲜明，小林之前写的 TCP 资料，那必定是《 **The TCP/IP GUIDE** 》这本书了，目前只有英文版本的，而且有个专⻔ TCP 文章不少案例和图片
都是参考这里的，这本书精华部分就是把多。 TCP 滑动窗口和流量控制说的超级明白，很可惜拥塞控制部分说的不


```
白嫖站点：http://www.tcpipguide.com/free/t_TCPSlidingWindowAcknowledgmentSystemForDataTranspo-6.htm
```
#### 当然，计算机网络最牛逼的资料，那必定和最正确的地方了，困惑大家的 TCP 为什么三次握手和四次挥手，其实在 RFC 文档 ，它可以称为计算机网络世界的「法规」，也是最新、最权威 RFC 文档几句话就说明白了。

```
TCP 协议的 RFC 文档：https://datatracker.ietf.org/doc/rfc1644/
```
## 实战系列^

在学习书籍资料的时候，不管是报，接着可以用 Wireshark 工具 TCP看每一个数据报文的信息，这样你会觉得计算机网络没有想象中那么抽象了，因为、UDP、ICMP、DNS、HTTP、HTTPS 等协议，最好都可以亲手尝试抓数据
它们被你「抓」出来了，并毫无保留地显现在你面前了，于是你就可以肆无忌惮地「扒开」它们，看清它们每一个头信息。

那在这里，我也给你推荐工作中的实际的案例，作者的文笔相当有趣，看起来堪比小说一样爽，相信你不用一个星期 2 本关于 Wireshark 网络分析的书，这两本书都是同一个作者，书中的案例都是源于作者 2 本都能看完了。


## 最后^

#### 文中推荐的书，小林都已经把电子书整理好给大家了，只需要在小林的公众号后台回复「度网盘下载链接。 我要学习 」，即可获取百


## 6.2 操作系统怎么学？

操作系统真的可以说是它，我们才能深刻体会到它的精妙之处，甚至会被计算机科学家设计思想所震撼，有些思想实际上也是可以应用于 Super Man，它为了我们做了非常厉害的事情，以至于我们根本察觉不到，只有通过学习
我们工作开发中。
操作系统比较重要的四大模块，分别是系统的顺序，也是我推荐给大家的学习顺序，因为内存管理不仅是最重要、最难的模块，也是和其他模块关联性最内存管理、进程管理、文件系统管理、输入输出设备管理。这是我学习操作
大的模块，先把它搞定，后续的模块学起来我认为会相对轻松一些。
学习的过程中，你可能会遇到很多「虚拟」的概念，比如虚拟内存、虚拟文件系统，实际上它们的本质上都是一样的，都是 **向下屏蔽差异，向上提供统一的东⻄** ，以方便我们程序员使用。

还有，你也遇到各种各样的出那么多调度算法，你当然可以说是为了更快更有效率，但是因什么问题而因此引入新算法的这个过程，更是我们调度算法，在这里你可以看到数据结构与算法的魅力，重要的是我们要理解为什么要提
重点学习的地方。
你也会开始明白进程与线程最大的区别在于上下文切换过程中，都是共享虚拟内存空间的，线程就单这一点不用切换，就相比进程上下文切换的性能开销减少了很多。由于虚拟内 **线程不用切换虚拟内存** ，因为同一个进程内的线程
存与物理内存的映射关系需要查询⻚表，⻚表的查询是很慢的过程，因此会把常用的地址映射关系缓存在的，这样便可以提高⻚表的查询速度，如果发生了进程切换，那 TLB 缓存的地址映射关系就会失效，缓存失效就 TLB 里
意味着命中率降低，于是虚拟地址转为物理地址这一过程就会很慢。
你也开始不会傻傻的认为会很低，因为你发现操作系统会有个「 read 或 write **磁盘高速缓冲区** 之后数据就直接写到硬盘了，更不会觉得多次操作」，它已经帮我们做了缓存的工作，它会预读数据、缓存最 read 或 write 方法性能
近访问的数据，以及使用率。 I/O 调度算法来合并和排队磁盘调度 I/O，这些都是为了减少操作系统对磁盘的访问频


#### ......

#### 还有太多太多了，我在这里就不赘述了，剩下的就交给你们在学习操作系统的途中去探索和发现了。

还有一点需要注意，学操作系统的时候，不要误以为它是在说误，操作系统是集合大多数操作系统实现的思想，跟实际具体实现的 Linux 操作系统，这也是我初学的时候犯的一个错 Linux 操作系统多少都会有点差别，如果要想
Linux 识，这样学起来才能事半功倍。操作系统的具体实现方式，可以选择看 Linux 内核相关的资料，但是在这之前你先掌握了操作系统的基本知

## 入⻔系列^

#### 对于没学过操作系统的小白，我建议学的时候，不要直接闷头看书。相信我，你不用几分钟就会打退堂鼓，然后就把厚厚的书拿去垫显示器了，从此再无后续，毕竟直接看书太特喵的枯燥了，当然不如用来垫显示器玩游戏来着

#### 香。

#### B 华大学 站关于操作系统课程资源很多，我在里面也看了不同老师讲的课程，觉得比较好的入⻔级课程是《》，该课程由清华大学老师向勇和陈渝授课，虽然我们上不了清华大学，但是至少我们可以在网上选择听清 操作系统 - 清

#### 华大学的课嘛。课程授课的顺序，就如我前面推荐的学习顺序：「内存管理输出设备管理」。 -> 进程管理 -> 文件系统管理 -> 输入

```
B 524697 站清华大学操作系统视频地址：https://www.bilibili.com/video/BV1js411b7vg?from=search&seid=2361361014547
```

#### 该清华大学的视频教学搭配的书应该是《存管理，然后就看书上对应的章节，这样相比直接啃书相对会比较好。 现代操作系统 》，你可以视频和书籍两者结合一起学，比如看完视频的内

清华大学的操作系统视频课讲的比较精炼，涉及到的内容没有那么细，《频课程相对就会比较细节，老师会用 Linux 内核代码的⻆度带你进一步理解操作系统，也会用生活小例子帮助你理 **操作系统 - 哈工大** 》李治军老师授课的视
解。


```
B 24697 站哈工大操作系统视频地址：https://www.bilibili.com/video/BV1d4411v7u7?from=search&seid=23613610145475
```
## 深入学习系列^

#### 《现代操作系统》这本书我感觉缺少比较多细节，说的还是比较笼统，而且书也好无聊。

推荐一个说的更细的操作系统书都是循序渐进，层层递进的，阅读起来还是觉得挺有意思的，这本书的内存管理和并发这两个部分说的很棒，这本 —— 《 **操作系统导论** 》，这本书不仅告诉你 What，还会告诉你 How，书的内容
书的中文版本我也没找到资源，不过微信读书可以免费看这本书。


#### 当然，少不了这本被称为神书的《书，它是以程序员视⻆理解计算机系统，不只是涉及到操作系统，还涉及到了计算机组成、 深入理解计算机系统 》，豆瓣评分高达 9.8 分，这本书严格来说不算操作系统C 语言、汇编语言等知

#### 识，是一本综合性比较强的书。


#### 它告诉我们计算机是如何设计和工作的，操作系统有哪些重点，它们的作用又是什么，这本书的目标其实便是要讲清楚原理，但并不会把某个话题挖掘地过于深入，过于细节。看看这本书后，我们就可以对计算机系统各组件的工

#### 作方式有了理性的认识。在一定程度上，其实它是在锻炼一种思维方式 —— 计算思维。

## 最后^

#### 文中推荐的书，小林都已经把电子书整理好给大家了，只需要在小林的公众号后台回复「度网盘下载链接。 我要学习 」，即可获取百


# 七、画图经验

#### 小林写这么多篇图解文章，你们猜我收到的最多的读者问题是什么？没错，就是问我是使用什么这一点大家都相当好奇，那干脆不如写一篇介绍下我是怎么画图的。 画图 工具，看来对

#### 如果我的文章缺少了自己画的图片，相当于失去了灵魂，技术文章本身就很枯燥，如果文章中没有几张图片，读者被劝退的概率飙飙升，剩下没被劝退的估计看着看着就睡着了。所以，精美的图片可以说是必不可少的一部分，不

#### 仅在阅读时能带来视觉的冲击，而且图片相比文字能涵盖更多的信息，不然怎会有一图胜千言的说法呢？

#### 这时，可能有的读者会说自己不写文章呀，是不是没有必要了解画图了？我觉得这是不对，画图在我们工作中其实也是有帮助的，比如如果你想跟领导汇报一个业务流程的问题，把业务流程画出来，肯定用图的方式比用文字的方

#### 式交流起来会更有效率，更轻松些；如果你参与了一个比较复杂的项目开发，你也可以把代码的流程图给画出来，不仅能帮助自己加深理解，也能帮助后面参与的同事能更快的接手这个项目；甚至如果你要晋升级别了，演讲 PTT

#### 里的配图也是必不可少的。

#### 不过很多人都是纠结用什么画图工具，其实小林觉得再烂的画图工具，只要你思路清晰，确定自己要表达出什么信息，也是能把图画好的，所以不必纠结哪款画图工具，挑一款自己画起来舒服的就行了。

#### “小林，你说的我都懂，我就是喜欢你的画图⻛格嘛，你就说说你用啥画的？”

#### 咳咳，没问题，直接坦白讲，我用的是一个在线的画图网址，地址是：

```
https://draw.io
```

用它的原因是使用方便和简单，当然最重要的是它完全免费，没有什么限制，甚至还能直接把图片保存到GoogleDrive 、 OneDrive 和 Github，我就是保存到 Github，然后用 Github 作为我的图床。

既然要认识它，那就先来看看它⻓什么样子，它主要分为三个区域，从左往右的顺序是「图形选择区域、绘图区域、属性设置区域」。

#### 其中，最左边的「图形选择区域」可以选择的图案有很多种，常⻅的流程图、时序图、表格图都有，甚至还可以在最左下⻆的「更多图形」找到其他种类的图形，比如网络设备图标等。


#### 再来，最右边「属性设置区域」可以设置文字的大小，图片颜色、线条形状等，而我最常用颜色板块是下面这三种，都是比较浅色的，这样看起来舒服些。


#### 我最近常用的一个图形是圆⻆方块图，它的位置如下图，但是它默认的颜色过于深色，如果要在方框图中描述文字，则可能看不清楚，这时我会在最右侧的「属性设置区域」把方块颜色设置成浅色系列的。另外，还有一点需要

注意的是，默认的字体大小比较小，我一般会调成 16px 大小。

#### 如果你不喜欢上图的带有「划痕」的圆⻆方块图形，可以选择下图中这个最简洁的圆⻆方框图形。

这个简洁的圆⻆方框图形，再搭配颜色，能组合成很多结构图，比如我用过它组成过 CPU Cache 的结构图。


#### 那直⻆方框图形，我主要是用来组成「表格」，原因自带的表格不好看，也不方便调。

如果觉得直直的线条太死板，你可以把图片属性中的「绘⻛格，挺多人喜欢这种⻛格。 _Comic_ 」勾上，于是就会变成歪歪扭扭的效果啦，有点像手

比如，我用过这种⻛格画过 TCP 三次握手流程的图。


#### 方块图形再加上菱形，就可以组合成简单程序流程图了，比如我画过存储器缓存流程图。



#### 所以，不要小看这些基本图形，只要构思清晰，再基本的图形，也是能构成层次分明并且好看的图。

#### 基本的图形介绍完后，相信你画一些简单程序流程图等图形是没问题的了，接下来就是各种了。 图形 + 线条 的组合的

#### 通过一些基本的图形组合，你还可以画出时序图，时序图可以用来描述多个对象之间的交互流程，比如我画过多个线程获取互斥锁的时序图。


#### 再来，为了更好表达零拷⻉技术的过程，那么用图的方式会更清晰。


#### 前面也提到，图形不只是简单图形，还有其他自带的设备类图形，比如我用网络设备图画过单播、广播、多播通信的区别图。


#### 你要说，我画过最复杂的图，那就是写来了，现在回想起来还是觉得累人。 TCP 流量控制的时候，把整个交互过程 + 文字描述 + 滑动窗口状况都画出



#### 还有好多好多，我就比一一列举，这半年下来，小林至少画了信画过图的朋友后，都能体会到这种感觉了。但没办法，谁叫小林是图解工具人呢，画图可以更好的诠释文章内 500+ 张图了，每一张图其实还是挺费时间的，相

#### 容，但最重要的是，把你们吸引过来了，这是件让我非常高兴的事情，也是让我感觉画图这个事情值得认真做。

#### 另外，细心的读者也发现了，小林贴代码的时候，使用的是图片的形式，原因是代码通常都是比较⻓，在手机看文章用图片的呈现的方式会更舒服清晰。

#### 在这里也推荐下这个代码截图网址：

_https://carbon.now.sh/_
网站⻚面如下图，代码显示的效果是不是很美观？

#### 文字的分享有局限性，关键还是要你自己动手摸索摸索，形成自己一套画图的方法论，练习的时候可以先从模仿画起，后面再结合工作或文章的需求画出自己心中的那个图。


# 赞赏支持

#### 本系列「图解网络」的所有图片都是小林纯手打的，大家突破计算机网络的痛点。 全文共 15W 字 + 450 张图 ，这么做的原因很简单，就是为了

#### 如果对你有帮助，可以给小林一个小小的赞赏，金额多少不重要，重要的是你们的小小心意，会助力小林输出更多优质的文章，先提前跟大家说声谢谢。

## 微信赞赏码

## 支付宝赞赏码